{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc132356-80f5-4841-9012-23637849efc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/04 00:33:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/04 00:33:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import json\n",
    "from operator import add\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from node2vec import Node2Vec as n2v\n",
    "import networkx as nx\n",
    "from hashlib import md5\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "\n",
    "from utils import create_category_md5_mapping, integrate_mapping_user_bus_cat_data, dataframe_to_rdd_dict, analyze_top_business_categories, analyze_top_categories\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "def initialize_spark_context(APP_NAME=\"Train: XGBModel\"):\n",
    "    # Spark配置项列表\n",
    "    SPARK_CONF = [\n",
    "        (\"spark.dynamicAllocation.enabled\", \"true\"),  # 启用动态资源分配\n",
    "        (\"spark.dynamicAllocation.maxExecutors\", \"2\"),  # 最大执行器数量\n",
    "        (\"spark.executor.memory\", \"4g\"),  # 每个执行器的内存\n",
    "        (\"spark.executor.cores\", \"6\"),  # 每个执行器的CPU核心数\n",
    "        (\"spark.executor.memoryOverhead\", \"3000\"),  # 执行器内存开销\n",
    "        (\"spark.driver.memory\", \"4g\"),  # 驱动程序的内存\n",
    "        (\"spark.driver.maxResultSize\", \"3\"),  # 驱动程序的最大结果大小\n",
    "        (\"spark.python.worker.memory\", \"4g\"),  # Python工作进程的内存\n",
    "        (\"spark.sql.shuffle.partitions\", \"20\"),  # Shuffle操作的分区数\n",
    "        (\"spark.sql.sources.partitionOverWriteMode\", \"dynamic\"),  # 分区覆写模式\n",
    "        # (\"spark.network.timeout\", \"10s\"),  # 网络超时设置\n",
    "        # (\"spark.executor.heartbeatInterval\", \"10s\"),  # 执行器心跳间隔\n",
    "    ]\n",
    "\n",
    "    # 创建Spark配置\n",
    "    spark_conf = pyspark.SparkConf()\n",
    "    spark_conf.setAppName(APP_NAME)\n",
    "    spark_conf.setAll(SPARK_CONF)\n",
    "\n",
    "    # 创建SparkContext\n",
    "    sc = pyspark.SparkContext(conf=spark_conf)\n",
    "    sc.setLogLevel(\"ERROR\")  # 设置日志级别\n",
    "\n",
    "    return sc\n",
    "\n",
    "sc = initialize_spark_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9bb53e-e735-48c5-aaf5-d1dfeb59dcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "import better_features\n",
    "from better_features import FeatureProcessor, read_json_data, transform_user_data, transform_business_data, extract_review_data\n",
    "from datetime import datetime #add\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# def rdd_to_pandas(rdd):\n",
    "#     return pd.DataFrame(rdd.collect(), columns=rdd.first().keys())\n",
    "\n",
    "def prepare_test_data(test_df, cluster):\n",
    "    if cluster == -1:\n",
    "        test_cluster_data = test_df\n",
    "    else:\n",
    "        test_cluster_data = test_df[test_df['Cluster'] == cluster]\n",
    "        \n",
    "    X_test = test_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y_test = test_cluster_data['stars']\n",
    "    return X_test, y_test\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "user_parsed_df = pd.read_csv('cache/user_df.csv') # parsed from users.json\n",
    "business_parsed_df = pd.read_csv('cache/business_df.csv') # parsed from business.json\n",
    "review_parsed_df = pd.read_csv('cache/review_df.csv') # parsed from business.json\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fa115b-dc3e-46fa-9dd7-3b316ab4bc9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79575021-b209-4691-9e42-018fe5ca165e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "from better_features import FeatureProcessor, read_json_data, transform_user_data, transform_business_data,extract_review_data\n",
    "from utils import integrate_mapping_user_bus_cat_data\n",
    "from KMeans_user_cluster import KMeans_process_user_clusters\n",
    "\n",
    "data_folder_path, test_data_file, output_file = '../data/', '../data/yelp_true.csv', 'prediction.csv'\n",
    "feature_processor = FeatureProcessor(sc, data_folder_path, user_parsed_df, business_parsed_df, review_parsed_df)\n",
    "user_clusters = KMeans_process_user_clusters(feature_processor.map_reviews_with_categories(), business_parsed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9acf94c9-6f2b-4b54-bc3e-298e1bba89ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration:  157.96219611167908\n"
     ]
    }
   ],
   "source": [
    "print(\"Duration: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba52775c-d05e-492f-b638-47ed6804dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e95ca0-389e-456d-b14c-159c2d02c575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "## TRAIN DATA FEATURE PROCESSING HERE\n",
    "train_data_file = '../data/yelp_train.csv'\n",
    "train_df = pd.read_csv(train_data_file)\n",
    "train_df = feature_processor.process_all_features(sc, train_df, train_data_file)\n",
    "train_df = train_df.merge(user_clusters, on='user_id', how='left')\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a755a2e7-06af-4670-bbbc-32f990a88f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "## TEST DATA FEATURE PROCESSING HERE\n",
    "test_data_file = '../data/yelp_true.csv'\n",
    "test_df = pd.read_csv(test_data_file)\n",
    "test_df = feature_processor.process_all_features(sc, test_df, test_data_file)\n",
    "test_df = test_df.merge(user_clusters, on='user_id', how='left')\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79550aca-4e8c-4427-b8ee-16f7d3f017a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "## TEST DATA FEATURE PROCESSING HERE\n",
    "val_data_file = '../data/yelp_val.csv'\n",
    "val_df = pd.read_csv(val_data_file)\n",
    "val_df = feature_processor.process_all_features(sc, val_df, test_data_file)\n",
    "val_df = val_df.merge(user_clusters, on='user_id', how='left')\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5d82653-ef53-42b0-9076-2135cb5a355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# train_df.to_csv('cache/train_df.csv', index=False)\n",
    "# test_df.to_csv('cache/test_df.csv', index=False)\n",
    "# val_df.to_csv('cache/val_df.csv', index=False)\n",
    "\n",
    "# print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90a645-59f0-4fcb-94d3-a53147cfcd71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4485db8-f6dd-4ca5-b6fe-f28faf980b77",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>score</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>fans</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>num_interactions</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>elite_years</th>\n",
       "      <th>compliments</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>total_ufc_count_per_year</th>\n",
       "      <th>avg_ufc_count_per_review</th>\n",
       "      <th>bus_stars</th>\n",
       "      <th>bus_review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>city_encoded</th>\n",
       "      <th>log_affinity_score</th>\n",
       "      <th>log_amp_affinity_score</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-qj9ouN0bzMXz1vfEslG-A</td>\n",
       "      <td>5j7BnXXvlS69uLVHrY9Upw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.69</td>\n",
       "      <td>154</td>\n",
       "      <td>9</td>\n",
       "      <td>2660</td>\n",
       "      <td>644</td>\n",
       "      <td>1003</td>\n",
       "      <td>4307</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>36.15</td>\n",
       "      <td>7.22</td>\n",
       "      <td>3.5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QZ_Arlwoj0ghfBvg69rjOw</td>\n",
       "      <td>SUktrYdNQD8k2vvkM4OpfA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.36</td>\n",
       "      <td>182</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>47</td>\n",
       "      <td>22</td>\n",
       "      <td>148</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.96</td>\n",
       "      <td>2.67</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.41</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>y0ZU1w6YY4W-KtMeRXSYLg</td>\n",
       "      <td>UpEVdq_euH-5mqCIgUAd2Q</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.58</td>\n",
       "      <td>231</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>7.70</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.5</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>984</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tYk7mMGGFl3gLfmhST5L-A</td>\n",
       "      <td>cgoHLKJLsAK1ww0_ezNFnw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.59</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>43</td>\n",
       "      <td>16</td>\n",
       "      <td>110</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12.07</td>\n",
       "      <td>7.09</td>\n",
       "      <td>3.5</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>984</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ehAvwDt4Fpsz9KPordu5lA</td>\n",
       "      <td>GPX3TnZ0-4pAxKPJUESbeA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>170</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455826</th>\n",
       "      <td>ubzSgqrV7dyLEQoHIocHXA</td>\n",
       "      <td>SipHumArj5ZIIpltsWwQpQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.09</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>83</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2.04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>984</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455827</th>\n",
       "      <td>E6pqcEmf1LpL82-CIi60aw</td>\n",
       "      <td>_6n27rKvvDiPzWjcF24onA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12.03</td>\n",
       "      <td>2.17</td>\n",
       "      <td>4.5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.41</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455839</th>\n",
       "      <td>x16Fl_5h9aX4tn38kKSGHw</td>\n",
       "      <td>5LNZ67Yw9RD6nf4_UhXOjw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>388</td>\n",
       "      <td>27</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>660</td>\n",
       "      <td>13</td>\n",
       "      <td>126</td>\n",
       "      <td>7</td>\n",
       "      <td>338</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "      <td>86</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>8.01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4097</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455850</th>\n",
       "      <td>BrqGnby6aahIOc0N_1x0Bg</td>\n",
       "      <td>_UEQPDDiSgyYqjORWeLfJg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.97</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>622</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455851</th>\n",
       "      <td>-lh59ko3dxChBSZ9U7LfUw</td>\n",
       "      <td>KPV_FVNWkgmYh1ArVlt6kg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.71</td>\n",
       "      <td>902</td>\n",
       "      <td>127</td>\n",
       "      <td>462</td>\n",
       "      <td>152</td>\n",
       "      <td>345</td>\n",
       "      <td>959</td>\n",
       "      <td>17</td>\n",
       "      <td>1221</td>\n",
       "      <td>10</td>\n",
       "      <td>2319</td>\n",
       "      <td>420</td>\n",
       "      <td>35</td>\n",
       "      <td>57</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>114</td>\n",
       "      <td>312</td>\n",
       "      <td>486</td>\n",
       "      <td>347</td>\n",
       "      <td>24</td>\n",
       "      <td>46.10</td>\n",
       "      <td>11.32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94928 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id             business_id  stars  score  average_stars  \\\n",
       "2       -qj9ouN0bzMXz1vfEslG-A  5j7BnXXvlS69uLVHrY9Upw    2.0    0.0           3.69   \n",
       "8       QZ_Arlwoj0ghfBvg69rjOw  SUktrYdNQD8k2vvkM4OpfA    5.0    0.0           3.36   \n",
       "16      y0ZU1w6YY4W-KtMeRXSYLg  UpEVdq_euH-5mqCIgUAd2Q    4.0    0.0           3.58   \n",
       "19      tYk7mMGGFl3gLfmhST5L-A  cgoHLKJLsAK1ww0_ezNFnw    4.0    0.0           3.59   \n",
       "34      ehAvwDt4Fpsz9KPordu5lA  GPX3TnZ0-4pAxKPJUESbeA    3.0    0.0           3.86   \n",
       "...                        ...                     ...    ...    ...            ...   \n",
       "455826  ubzSgqrV7dyLEQoHIocHXA  SipHumArj5ZIIpltsWwQpQ    4.0    0.0           3.09   \n",
       "455827  E6pqcEmf1LpL82-CIi60aw  _6n27rKvvDiPzWjcF24onA    3.0    0.0           3.86   \n",
       "455839  x16Fl_5h9aX4tn38kKSGHw  5LNZ67Yw9RD6nf4_UhXOjw    5.0    0.0           3.89   \n",
       "455850  BrqGnby6aahIOc0N_1x0Bg  _UEQPDDiSgyYqjORWeLfJg    1.0    0.0           3.63   \n",
       "455851  -lh59ko3dxChBSZ9U7LfUw  KPV_FVNWkgmYh1ArVlt6kg    3.0    0.0           3.71   \n",
       "\n",
       "        user_review_count  fans  useful  funny  cool  num_interactions  yelping_since  \\\n",
       "2                     154     9    2660    644  1003              4307             12   \n",
       "8                     182     2      79     47    22               148             17   \n",
       "16                    231    10       1      5     2                 8             16   \n",
       "19                     60     2      51     43    16               110             14   \n",
       "34                    170     3      27      1    28                56             14   \n",
       "...                   ...   ...     ...    ...   ...               ...            ...   \n",
       "455826                 88     1      35     29    19                83             13   \n",
       "455827                301     4       8      1     0                 9             10   \n",
       "455839                388    27     286    110   264               660             13   \n",
       "455850                 63     5       8      3     0                11             12   \n",
       "455851                902   127     462    152   345               959             17   \n",
       "\n",
       "        friends_count  elite_years  compliments  compliment_hot  compliment_more  \\\n",
       "2                  55            0          160              12                6   \n",
       "8                  24            0            9               1                2   \n",
       "16                 35            0           76               8                2   \n",
       "19                 11            1           68               8                4   \n",
       "34                299            0            2               0                0   \n",
       "...               ...          ...          ...             ...              ...   \n",
       "455826              3            0           18               2                0   \n",
       "455827             24            3           41               2                2   \n",
       "455839            126            7          338              29                5   \n",
       "455850             99            0           13               0                0   \n",
       "455851           1221           10         2319             420               35   \n",
       "\n",
       "        compliment_profile  compliment_cute  compliment_list  compliment_note  compliment_plain  \\\n",
       "2                        0                0                0               15                39   \n",
       "8                        1                0                0                2                 2   \n",
       "16                       2                0                1               11                15   \n",
       "19                       1                0                3               14                 9   \n",
       "34                       0                0                0                1                 0   \n",
       "...                    ...              ...              ...              ...               ...   \n",
       "455826                   1                0                0                2                 4   \n",
       "455827                   0                0                0                4                 6   \n",
       "455839                   1                0                4               42                46   \n",
       "455850                   1                0                0                1                 1   \n",
       "455851                  57               17               21              114               312   \n",
       "\n",
       "        compliment_cool  compliment_writer  compliment_photos  total_ufc_count_per_year  \\\n",
       "2                    37                 14                  0                     36.15   \n",
       "8                     0                  1                  0                      7.96   \n",
       "16                    8                 15                  6                      7.70   \n",
       "19                    8                 12                  1                     12.07   \n",
       "34                    0                  1                  0                      6.41   \n",
       "...                 ...                ...                ...                       ...   \n",
       "455826                2                  5                  0                      4.98   \n",
       "455827                8                  9                  2                     12.03   \n",
       "455839               86                 34                  5                      8.01   \n",
       "455850                2                  5                  1                      5.97   \n",
       "455851              486                347                 24                     46.10   \n",
       "\n",
       "        avg_ufc_count_per_review  bus_stars  bus_review_count  is_open  city_encoded  \\\n",
       "2                           7.22        3.5                45        1           416   \n",
       "8                           2.67        4.0                70        1           147   \n",
       "16                          3.14        3.5               133        1           984   \n",
       "19                          7.09        3.5                83        0           984   \n",
       "34                          0.80        4.0               155        1           333   \n",
       "...                          ...        ...               ...      ...           ...   \n",
       "455826                      2.04        4.0                75        0           984   \n",
       "455827                      2.17        4.5               123        1           893   \n",
       "455839                      3.00        4.0              4097        1           416   \n",
       "455850                      3.16        1.0                32        1           622   \n",
       "455851                     11.32        3.0               591        1           416   \n",
       "\n",
       "        log_affinity_score  log_amp_affinity_score  Cluster  \n",
       "2                     0.44                    4.41        0  \n",
       "8                     0.44                    4.41        7  \n",
       "16                    0.44                    4.41        0  \n",
       "19                    0.44                    4.41        0  \n",
       "34                    0.44                    4.41        0  \n",
       "...                    ...                     ...      ...  \n",
       "455826                0.44                    4.41        0  \n",
       "455827                0.44                    4.41        3  \n",
       "455839                0.44                    4.41        0  \n",
       "455850                0.44                    4.41        0  \n",
       "455851                0.44                    4.41        0  \n",
       "\n",
       "[94928 rows x 34 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df['score'] != 0) & (train_df['score'] < 0)]\n",
    "test_df[(test_df['score'] != 0) & (test_df['score'] < 0)]\n",
    "\n",
    "train_df[(train_df['score'] == 0)]\n",
    "# train_df[(train_df['log_amp_affinity_score'] < 4.42)]\n",
    "# train_df[(train_df['log_affinity_score'] > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66be79de-4d9a-4d7c-817d-cf86f5a9046a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>score</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>fans</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>num_interactions</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>elite_years</th>\n",
       "      <th>compliments</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>total_ufc_count_per_year</th>\n",
       "      <th>avg_ufc_count_per_review</th>\n",
       "      <th>bus_stars</th>\n",
       "      <th>bus_review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>city_encoded</th>\n",
       "      <th>log_affinity_score</th>\n",
       "      <th>binary_affinity_score</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HzhIRYj_MHSyzer02AOBLA</td>\n",
       "      <td>DgE8JqFcYgp2SrjSKb3Gsg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.42e-03</td>\n",
       "      <td>3.76</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4.5</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>984</td>\n",
       "      <td>-37.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DK01jsn-JcbiBamE1pB1mQ</td>\n",
       "      <td>8olG8J91NG_QU92WHG5QfA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.91e-02</td>\n",
       "      <td>4.17</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.16</td>\n",
       "      <td>3.57</td>\n",
       "      <td>4.0</td>\n",
       "      <td>663</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>-37.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>456sZ9lPis-4EliHsWtQlw</td>\n",
       "      <td>TRM0H_3uKfbenY9TFtdhHg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.86e-03</td>\n",
       "      <td>3.72</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>245</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>-37.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hc71knjnXMI9wG_Oo9hpoA</td>\n",
       "      <td>qC9ivAdl47BcZdlbW7ffLg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.75e-01</td>\n",
       "      <td>4.03</td>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "      <td>121</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>15.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>-29.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zgV0ZroIF956gw4cul8MHA</td>\n",
       "      <td>AgMBY5tKMaFnFA2S6Vf22A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.61e-01</td>\n",
       "      <td>3.90</td>\n",
       "      <td>608</td>\n",
       "      <td>151</td>\n",
       "      <td>2952</td>\n",
       "      <td>3816</td>\n",
       "      <td>2505</td>\n",
       "      <td>9273</td>\n",
       "      <td>14</td>\n",
       "      <td>523</td>\n",
       "      <td>7</td>\n",
       "      <td>2205</td>\n",
       "      <td>346</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>437</td>\n",
       "      <td>438</td>\n",
       "      <td>179</td>\n",
       "      <td>125</td>\n",
       "      <td>422.48</td>\n",
       "      <td>14.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>-19.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146990</th>\n",
       "      <td>keBv05MsMFBd0Hu98vXThQ</td>\n",
       "      <td>qEJjv2k8nDhOiYpmi_aVOw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.19e-01</td>\n",
       "      <td>4.85</td>\n",
       "      <td>470</td>\n",
       "      <td>31</td>\n",
       "      <td>2818</td>\n",
       "      <td>343</td>\n",
       "      <td>756</td>\n",
       "      <td>3917</td>\n",
       "      <td>10</td>\n",
       "      <td>427</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>143.57</td>\n",
       "      <td>5.05</td>\n",
       "      <td>3.5</td>\n",
       "      <td>530</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>-30.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146991</th>\n",
       "      <td>5ArMzPUBncPqDrB7PmZBCg</td>\n",
       "      <td>aYyj9OdH059CoEXadmldXA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.38e-01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>1.52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>-32.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146992</th>\n",
       "      <td>Fr6nMhzpaaicLsx_ZBczgg</td>\n",
       "      <td>CFtZH4Skp9z3o4ToSywI4w</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.09e+00</td>\n",
       "      <td>3.35</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>15</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>26.03</td>\n",
       "      <td>10.87</td>\n",
       "      <td>3.5</td>\n",
       "      <td>422</td>\n",
       "      <td>1</td>\n",
       "      <td>725</td>\n",
       "      <td>6.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146993</th>\n",
       "      <td>yQiFb3kzronkldMDomOAWg</td>\n",
       "      <td>pk3C3zEvBWl8Pfby1HjvUw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.78e-01</td>\n",
       "      <td>3.61</td>\n",
       "      <td>157</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.5</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "      <td>-34.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146994</th>\n",
       "      <td>nCRPCQE7E1PV83uQrIf7Cw</td>\n",
       "      <td>KcIalceIg6PSPONvLlI4-w</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.79e-01</td>\n",
       "      <td>3.49</td>\n",
       "      <td>387</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>14.38</td>\n",
       "      <td>1.31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>984</td>\n",
       "      <td>-29.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141387 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id             business_id  stars     score  average_stars  \\\n",
       "0       HzhIRYj_MHSyzer02AOBLA  DgE8JqFcYgp2SrjSKb3Gsg    4.0  3.42e-03           3.76   \n",
       "1       DK01jsn-JcbiBamE1pB1mQ  8olG8J91NG_QU92WHG5QfA    5.0  1.91e-02           4.17   \n",
       "2       456sZ9lPis-4EliHsWtQlw  TRM0H_3uKfbenY9TFtdhHg    1.0  1.86e-03           3.72   \n",
       "4       hc71knjnXMI9wG_Oo9hpoA  qC9ivAdl47BcZdlbW7ffLg    3.0  3.75e-01           4.03   \n",
       "5       zgV0ZroIF956gw4cul8MHA  AgMBY5tKMaFnFA2S6Vf22A    4.0  6.61e-01           3.90   \n",
       "...                        ...                     ...    ...       ...            ...   \n",
       "146990  keBv05MsMFBd0Hu98vXThQ  qEJjv2k8nDhOiYpmi_aVOw    5.0  3.19e-01           4.85   \n",
       "146991  5ArMzPUBncPqDrB7PmZBCg  aYyj9OdH059CoEXadmldXA    5.0  2.38e-01           3.40   \n",
       "146992  Fr6nMhzpaaicLsx_ZBczgg  CFtZH4Skp9z3o4ToSywI4w    4.0  1.09e+00           3.35   \n",
       "146993  yQiFb3kzronkldMDomOAWg  pk3C3zEvBWl8Pfby1HjvUw    2.0  1.78e-01           3.61   \n",
       "146994  nCRPCQE7E1PV83uQrIf7Cw  KcIalceIg6PSPONvLlI4-w    4.0  3.79e-01           3.49   \n",
       "\n",
       "        user_review_count  fans  useful  funny  cool  num_interactions  yelping_since  \\\n",
       "0                      37     0       4      0     0                 4              8   \n",
       "1                      98     3      44      8     4                56             14   \n",
       "2                      58     2     140     53    52               245             15   \n",
       "4                      74     9     121     16    45               182             14   \n",
       "5                     608   151    2952   3816  2505              9273             14   \n",
       "...                   ...   ...     ...    ...   ...               ...            ...   \n",
       "146990                470    31    2818    343   756              3917             10   \n",
       "146991                 77     2       0      0     0                 0             14   \n",
       "146992                 80     3      21     22    13                56             15   \n",
       "146993                157     2      12      1     1                14             10   \n",
       "146994                387    16      31     19    24                74             12   \n",
       "\n",
       "        friends_count  elite_years  compliments  compliment_hot  compliment_more  \\\n",
       "0                  40            0            3               0                0   \n",
       "1                  10            0            7               1                2   \n",
       "2                   1            0            2               0                0   \n",
       "4                  87            3           84              11                5   \n",
       "5                 523            7         2205             346               32   \n",
       "...               ...          ...          ...             ...              ...   \n",
       "146990            427            0           96               7                6   \n",
       "146991            130            0            8               0                0   \n",
       "146992             93            3           79              16                3   \n",
       "146993              6            0            3               0                1   \n",
       "146994             21            6           56               9                0   \n",
       "\n",
       "        compliment_profile  compliment_cute  compliment_list  compliment_note  compliment_plain  \\\n",
       "0                        0                0                0                0                 1   \n",
       "1                        0                0                0                0                 1   \n",
       "2                        0                0                0                0                 0   \n",
       "4                        1                0                0                7                 4   \n",
       "5                       12               15                1              182               437   \n",
       "...                    ...              ...              ...              ...               ...   \n",
       "146990                   2                0                0                6                13   \n",
       "146991                   0                0                0                3                 2   \n",
       "146992                   0                0                0                5                 8   \n",
       "146993                   0                0                0                1                 1   \n",
       "146994                   0                0                0               11                11   \n",
       "\n",
       "        compliment_cool  compliment_writer  compliment_photos  total_ufc_count_per_year  \\\n",
       "0                     0                  2                  0                      1.03   \n",
       "1                     1                  1                  0                      7.16   \n",
       "2                     0                  2                  0                      2.55   \n",
       "4                    20                 15                  1                     15.33   \n",
       "5                   438                179                125                    422.48   \n",
       "...                 ...                ...                ...                       ...   \n",
       "146990               17                  3                 25                    143.57   \n",
       "146991                0                  3                  0                      8.43   \n",
       "146992               16                 15                  0                     26.03   \n",
       "146993                0                  0                  0                      3.46   \n",
       "146994                6                 12                  1                     14.38   \n",
       "\n",
       "        avg_ufc_count_per_review  bus_stars  bus_review_count  is_open  city_encoded  \\\n",
       "0                           0.32        4.5               168        1           984   \n",
       "1                           3.57        4.0               663        1           416   \n",
       "2                           0.92        2.0                58        1           416   \n",
       "4                           5.00        3.0               114        1           155   \n",
       "5                          14.99        4.0               104        1           416   \n",
       "...                          ...        ...               ...      ...           ...   \n",
       "146990                      5.05        3.5               530        1           416   \n",
       "146991                      1.52        4.0               259        1           416   \n",
       "146992                     10.87        3.5               422        1           725   \n",
       "146993                      0.64        3.5                81        1           333   \n",
       "146994                      1.31        4.0               139        1           984   \n",
       "\n",
       "        log_affinity_score  binary_affinity_score  Cluster  \n",
       "0                   -37.77                      1        0  \n",
       "1                   -37.50                      1        0  \n",
       "2                   -37.80                      1        0  \n",
       "4                   -29.34                      1        0  \n",
       "5                   -19.05                      1        0  \n",
       "...                    ...                    ...      ...  \n",
       "146990              -30.90                      1        0  \n",
       "146991              -32.98                      1        0  \n",
       "146992                6.86                      1        0  \n",
       "146993              -34.34                      1        0  \n",
       "146994              -29.21                      1        0  \n",
       "\n",
       "[141387 rows x 34 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[(test_df['score'] > 0)]\n",
    "# test_df[(test_df['log_affinity_score'] > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e92eca7-ec5b-4de8-83c3-98a0857a49a2",
   "metadata": {},
   "source": [
    "## START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ccfe0d2-c334-4551-98a4-d6c66d48ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('cache/train_df.csv', index_col=None)\n",
    "test_df = pd.read_csv('cache/test_df.csv', index_col=None)\n",
    "val_df = pd.read_csv('cache/val_df.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a477a4-1d9d-4037-8098-3232c035b103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'business_id', 'stars', 'score', 'average_stars', 'user_review_count', 'fans',\n",
       "       'useful', 'funny', 'cool', 'num_interactions', 'yelping_since', 'friends_count',\n",
       "       'elite_years', 'compliments', 'compliment_hot', 'compliment_more', 'compliment_profile',\n",
       "       'compliment_cute', 'compliment_list', 'compliment_note', 'compliment_plain',\n",
       "       'compliment_cool', 'compliment_writer', 'compliment_photos', 'total_ufc_count_per_year',\n",
       "       'avg_ufc_count_per_review', 'bus_stars', 'bus_review_count', 'is_open', 'city_encoded',\n",
       "       'log_affinity_score', 'binary_affinity_score', 'Cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358eb26e-b7b4-4bf1-8ddb-42d6b0c94884",
   "metadata": {},
   "source": [
    "## ATTEMPT: MODEL ENSEMBLING\n",
    "\n",
    "- Large Sample Clusters: Cluster 0, 2, 4, and 3 have relatively higher sample counts ranging from about 8,189 to 559,331.\n",
    "- Moderate Sample Clusters: Clusters 7, 6, and 8 have moderate numbers ranging from about 1,961 to 2,153.\n",
    "- Small Sample Clusters: Clusters 5 and 1 are significantly smaller, with 1,332 and 82 samples, respectively.\n",
    "\n",
    "Sample counts per Cluster:\n",
    " Cluster\n",
    "0    422982\n",
    "2     12745\n",
    "4      8183\n",
    "3      6189\n",
    "7      1632\n",
    "6      1570\n",
    "8      1487\n",
    "5      1004\n",
    "1        62\n",
    "  \n",
    "**early_stopping_rounds=10**\n",
    "\n",
    "{0: 0.9826888034981346, 1: 1.014988119592079, 2: 0.8756094886713228, 3: 0.9577187369705044, 4: 0.9463867369241324, \n",
    " 5: 1.0896717324335012, 6: 0.9023332514439544, 7: 1.0593137926993073, 8: 1.0335643721328076}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f382c683-d236-490d-8170-7881afbba708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "models = {}\n",
    "rmse_scores = {}\n",
    "\n",
    "# default params, the best found on train dataset\n",
    "params = {'objective': 'reg:squarederror', 'max_depth': 7, 'n_estimators': 400, 'min_child_weight': 4, 'colsample_bytree': 0.6827530025351433, \n",
    "       'learning_rate': 0.03958467377002343, 'gamma': 0.699572436949439, 'subsample': 0.8634832107993408}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7746ecd-06b8-4451-aa4d-6f67c6b30117",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'max_depth': 7,\n",
       " 'n_estimators': 400,\n",
       " 'min_child_weight': 4,\n",
       " 'colsample_bytree': 0.6827530025351433,\n",
       " 'learning_rate': 0.03958467377002343,\n",
       " 'gamma': 0.699572436949439,\n",
       " 'subsample': 0.8634832107993408}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d48cac1-b952-45e8-b695-70b60a49f72c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Scores by Cluster: {0: 0.9826888034981346, 1: 1.014988119592079, 2: 0.8756094886713228, 3: 0.9577187369705044, 4: 0.9463867369241324, 5: 1.0896717324335012, 6: 0.9023332514439544, 7: 1.0593137926993073, 8: 1.0335643721328076}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "'''test on train and test data'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# default params, the best found on train dataset\n",
    "params = {'objective': 'reg:squarederror', 'max_depth': 7, 'n_estimators': 400, 'min_child_weight': 4, 'colsample_bytree': 0.6827530025351433, \n",
    "       'learning_rate': 0.03958467377002343, 'gamma': 0.699572436949439, 'subsample': 0.8634832107993408}\n",
    "\n",
    "for cluster in range(9):\n",
    "    train_cluster_data = train_df[train_df['Cluster'] == cluster]\n",
    "    X = train_cluster_data.drop(columns=['stars', 'user_id', 'business_id']) # , 'log_affinity_score'\n",
    "    y = train_cluster_data['stars']\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "    \n",
    "    # 使用XGBRegressor\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "    def prepare_test_data(test_df, cluster):\n",
    "        test_cluster_data = test_df[test_df['Cluster'] == cluster]\n",
    "        X_test = test_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "        y_test = test_cluster_data['stars']\n",
    "        return X_test, y_test\n",
    "\n",
    "    X_test, y_test = prepare_test_data(test_df, cluster)\n",
    "    \n",
    "    models[cluster] = model\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    rmse_scores[cluster] = rmse\n",
    "\n",
    "# 输出每个Cluster的RMSE\n",
    "print(\"RMSE Scores by Cluster:\", rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e742440-9b2c-4915-aa4b-97814e688e3d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "{0: 0.9826888034981346, 1: 1.014988119592079, 2: 0.8756094886713228, 3: 0.9577187369705044, 4: 0.9463867369241324, \n",
    " 5: 1.0896717324335012, 6: 0.9023332514439544, 7: 1.0593137926993073, 8: 1.0335643721328076}\n",
    "\n",
    "'''compare'''\n",
    "***RMSE Scores by Cluster: {0: 0.9824686714564024, 1: 1.014988119592079, 2: 0.8767446977193243, 3: 0.9585491891701624, 4: 0.9452038088353173, \n",
    "                         5: 1.0873296412466678, 6: 0.907313500532493, 7: 1.068930368341315, 8: 1.029497789897289} # original w/ rank=120, default1=0, default2=1, +log_affinity_score, test_size=0.05\n",
    "\n",
    "RMSE Scores by Cluster: {0: 0.9825338155446997, 1: 0.9901830991049633, 2: 0.8783358989800031, 3: 0.9578945444082837, 4: 0.9499816858920407, \n",
    "                         5: 1.0853201164187696, 6: 0.909600206073975, 7: 1.0549750413779833, 8: 1.0459203589186783} # original w/ rank=120, default=1, +log_affinity_score\n",
    "\n",
    "***RMSE Scores by Cluster: {0: 0.982434545359731, 1: 1.0450832466807036, 2: 0.875241570724334, 3: 0.9612956183026671, 4: 0.948474842542706, \n",
    "                         5: 1.0710061004503517, 6: 0.8998862025792799, 7: 1.0382836776951188, 8: 1.0341570676457565} # original w/ rank=120, default=1, \\log_affinity_score, test_size=0.1\n",
    "\n",
    "RMSE Scores by Cluster: {0: 0.9828531835050012, 1: 1.0450832466807036, 2: 0.8769163030877263, 3: 0.9582877665467199, 4: 0.9492225823191563, \n",
    "                         5: 1.070343649997305, 6: 0.9013046327620369, 7: 1.0499606367320111, 8: 1.0384354316973448} # default=0, \\log_affinity_score\n",
    "\n",
    "RMSE Scores by Cluster: {0: 0.9830479933504006, 1: 1.0450832466807036, 2: 0.8791304453718787, 3: 0.9629053092798874, 4: 0.948741200048593, \n",
    "                         5: 1.0707645862520345, 6: 0.9096426863912603, 7: 1.0576515429369537, 8: 1.0400421276418648} # default=1, \\log_affinity_score\n",
    "\n",
    "RMSE Scores by Cluster: {0: 0.9834585097590449, 1: 1.0561494279772126, 2: 0.8765824445741225, 3: 0.9659717158520954, 4: 0.9467519455256139, \n",
    "                         5: 1.0610768207383312, 6: 0.9046608167556579, 7: 1.039620970687066, 8: 1.0359433156935904}\n",
    "\n",
    "\n",
    "# original\n",
    "RMSE Scores by Cluster: {0: 0.9828658502650812, 2: 0.8761593887238531, 4: 0.9443702348479344, 3: 0.9689126759366788, \n",
    "1: 0.9486380392367105, 5: 1.0693467025903196, # with log_affinity_score * 50\n",
    "6: 0.9071186256407098, 7: 1.042741917361027, 8: 1.039941487282683} # original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b12259c6-5a53-4fc3-94b1-8ed835670caf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall RMSE: 0.9792850242342954\n",
      "                  user_id             business_id  stars  prediction\n",
      "0  HzhIRYj_MHSyzer02AOBLA  DgE8JqFcYgp2SrjSKb3Gsg    4.0        4.36\n",
      "1  DK01jsn-JcbiBamE1pB1mQ  8olG8J91NG_QU92WHG5QfA    5.0        4.18\n",
      "2  456sZ9lPis-4EliHsWtQlw  TRM0H_3uKfbenY9TFtdhHg    1.0        2.38\n",
      "3  4bgpE8kMw8cQCaMin_dcww  QEgvfB8OUq5_X-UURbw2DA    4.0        4.53\n",
      "4  hc71knjnXMI9wG_Oo9hpoA  qC9ivAdl47BcZdlbW7ffLg    3.0        3.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 初始化一个空列表，用于存储每个群集的预测结果DataFrame\n",
    "all_clusters_predictions = []\n",
    "\n",
    "for cluster in range(9):\n",
    "    train_cluster_data = train_df[train_df['Cluster'] == cluster]\n",
    "    X = train_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y = train_cluster_data['stars']\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "    test_cluster_data = test_df[test_df['Cluster'] == cluster]\n",
    "    X_test = test_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y_test = test_cluster_data['stars']\n",
    "    \n",
    "    # 使用XGBRegressor\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=False)\n",
    "    \n",
    "    models[cluster] = model\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # 创建预测结果的DataFrame\n",
    "    temp_df = pd.DataFrame({\n",
    "        'user_id': test_cluster_data['user_id'],\n",
    "        'business_id': test_cluster_data['business_id'],\n",
    "        'stars': y_test,\n",
    "        'prediction': predictions\n",
    "    })\n",
    "    all_clusters_predictions.append(temp_df)\n",
    "\n",
    "# 将所有群集的预测结果合并成一个DataFrame\n",
    "all_predictions = pd.concat(all_clusters_predictions, ignore_index=True)\n",
    "all_predictions['prediction'] = all_predictions['prediction'].clip(lower=1, upper=5)\n",
    "\n",
    "# 计算整个DataFrame的RMSE\n",
    "overall_rmse = np.sqrt(mean_squared_error(all_predictions['stars'], all_predictions['prediction']))\n",
    "print(\"Overall RMSE:\", overall_rmse)\n",
    "\n",
    "# 输出合并后的DataFrame\n",
    "print(all_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dec626e-bac0-4986-b282-b1a26634e916",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts per Cluster:\n",
      " Cluster\n",
      "0    136349\n",
      "2      4136\n",
      "4      2653\n",
      "3      2000\n",
      "7       521\n",
      "6       515\n",
      "8       474\n",
      "5       328\n",
      "1        20\n",
      "Name: count, dtype: int64\n",
      "Cluster 0 - Feature Statistics:\n",
      "           stars     score  average_stars  user_review_count       fans    useful      funny  \\\n",
      "count  136349.00  1.36e+05      136349.00          136349.00  136349.00  136349.0  136349.00   \n",
      "mean        3.74  3.62e-01           3.75             362.84      39.53     958.0     561.44   \n",
      "std         1.13  3.93e-01           0.39             650.91     103.65    5445.7    3922.46   \n",
      "min         1.00  0.00e+00           1.42              31.00       0.00       0.0       0.00   \n",
      "25%         3.00  6.57e-03           3.53              87.00       3.00      12.0       2.00   \n",
      "50%         4.00  2.11e-01           3.77             165.00      10.00      55.0      13.00   \n",
      "75%         5.00  6.54e-01           4.00             374.00      31.00     262.0      91.00   \n",
      "max         5.00  7.09e+00           5.00           11942.00    2255.00  201798.0  167360.00   \n",
      "\n",
      "            cool  num_interactions  yelping_since  friends_count  elite_years  compliments  \\\n",
      "count  136349.00         136349.00      136349.00      136349.00    136349.00    136349.00   \n",
      "mean      842.23           2361.67          12.47         318.89         3.06       688.88   \n",
      "std      5364.27          14310.96           2.43         663.39         2.89      3228.62   \n",
      "min         0.00              0.00           6.00           0.00         0.00         0.00   \n",
      "25%         2.00             19.00          11.00          37.00         0.00        12.00   \n",
      "50%        12.00             90.00          13.00         117.00         3.00        48.00   \n",
      "75%       109.00            489.00          14.00         296.00         5.00       232.00   \n",
      "max    207329.00         503165.00          20.00        9213.00        14.00    129627.00   \n",
      "\n",
      "       compliment_hot  compliment_more  compliment_profile  compliment_cute  compliment_list  \\\n",
      "count       136349.00        136349.00           136349.00        136349.00        136349.00   \n",
      "mean            86.79            10.63                8.36             5.92             3.80   \n",
      "std            510.78            58.73               77.40            67.11            38.19   \n",
      "min              0.00             0.00                0.00             0.00             0.00   \n",
      "25%              1.00             0.00                0.00             0.00             0.00   \n",
      "50%              4.00             1.00                0.00             0.00             0.00   \n",
      "75%             26.00             5.00                2.00             1.00             1.00   \n",
      "max          21389.00          2475.00             2746.00          2250.00          1305.00   \n",
      "\n",
      "       compliment_note  compliment_plain  compliment_cool  compliment_writer  compliment_photos  \\\n",
      "count        136349.00         136349.00        136349.00          136349.00          136349.00   \n",
      "mean             55.98            141.35           132.90              51.51              58.74   \n",
      "std             214.17            618.20           600.03             232.33             507.10   \n",
      "min               0.00              0.00             0.00               0.00               0.00   \n",
      "25%               2.00              2.00             2.00               1.00               0.00   \n",
      "50%               6.00              8.00             8.00               5.00               2.00   \n",
      "75%              25.00             40.00            46.00              26.00              10.00   \n",
      "max            7280.00          15897.00         18664.00            7972.00           37415.00   \n",
      "\n",
      "       total_ufc_count_per_year  avg_ufc_count_per_review  bus_stars  bus_review_count    is_open  \\\n",
      "count                 136349.00                 136349.00  136349.00         136349.00  136349.00   \n",
      "mean                      73.80                      4.82       3.73            423.30       0.87   \n",
      "std                      279.35                      8.04       0.59            737.38       0.33   \n",
      "min                        0.00                      0.00       1.00             30.00       0.00   \n",
      "25%                        5.80                      1.44       3.50             81.00       1.00   \n",
      "50%                       13.67                      2.69       4.00            181.00       1.00   \n",
      "75%                       41.11                      5.15       4.00            422.00       1.00   \n",
      "max                     3930.74                    415.25       5.00           7968.00       1.00   \n",
      "\n",
      "       city_encoded  log_affinity_score  binary_affinity_score   Cluster  \n",
      "count     136349.00           136349.00              136349.00  136349.0  \n",
      "mean         525.84                4.36                   0.78       0.0  \n",
      "std          259.39              545.72                   0.42       0.0  \n",
      "min            0.00              -21.06                   0.00       0.0  \n",
      "25%          416.00              -20.82                   1.00       0.0  \n",
      "50%          416.00              -12.41                   1.00       0.0  \n",
      "75%          632.00               15.15                   1.00       0.0  \n",
      "max         1108.00           191129.20                   1.00       0.0  \n",
      "\n",
      "Cluster 1 - Feature Statistics:\n",
      "       stars  score  average_stars  user_review_count  fans  useful  funny  cool  \\\n",
      "count  20.00   20.0       2.00e+01               20.0  20.0    20.0   20.0  20.0   \n",
      "mean    3.90    0.0       3.80e+00              175.0   4.0     0.0    0.0   0.0   \n",
      "std     1.02    0.0       4.56e-16                0.0   0.0     0.0    0.0   0.0   \n",
      "min     1.00    0.0       3.80e+00              175.0   4.0     0.0    0.0   0.0   \n",
      "25%     4.00    0.0       3.80e+00              175.0   4.0     0.0    0.0   0.0   \n",
      "50%     4.00    0.0       3.80e+00              175.0   4.0     0.0    0.0   0.0   \n",
      "75%     4.25    0.0       3.80e+00              175.0   4.0     0.0    0.0   0.0   \n",
      "max     5.00    0.0       3.80e+00              175.0   4.0     0.0    0.0   0.0   \n",
      "\n",
      "       num_interactions  yelping_since  friends_count  elite_years  compliments  compliment_hot  \\\n",
      "count              20.0           20.0           20.0         20.0         20.0            20.0   \n",
      "mean                0.0           13.0           11.0          3.0         17.0             0.0   \n",
      "std                 0.0            0.0            0.0          0.0          0.0             0.0   \n",
      "min                 0.0           13.0           11.0          3.0         17.0             0.0   \n",
      "25%                 0.0           13.0           11.0          3.0         17.0             0.0   \n",
      "50%                 0.0           13.0           11.0          3.0         17.0             0.0   \n",
      "75%                 0.0           13.0           11.0          3.0         17.0             0.0   \n",
      "max                 0.0           13.0           11.0          3.0         17.0             0.0   \n",
      "\n",
      "       compliment_more  compliment_profile  compliment_cute  compliment_list  compliment_note  \\\n",
      "count             20.0                20.0             20.0             20.0             20.0   \n",
      "mean               2.0                 0.0              0.0              0.0              4.0   \n",
      "std                0.0                 0.0              0.0              0.0              0.0   \n",
      "min                2.0                 0.0              0.0              0.0              4.0   \n",
      "25%                2.0                 0.0              0.0              0.0              4.0   \n",
      "50%                2.0                 0.0              0.0              0.0              4.0   \n",
      "75%                2.0                 0.0              0.0              0.0              4.0   \n",
      "max                2.0                 0.0              0.0              0.0              4.0   \n",
      "\n",
      "       compliment_plain  compliment_cool  compliment_writer  compliment_photos  \\\n",
      "count              20.0             20.0               20.0               20.0   \n",
      "mean                8.0              0.0                3.0                0.0   \n",
      "std                 0.0              0.0                0.0                0.0   \n",
      "min                 8.0              0.0                3.0                0.0   \n",
      "25%                 8.0              0.0                3.0                0.0   \n",
      "50%                 8.0              0.0                3.0                0.0   \n",
      "75%                 8.0              0.0                3.0                0.0   \n",
      "max                 8.0              0.0                3.0                0.0   \n",
      "\n",
      "       total_ufc_count_per_year  avg_ufc_count_per_review  bus_stars  bus_review_count  is_open  \\\n",
      "count                  2.00e+01                  2.00e+01      20.00             20.00     20.0   \n",
      "mean                   1.23e+01                  1.69e+00       3.83            144.10      1.0   \n",
      "std                    1.82e-15                  2.28e-16       0.52             94.45      0.0   \n",
      "min                    1.23e+01                  1.69e+00       2.50             33.00      1.0   \n",
      "25%                    1.23e+01                  1.69e+00       3.50             70.50      1.0   \n",
      "50%                    1.23e+01                  1.69e+00       4.00            108.00      1.0   \n",
      "75%                    1.23e+01                  1.69e+00       4.00            230.00      1.0   \n",
      "max                    1.23e+01                  1.69e+00       4.50            349.00      1.0   \n",
      "\n",
      "       city_encoded  log_affinity_score  binary_affinity_score  Cluster  \n",
      "count          20.0            2.00e+01                   20.0     20.0  \n",
      "mean          222.3           -2.11e+01                    0.0      1.0  \n",
      "std            98.6            3.65e-15                    0.0      0.0  \n",
      "min           155.0           -2.11e+01                    0.0      1.0  \n",
      "25%           155.0           -2.11e+01                    0.0      1.0  \n",
      "50%           169.0           -2.11e+01                    0.0      1.0  \n",
      "75%           325.0           -2.11e+01                    0.0      1.0  \n",
      "max           481.0           -2.11e+01                    0.0      1.0  \n",
      "\n",
      "Cluster 2 - Feature Statistics:\n",
      "         stars    score  average_stars  user_review_count     fans    useful     funny      cool  \\\n",
      "count  4136.00  4136.00        4136.00            4136.00  4136.00   4136.00   4136.00   4136.00   \n",
      "mean      3.79     0.40           3.83             404.56    38.60    728.21    210.59    621.93   \n",
      "std       1.01     0.40           0.29             338.63    82.37   2294.32   1078.23   2038.36   \n",
      "min       1.00     0.00           2.58              36.00     0.00      0.00      0.00      0.00   \n",
      "25%       3.00     0.01           3.64             155.00     7.00     30.00      5.00      6.00   \n",
      "50%       4.00     0.29           3.83             276.50    17.00     98.50     22.00     24.00   \n",
      "75%       5.00     0.69           4.02             565.00    32.00    412.00     71.00    168.75   \n",
      "max       5.00     4.97           4.68            1579.00   506.00  36994.00  20855.00  21042.00   \n",
      "\n",
      "       num_interactions  yelping_since  friends_count  elite_years  compliments  compliment_hot  \\\n",
      "count           4136.00        4136.00        4136.00      4136.00      4136.00         4136.00   \n",
      "mean            1560.72          12.22         384.73         4.10       498.02           55.78   \n",
      "std             5098.08           2.09         693.55         2.27      1122.07          133.41   \n",
      "min                0.00           7.00           0.00         0.00         0.00            0.00   \n",
      "25%               42.00          11.00          76.00         3.00        32.00            4.00   \n",
      "50%              161.00          12.00         165.00         4.00       122.00           15.00   \n",
      "75%              671.00          13.00         295.00         6.00       248.00           38.00   \n",
      "max            78891.00          19.00        3900.00         8.00      5818.00         1140.00   \n",
      "\n",
      "       compliment_more  compliment_profile  compliment_cute  compliment_list  compliment_note  \\\n",
      "count          4136.00             4136.00          4136.00          4136.00          4136.00   \n",
      "mean              7.67                4.59             1.76             1.34            47.21   \n",
      "std              12.99                9.24             5.12             3.26           121.84   \n",
      "min               0.00                0.00             0.00             0.00             0.00   \n",
      "25%               1.00                0.00             0.00             0.00             2.00   \n",
      "50%               3.00                1.00             0.00             0.00            11.00   \n",
      "75%               7.00                3.00             1.00             1.00            21.00   \n",
      "max             105.00               56.00            29.00            16.00           704.00   \n",
      "\n",
      "       compliment_plain  compliment_cool  compliment_writer  compliment_photos  \\\n",
      "count           4136.00          4136.00            4136.00            4136.00   \n",
      "mean             130.72            95.05              37.20              21.67   \n",
      "std              409.76           198.86              65.69              58.79   \n",
      "min                0.00             0.00               0.00               0.00   \n",
      "25%                6.00             6.00               4.00               0.00   \n",
      "50%               17.00            24.00              15.00               2.00   \n",
      "75%               44.00            53.50              37.00              15.00   \n",
      "max             2493.00          1187.00             300.00             605.00   \n",
      "\n",
      "       total_ufc_count_per_year  avg_ufc_count_per_review  bus_stars  bus_review_count  is_open  \\\n",
      "count                   4136.00                   4136.00    4136.00           4136.00   4136.0   \n",
      "mean                      66.28                      5.09       3.76            203.14      0.9   \n",
      "std                      117.40                      6.20       0.58            328.88      0.3   \n",
      "min                        0.46                      0.16       1.00             30.00      0.0   \n",
      "25%                       11.25                      1.82       3.50             64.00      1.0   \n",
      "50%                       23.90                      3.17       4.00            118.00      1.0   \n",
      "75%                       60.81                      5.45       4.00            220.00      1.0   \n",
      "max                      550.42                     43.71       5.00           7866.00      1.0   \n",
      "\n",
      "       city_encoded  log_affinity_score  binary_affinity_score  Cluster  \n",
      "count       4136.00             4136.00                4136.00   4136.0  \n",
      "mean         667.72                7.79                   0.78      2.0  \n",
      "std          180.64              215.70                   0.41      0.0  \n",
      "min           12.00              -21.06                   0.00      2.0  \n",
      "25%          725.00              -20.57                   1.00      2.0  \n",
      "50%          725.00               -8.37                   1.00      2.0  \n",
      "75%          725.00               18.48                   1.00      2.0  \n",
      "max         1085.00            13640.07                   1.00      2.0  \n",
      "\n",
      "Cluster 3 - Feature Statistics:\n",
      "         stars    score  average_stars  user_review_count     fans    useful     funny      cool  \\\n",
      "count  2000.00  2000.00        2000.00            2000.00  2000.00   2000.00   2000.00   2000.00   \n",
      "mean      3.83     0.43           3.83             496.57    67.55   1866.99    896.40   2064.50   \n",
      "std       1.09     0.39           0.36             624.87   166.40   6220.46   4583.81   8453.08   \n",
      "min       1.00     0.00           1.96              35.00     0.00      0.00      0.00      0.00   \n",
      "25%       3.00     0.03           3.68             132.00     8.00     17.00      3.00      3.00   \n",
      "50%       4.00     0.36           3.86             333.00    25.00     96.00     24.00     20.00   \n",
      "75%       5.00     0.77           3.98             601.00    53.00    352.00     92.00    123.00   \n",
      "max       5.00     2.26           4.70            4459.00   936.00  34389.00  30289.00  62122.00   \n",
      "\n",
      "       num_interactions  yelping_since  friends_count  elite_years  compliments  compliment_hot  \\\n",
      "count           2000.00        2000.00        2000.00      2000.00      2000.00         2000.00   \n",
      "mean            4827.89          13.23         451.96         4.58       416.27           39.79   \n",
      "std            17649.58           2.32        1064.81         3.00       974.46           85.23   \n",
      "min                0.00           6.00           0.00         0.00         0.00            0.00   \n",
      "25%               34.00          12.00          50.00         3.00        34.00            1.00   \n",
      "50%              184.00          13.00         149.00         4.00        90.00           12.00   \n",
      "75%              597.00          15.00         311.75         7.00       311.00           40.00   \n",
      "max            97350.00          18.00        6014.00        12.00      4710.00          543.00   \n",
      "\n",
      "       compliment_more  compliment_profile  compliment_cute  compliment_list  compliment_note  \\\n",
      "count          2000.00             2000.00          2000.00          2000.00          2000.00   \n",
      "mean              9.24                3.55             3.59             3.12            46.99   \n",
      "std              12.42                7.75            10.35             9.22           113.82   \n",
      "min               0.00                0.00             0.00             0.00             0.00   \n",
      "25%               3.00                0.00             0.00             0.00             5.00   \n",
      "50%               6.00                1.00             0.00             0.00            11.00   \n",
      "75%              12.00                4.00             2.00             2.00            31.00   \n",
      "max              71.00               55.00            56.00            64.00           641.00   \n",
      "\n",
      "       compliment_plain  compliment_cool  compliment_writer  compliment_photos  \\\n",
      "count           2000.00          2000.00            2000.00            2000.00   \n",
      "mean             126.67            67.65              34.33              13.68   \n",
      "std              358.04           160.61              61.94              33.56   \n",
      "min                0.00             0.00               0.00               0.00   \n",
      "25%                4.00             6.00               5.00               0.00   \n",
      "50%               14.00            16.00              14.00               3.00   \n",
      "75%               54.00            53.00              43.00               8.00   \n",
      "max             1604.00           927.00             330.00             147.00   \n",
      "\n",
      "       total_ufc_count_per_year  avg_ufc_count_per_review  bus_stars  bus_review_count  is_open  \\\n",
      "count                   2000.00                   2000.00    2000.00           2000.00  2000.00   \n",
      "mean                      47.46                      4.31       3.78            193.59     0.88   \n",
      "std                       61.99                      4.11       0.57            356.86     0.33   \n",
      "min                        1.40                      0.44       1.50             31.00     0.00   \n",
      "25%                        9.23                      1.87       3.50             60.00     1.00   \n",
      "50%                       19.74                      2.95       4.00            105.50     1.00   \n",
      "75%                       63.64                      4.30       4.00            193.00     1.00   \n",
      "max                      309.54                     30.57       5.00           5382.00     1.00   \n",
      "\n",
      "       city_encoded  log_affinity_score  binary_affinity_score  Cluster  \n",
      "count       2000.00             2000.00                 2000.0   2000.0  \n",
      "mean         380.36                5.69                    0.8      3.0  \n",
      "std          316.66               31.12                    0.4      0.0  \n",
      "min           14.00              -21.06                    0.0      3.0  \n",
      "25%          175.00              -19.81                    1.0      3.0  \n",
      "50%          175.00               -4.80                    1.0      3.0  \n",
      "75%          511.00               24.91                    1.0      3.0  \n",
      "max         1085.00              425.69                    1.0      3.0  \n",
      "\n",
      "Cluster 4 - Feature Statistics:\n",
      "         stars     score  average_stars  user_review_count     fans   useful    funny     cool  \\\n",
      "count  2653.00  2.65e+03        2653.00            2653.00  2653.00  2653.00  2653.00  2653.00   \n",
      "mean      3.81  3.95e-01           3.83             342.93    28.59   542.65   222.36   311.71   \n",
      "std       1.06  4.03e-01           0.33             296.21    30.30  1196.74   647.70   852.66   \n",
      "min       1.00  0.00e+00           2.63              45.00     0.00     0.00     0.00     0.00   \n",
      "25%       3.00  9.97e-03           3.61             151.00     7.00    25.00     6.00     5.00   \n",
      "50%       4.00  2.83e-01           3.84             229.00    17.00   122.00    29.00    30.00   \n",
      "75%       5.00  7.08e-01           4.06             412.00    38.00   484.00   153.00   262.00   \n",
      "max       5.00  3.68e+00           4.57            1214.00   152.00  7446.00  4492.00  9910.00   \n",
      "\n",
      "       num_interactions  yelping_since  friends_count  elite_years  compliments  compliment_hot  \\\n",
      "count           2653.00        2653.00        2653.00      2653.00      2653.00         2653.00   \n",
      "mean            1076.72          12.47         190.17         3.95       222.32           24.70   \n",
      "std             2240.87           2.21         278.62         2.47       374.69           49.67   \n",
      "min                0.00           7.00           0.00         0.00         0.00            0.00   \n",
      "25%               46.00          11.00          38.00         2.00        33.00            2.00   \n",
      "50%              193.00          13.00         115.00         4.00        87.00           11.00   \n",
      "75%              922.00          14.00         238.00         6.00       243.00           30.00   \n",
      "max            12598.00          16.00        2664.00         9.00      1953.00          433.00   \n",
      "\n",
      "       compliment_more  compliment_profile  compliment_cute  compliment_list  compliment_note  \\\n",
      "count          2653.00             2653.00          2653.00          2653.00          2653.00   \n",
      "mean              6.80                1.34             1.36             0.74            26.89   \n",
      "std               6.24                2.41             2.78             1.92            54.02   \n",
      "min               0.00                0.00             0.00             0.00             0.00   \n",
      "25%               3.00                0.00             0.00             0.00             6.00   \n",
      "50%               5.00                0.00             0.00             0.00            11.00   \n",
      "75%               9.00                1.00             2.00             1.00            25.00   \n",
      "max              29.00               11.00            20.00            15.00           331.00   \n",
      "\n",
      "       compliment_plain  compliment_cool  compliment_writer  compliment_photos  \\\n",
      "count           2653.00          2653.00            2653.00            2653.00   \n",
      "mean              39.80            40.72              24.54              14.71   \n",
      "std               77.47            73.01              30.23              32.21   \n",
      "min                0.00             0.00               0.00               0.00   \n",
      "25%                4.00             5.00               6.00               0.00   \n",
      "50%               11.00            14.00              15.00               2.00   \n",
      "75%               39.00            42.00              32.00               9.00   \n",
      "max              477.00           390.00             189.00             270.00   \n",
      "\n",
      "       total_ufc_count_per_year  avg_ufc_count_per_review  bus_stars  bus_review_count  is_open  \\\n",
      "count                   2653.00                   2653.00    2653.00           2653.00  2653.00   \n",
      "mean                      56.24                      4.45       3.80            204.58     0.89   \n",
      "std                       88.59                      3.14       0.56            447.29     0.31   \n",
      "min                        1.68                      0.52       1.50             30.00     0.00   \n",
      "25%                       11.64                      2.19       3.50             58.00     1.00   \n",
      "50%                       25.19                      3.75       4.00            106.00     1.00   \n",
      "75%                       47.34                      6.13       4.00            210.00     1.00   \n",
      "max                      390.21                     14.97       5.00           7968.00     1.00   \n",
      "\n",
      "       city_encoded  log_affinity_score  binary_affinity_score  Cluster  \n",
      "count       2653.00             2653.00                2653.00   2653.0  \n",
      "mean         393.42                5.19                   0.78      4.0  \n",
      "std          297.60               64.36                   0.41      0.0  \n",
      "min           14.00              -21.06                   0.00      4.0  \n",
      "25%          175.00              -20.70                   1.00      4.0  \n",
      "50%          270.00               -8.87                   1.00      4.0  \n",
      "75%          624.00               19.64                   1.00      4.0  \n",
      "max         1085.00             2736.32                   1.00      4.0  \n",
      "\n",
      "Cluster 5 - Feature Statistics:\n",
      "        stars   score  average_stars  user_review_count    fans    useful     funny      cool  \\\n",
      "count  328.00  328.00         328.00             328.00  328.00    328.00    328.00    328.00   \n",
      "mean     3.72    0.40           3.70             659.25   69.55   4628.50   3409.66   4014.04   \n",
      "std      1.15    0.38           0.27             403.10  114.10   8028.25   7019.09   7975.63   \n",
      "min      1.00    0.00           3.09              49.00    0.00      0.00      0.00      0.00   \n",
      "25%      3.00    0.06           3.48             215.75   10.00     81.00      7.75     13.00   \n",
      "50%      4.00    0.31           3.80             742.00   20.00    131.00     23.00     54.00   \n",
      "75%      5.00    0.67           3.84             918.00   79.00   8130.00   4375.00   5009.00   \n",
      "max      5.00    1.85           4.32            1337.00  384.00  24716.00  22611.00  25053.00   \n",
      "\n",
      "       num_interactions  yelping_since  friends_count  elite_years  compliments  compliment_hot  \\\n",
      "count            328.00         328.00         328.00       328.00       328.00          328.00   \n",
      "mean           12052.20          12.33         706.62         4.23       635.61           60.42   \n",
      "std            22912.05           2.53        1588.04         2.89       811.71           87.15   \n",
      "min                0.00           8.00           0.00         0.00         1.00            0.00   \n",
      "25%              124.00          10.00          41.00         2.00        31.00            2.50   \n",
      "50%              180.00          12.00         169.00         4.00       114.00            5.00   \n",
      "75%            17514.00          15.00         283.00         5.00      1301.00           97.75   \n",
      "max            72380.00          16.00        5213.00         9.00      2080.00          252.00   \n",
      "\n",
      "       compliment_more  compliment_profile  compliment_cute  compliment_list  compliment_note  \\\n",
      "count           328.00              328.00           328.00           328.00           328.00   \n",
      "mean             15.02                8.83             2.13             1.00            59.52   \n",
      "std              22.27               11.16             2.97             1.81            67.40   \n",
      "min               0.00                0.00             0.00             0.00             0.00   \n",
      "25%               1.00                1.00             0.00             0.00             5.75   \n",
      "50%               7.00                2.00             1.00             0.00            23.00   \n",
      "75%              17.50               11.75             3.00             1.00           150.00   \n",
      "max              68.00               32.00             8.00             5.00           164.00   \n",
      "\n",
      "       compliment_plain  compliment_cool  compliment_writer  compliment_photos  \\\n",
      "count            328.00           328.00             328.00             328.00   \n",
      "mean             137.35           114.26              66.21              56.60   \n",
      "std              181.91           149.76              76.69              84.16   \n",
      "min                0.00             0.00               0.00               0.00   \n",
      "25%                7.00             2.00               3.00               0.00   \n",
      "50%               32.00            14.00              13.00               1.00   \n",
      "75%              335.50           225.50             145.00             149.00   \n",
      "max              469.00           369.00             209.00             230.00   \n",
      "\n",
      "       total_ufc_count_per_year  avg_ufc_count_per_review  bus_stars  bus_review_count  is_open  \\\n",
      "count                    328.00                    328.00     328.00            328.00   328.00   \n",
      "mean                     130.79                      8.61       3.81            156.48     0.91   \n",
      "std                      197.89                     11.37       0.60            151.34     0.28   \n",
      "min                        0.70                      0.14       1.50             31.00     0.00   \n",
      "25%                       12.32                      1.41       3.50             61.75     1.00   \n",
      "50%                       19.73                      2.73       4.00            112.00     1.00   \n",
      "75%                      126.02                     11.47       4.00            205.25     1.00   \n",
      "max                      609.33                     36.69       5.00           1437.00     1.00   \n",
      "\n",
      "       city_encoded  log_affinity_score  binary_affinity_score  Cluster  \n",
      "count        328.00              328.00                 328.00    328.0  \n",
      "mean         220.92                3.94                   0.86      5.0  \n",
      "std          125.31               31.19                   0.35      0.0  \n",
      "min           59.00              -21.06                   0.00      5.0  \n",
      "25%          155.00              -18.99                   1.00      5.0  \n",
      "50%          155.00               -7.75                   1.00      5.0  \n",
      "75%          284.75               16.79                   1.00      5.0  \n",
      "max         1045.00              238.34                   1.00      5.0  \n",
      "\n",
      "Cluster 6 - Feature Statistics:\n",
      "        stars   score  average_stars  user_review_count    fans   useful    funny     cool  \\\n",
      "count  515.00  515.00         515.00             515.00  515.00   515.00   515.00   515.00   \n",
      "mean     3.85    0.48           3.84             739.24   83.15  2890.44   643.91  1443.18   \n",
      "std      0.96    0.42           0.17             391.86   78.15  3544.72   782.83  1733.98   \n",
      "min      1.00    0.00           3.39              76.00    2.00    14.00     0.00     0.00   \n",
      "25%      3.00    0.08           3.70             432.00   35.00   153.00    20.00    79.00   \n",
      "50%      4.00    0.42           3.89             748.00   45.00   326.00    58.00   252.00   \n",
      "75%      5.00    0.85           3.95             907.00  100.00  7800.00   742.00  2044.00   \n",
      "max      5.00    3.25           4.34            1450.00  247.00  8544.00  2123.00  5643.00   \n",
      "\n",
      "       num_interactions  yelping_since  friends_count  elite_years  compliments  compliment_hot  \\\n",
      "count            515.00         515.00         515.00       515.00       515.00          515.00   \n",
      "mean            4977.53          13.09         993.64         3.83      2021.33          215.02   \n",
      "std             5179.57           2.39        1202.47         2.07      2971.80          346.92   \n",
      "min               14.00           9.00           7.00         0.00         8.00            0.00   \n",
      "25%              250.00          11.00         151.00         3.00       246.00           24.00   \n",
      "50%              594.00          14.00         459.00         3.00       335.00           55.00   \n",
      "75%            11648.00          15.00        1663.00         5.00      2127.00          188.00   \n",
      "max            11967.00          18.00        3449.00         9.00      8551.00          992.00   \n",
      "\n",
      "       compliment_more  compliment_profile  compliment_cute  compliment_list  compliment_note  \\\n",
      "count           515.00              515.00           515.00           515.00           515.00   \n",
      "mean             27.65               29.19             7.65             8.06           178.58   \n",
      "std              39.48               42.62            13.08            13.25           263.93   \n",
      "min               0.00                0.00             0.00             0.00             0.00   \n",
      "25%               5.00                0.00             0.50             0.00            20.00   \n",
      "50%               9.00                5.00             2.00             0.00            29.00   \n",
      "75%              29.00               42.00             3.00            10.00           203.00   \n",
      "max             115.00              120.00            37.00            37.00           757.00   \n",
      "\n",
      "       compliment_plain  compliment_cool  compliment_writer  compliment_photos  \\\n",
      "count            515.00           515.00             515.00             515.00   \n",
      "mean             496.96           353.39             240.59             110.85   \n",
      "std              753.58           485.77             405.84             151.08   \n",
      "min                2.00             1.00               1.00               0.00   \n",
      "25%               49.00            47.00              29.00               3.00   \n",
      "50%               55.00            78.00              45.00              30.00   \n",
      "75%              712.00           419.00             176.00             268.00   \n",
      "max             2123.00          1408.00            1151.00             403.00   \n",
      "\n",
      "       total_ufc_count_per_year  avg_ufc_count_per_review  bus_stars  bus_review_count  is_open  \\\n",
      "count                    515.00                    515.00     515.00            515.00   515.00   \n",
      "mean                     292.33                     12.40       3.84            164.43     0.89   \n",
      "std                      280.56                     10.99       0.53            259.54     0.32   \n",
      "min                        4.11                      1.33       2.00             31.00     0.00   \n",
      "25%                       50.02                      3.83       3.50             56.50     1.00   \n",
      "50%                      152.91                      6.54       4.00             94.00     1.00   \n",
      "75%                      592.72                     20.32       4.00            188.00     1.00   \n",
      "max                      736.20                     32.34       5.00           3743.00     1.00   \n",
      "\n",
      "       city_encoded  log_affinity_score  binary_affinity_score  Cluster  \n",
      "count        515.00              515.00                 515.00    515.0  \n",
      "mean         649.37               12.16                   0.84      6.0  \n",
      "std          200.67               77.38                   0.37      0.0  \n",
      "min           12.00              -21.06                   0.00      6.0  \n",
      "25%          725.00              -17.91                   1.00      6.0  \n",
      "50%          725.00               -1.41                   1.00      6.0  \n",
      "75%          725.00               33.42                   1.00      6.0  \n",
      "max         1053.00             1582.99                   1.00      6.0  \n",
      "\n",
      "Cluster 7 - Feature Statistics:\n",
      "        stars     score  average_stars  user_review_count    fans   useful    funny     cool  \\\n",
      "count  521.00  5.21e+02         521.00             521.00  521.00   521.00   521.00   521.00   \n",
      "mean     3.63  2.51e-01           3.65             351.59   20.79   290.55   127.26   174.09   \n",
      "std      1.19  3.65e-01           0.39             348.89   29.46   451.35   226.96   424.07   \n",
      "min      1.00  0.00e+00           2.98              55.00    0.00     0.00     0.00     0.00   \n",
      "25%      3.00  0.00e+00           3.36             141.00    4.00    30.00     6.00     2.00   \n",
      "50%      4.00  4.79e-03           3.60             222.00    8.00   103.00    32.00    17.00   \n",
      "75%      5.00  4.14e-01           3.97             427.00   22.00   373.00   133.00   152.00   \n",
      "max      5.00  1.91e+00           4.46            1743.00  126.00  2375.00  1351.00  2207.00   \n",
      "\n",
      "       num_interactions  yelping_since  friends_count  elite_years  compliments  compliment_hot  \\\n",
      "count             521.0         521.00         521.00       521.00       521.00          521.00   \n",
      "mean              591.9          14.00         170.70         3.32       166.26           25.81   \n",
      "std              1048.4           2.71         194.12         2.63       433.93           84.82   \n",
      "min                 0.0           8.00           0.00         0.00         1.00            0.00   \n",
      "25%                44.0          11.00          43.00         2.00        15.00            1.00   \n",
      "50%               223.0          15.00         110.00         3.00        39.00            4.00   \n",
      "75%               633.0          16.00         234.00         5.00       118.00           10.00   \n",
      "max              5247.0          18.00         754.00         8.00      2447.00          451.00   \n",
      "\n",
      "       compliment_more  compliment_profile  compliment_cute  compliment_list  compliment_note  \\\n",
      "count           521.00              521.00           521.00           521.00           521.00   \n",
      "mean              5.02                1.56             4.71             2.09            17.54   \n",
      "std              12.47                3.50            20.66             7.15            48.32   \n",
      "min               0.00                0.00             0.00             0.00             0.00   \n",
      "25%               0.00                0.00             0.00             0.00             1.00   \n",
      "50%               1.00                0.00             0.00             0.00             5.00   \n",
      "75%               4.00                1.00             1.00             1.00            11.00   \n",
      "max              71.00               19.00           111.00            36.00           281.00   \n",
      "\n",
      "       compliment_plain  compliment_cool  compliment_writer  compliment_photos  \\\n",
      "count            521.00           521.00             521.00             521.00   \n",
      "mean              26.20            32.92              12.65               4.83   \n",
      "std               51.31            90.14              26.08               8.57   \n",
      "min                0.00             0.00               0.00               0.00   \n",
      "25%                3.00             2.00               1.00               0.00   \n",
      "50%                8.00             6.00               5.00               1.00   \n",
      "75%               28.00            18.00              12.00               5.00   \n",
      "max              278.00           515.00             141.00              37.00   \n",
      "\n",
      "       total_ufc_count_per_year  avg_ufc_count_per_review  bus_stars  bus_review_count  is_open  \\\n",
      "count                    521.00                    521.00     521.00            521.00   521.00   \n",
      "mean                      10.98                      3.45       3.71            173.83     0.87   \n",
      "std                       10.70                      4.02       0.54            418.99     0.34   \n",
      "min                        1.26                      0.46       1.50             31.00     0.00   \n",
      "25%                        4.89                      1.76       3.50             49.00     1.00   \n",
      "50%                        8.61                      2.57       3.50             91.00     1.00   \n",
      "75%                       13.12                      3.33       4.00            165.00     1.00   \n",
      "max                       60.80                     27.68       5.00           7968.00     1.00   \n",
      "\n",
      "       city_encoded  log_affinity_score  binary_affinity_score  Cluster  \n",
      "count        521.00              521.00                 521.00    521.0  \n",
      "mean         353.88               -5.26                   0.51      7.0  \n",
      "std          344.87               28.35                   0.50      0.0  \n",
      "min          147.00              -21.06                   0.00      7.0  \n",
      "25%          147.00              -21.06                   0.00      7.0  \n",
      "50%          147.00              -20.88                   1.00      7.0  \n",
      "75%          463.00               -1.65                   1.00      7.0  \n",
      "max         1023.00              258.05                   1.00      7.0  \n",
      "\n",
      "Cluster 8 - Feature Statistics:\n",
      "        stars   score  average_stars  user_review_count    fans   useful   funny    cool  \\\n",
      "count  474.00  474.00         474.00             474.00  474.00   474.00  474.00  474.00   \n",
      "mean     3.81    0.24           3.87             232.01   18.01   231.64   55.77   95.55   \n",
      "std      1.12    0.35           0.41             116.17   15.01   437.58  150.26  213.45   \n",
      "min      1.00    0.00           2.90              77.00    1.00     0.00    0.00    0.00   \n",
      "25%      3.00    0.00           3.56             149.00    6.00    16.00    2.00    2.00   \n",
      "50%      4.00    0.06           3.96             202.00   14.00    47.00   15.00    7.00   \n",
      "75%      5.00    0.37           4.10             287.00   23.00   297.00   36.00   32.50   \n",
      "max      5.00    1.94           4.60             510.00   61.00  2382.00  899.00  913.00   \n",
      "\n",
      "       num_interactions  yelping_since  friends_count  elite_years  compliments  compliment_hot  \\\n",
      "count            474.00         474.00         474.00       474.00       474.00          474.00   \n",
      "mean             382.97          11.75         116.08         3.45        81.03            6.08   \n",
      "std              765.09           2.59         134.19         2.48        83.05            8.50   \n",
      "min                1.00           8.00           1.00         0.00         2.00            0.00   \n",
      "25%               23.00           9.00          27.00         2.00        32.00            1.00   \n",
      "50%               67.00          12.00          48.00         3.00        48.00            2.00   \n",
      "75%              423.00          13.00         170.00         5.00       101.00            8.00   \n",
      "max             4194.00          17.00         490.00         9.00       402.00           39.00   \n",
      "\n",
      "       compliment_more  compliment_profile  compliment_cute  compliment_list  compliment_note  \\\n",
      "count           474.00              474.00           474.00           474.00           474.00   \n",
      "mean              4.70                1.19             0.14             0.32            12.72   \n",
      "std               2.89                1.69             0.34             0.98            11.68   \n",
      "min               0.00                0.00             0.00             0.00             0.00   \n",
      "25%               3.00                0.00             0.00             0.00             5.00   \n",
      "50%               5.00                1.00             0.00             0.00             9.00   \n",
      "75%               6.00                2.00             0.00             0.00            17.00   \n",
      "max              14.00                7.00             1.00             6.00            56.00   \n",
      "\n",
      "       compliment_plain  compliment_cool  compliment_writer  compliment_photos  \\\n",
      "count            474.00           474.00             474.00             474.00   \n",
      "mean              12.93            13.80              10.71               4.63   \n",
      "std               17.83            17.41               9.12               6.60   \n",
      "min                0.00             0.00               0.00               0.00   \n",
      "25%                2.00             4.00               4.00               1.00   \n",
      "50%                6.00             8.00               8.00               3.00   \n",
      "75%               15.00            16.00              15.00               6.00   \n",
      "max               77.00            85.00              37.00              28.00   \n",
      "\n",
      "       total_ufc_count_per_year  avg_ufc_count_per_review  bus_stars  bus_review_count  is_open  \\\n",
      "count                    474.00                    474.00     474.00            474.00   474.00   \n",
      "mean                      16.07                      3.07       3.76            154.34     0.93   \n",
      "std                       11.22                      1.72       0.53            294.27     0.26   \n",
      "min                        2.08                      0.67       2.00             31.00     0.00   \n",
      "25%                        7.26                      1.79       3.50             49.00     1.00   \n",
      "50%                       11.67                      2.57       4.00             89.00     1.00   \n",
      "75%                       22.14                      3.89       4.00            153.00     1.00   \n",
      "max                       38.49                     11.08       5.00           5382.00     1.00   \n",
      "\n",
      "       city_encoded  log_affinity_score  binary_affinity_score  Cluster  \n",
      "count        474.00              474.00                 474.00    474.0  \n",
      "mean         419.43               -5.61                   0.67      8.0  \n",
      "std          305.96               30.89                   0.47      0.0  \n",
      "min           29.00              -21.06                   0.00      8.0  \n",
      "25%          175.00              -21.06                   0.00      8.0  \n",
      "50%          353.00              -18.66                   1.00      8.0  \n",
      "75%          627.50               -3.94                   1.00      8.0  \n",
      "max         1085.00              269.11                   1.00      8.0  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设final_df是您的整个数据集\n",
    "# 统计每个Cluster的样本数量\n",
    "sample_counts = train_df['Cluster'].value_counts()\n",
    "print(\"Sample counts per Cluster:\\n\", sample_counts)\n",
    "\n",
    "# 分析特征分布\n",
    "feature_analysis = {}\n",
    "for cluster in range(9):\n",
    "    cluster_data = train_df[train_df['Cluster'] == cluster]\n",
    "    feature_description = cluster_data.describe()\n",
    "    feature_analysis[cluster] = feature_description\n",
    "\n",
    "# 打印出每个Cluster的描述统计，查看是否有异常值或分布不平衡\n",
    "for cluster, description in feature_analysis.items():\n",
    "    print(f\"Cluster {cluster} - Feature Statistics:\\n{description}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53581e3b-eeb8-4b68-84dc-43d0ebcc740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts per Cluster:\n",
      " Cluster\n",
      "0    422982\n",
      "2     12745\n",
      "4      8183\n",
      "3      6189\n",
      "7      1632\n",
      "6      1570\n",
      "8      1487\n",
      "5      1004\n",
      "1        62\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sample_counts = train_df['Cluster'].value_counts()\n",
    "print(\"Sample counts per Cluster:\\n\", sample_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f186b9-22e0-47cd-889f-6cc4f3796bc2",
   "metadata": {},
   "source": [
    "## APPROACH 1: FOR EACH CLUSTER, BUILD A MODEL to get params and best-suited model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ed118-fd7c-43c4-8e3b-b11a5eb719b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# search_spaces = {\n",
    "#     'max_depth': Integer(7, 9),\n",
    "#     'learning_rate': Real(0.029, 0.035, 'uniform'),\n",
    "#     'n_estimators': Integer(470, 490),\n",
    "#     'subsample': Real(0.87, 0.93),\n",
    "#     'colsample_bytree': Real(0.58, 0.61),\n",
    "#     'gamma': Real(0.34, 0.40),\n",
    "#     'max_leaves': Integer(118, 126)\n",
    "# }\n",
    "# 最佳参数: OrderedDict([('colsample_bytree', 0.6000253271077364), \n",
    "#                    ('gamma', 0.3476073435753331), \n",
    "#                    ('learning_rate', 0.03186356519406673), \n",
    "#                    ('max_depth', 8), \n",
    "#                    ('n_estimators', 480), \n",
    "#                    ('subsample', 0.8831766281686719)]) \n",
    "# 最终测试集上的RMSE: 0.9472496841333367"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d979902-32f2-4340-b05a-e899c01dfb98",
   "metadata": {},
   "source": [
    "### Large Sample Clusters (0, 2, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eef76d7-ee96-4f1f-8858-26612f485539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:06<00:00,  4.93s/trial, best loss: 0.9822613434809238]\n",
      "Cluster 0 - 最佳参数: {'colsample_bytree': 0.5693794662243868, 'gamma': 0.3540225200080566, 'learning_rate': 0.03264647132113966, 'max_depth': 1, 'max_leaves': 1, 'n_estimators': 15, 'subsample': 0.8806235635005766}\n",
      "Cluster 0 - 最终测试集上的RMSE: 0.9822613434809238\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:46<00:00,  1.08trial/s, best loss: 0.8782371474956998]\n",
      "Cluster 2 - 最佳参数: {'colsample_bytree': 0.5637401106046143, 'gamma': 0.3516260477605038, 'learning_rate': 0.02015222693767021, 'max_depth': 0, 'max_leaves': 7, 'n_estimators': 8, 'subsample': 0.9177283905231816}\n",
      "Cluster 2 - 最终测试集上的RMSE: 0.8782371474956998\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:37<00:00,  1.33trial/s, best loss: 0.9525948864939566]\n",
      "Cluster 4 - 最佳参数: {'colsample_bytree': 0.572677235386876, 'gamma': 0.3699412832566138, 'learning_rate': 0.020089156079416262, 'max_depth': 0, 'max_leaves': 3, 'n_estimators': 21, 'subsample': 0.8960898111959485}\n",
      "Cluster 4 - 最终测试集上的RMSE: 0.9525948864939566\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:32<00:00,  1.52trial/s, best loss: 0.9653257503823441]\n",
      "Cluster 3 - 最佳参数: {'colsample_bytree': 0.5965603123316021, 'gamma': 0.36682709278681697, 'learning_rate': 0.02170349006009854, 'max_depth': 0, 'max_leaves': 3, 'n_estimators': 60, 'subsample': 0.8704476894799581}\n",
      "Cluster 3 - 最终测试集上的RMSE: 0.9653257503823441\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# params = {'objective': 'reg:squarederror', 'max_depth': 7, 'n_estimators': 400, 'min_child_weight': 4, 'colsample_bytree': 0.6827530025351433, \n",
    "#        'learning_rate': 0.03958467377002343, 'gamma': 0.699572436949439, 'subsample': 0.8634832107993408}\n",
    "\n",
    "# 定义搜索空间\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(6, 12)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(390, 410, 10)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', range(3, 7)),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.60, 0.70),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.02, 0.04),\n",
    "    'gamma': hp.uniform('gamma', 0.60, 0.70),\n",
    "    'subsample': hp.uniform('subsample', 0.84, 0.88)\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    model = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        max_depth=int(params['max_depth']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        gamma=params['gamma'],\n",
    "        max_leaves=int(params['max_leaves'])\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "best_models = {}\n",
    "rmse_scores = {}\n",
    "\n",
    "for cluster in [0, 2, 4, 3]:\n",
    "    train_cluster_data = final_df[final_df['Cluster'] == cluster]\n",
    "    X_train = train_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y_train = train_cluster_data['stars']\n",
    "    \n",
    "    val_cluster_data = val_df[val_df['Cluster'] == cluster]\n",
    "    X_val = val_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y_val = val_cluster_data['stars']\n",
    "\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=search_spaces,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=50,  # 可以根据需要调整迭代次数\n",
    "        trials=trials\n",
    "    )\n",
    "    \n",
    "    best_model = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        max_depth=range(7, 10)[best['max_depth']],\n",
    "        learning_rate=best['learning_rate'],\n",
    "        n_estimators=range(420, 481)[best['n_estimators']],\n",
    "        subsample=best['subsample'],\n",
    "        colsample_bytree=best['colsample_bytree'],\n",
    "        gamma=best['gamma'],\n",
    "        max_leaves=range(118, 127)[best['max_leaves']]\n",
    "    )\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    final_rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "    best_models[cluster] = best_model\n",
    "    rmse_scores[cluster] = final_rmse\n",
    "\n",
    "    print(f\"Cluster {cluster} - 最佳参数: {best}\")\n",
    "    print(f\"Cluster {cluster} - 最终测试集上的RMSE: {final_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50f00dd-c8ba-435c-aee0-1e50bf604872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE Scores by Cluster: {0: 0.9822314440754664, 1: 0.9332088716462881, 2: 0.8751002637935721, 3: 0.9574858709357046, 4: 0.9404585183198316, \n",
    "#                          5: 1.0846576627248898, 6: 0.8896547222491545, 7: 1.0397995259518373, 8: 1.0388345770749272}\n",
    "\n",
    "# # default params, the best found on train dataset\n",
    "# params = {'objective': 'reg:squarederror', 'max_depth': 7, 'n_estimators': 400, \n",
    "#           'min_child_weight': 4, 'colsample_bytree': 0.6827530025351433, \n",
    "#        'learning_rate': 0.03958467377002343, 'gamma': 0.699572436949439, 'subsample': 0.8634832107993408}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcc027-ae99-4224-a103-f1f32bae2eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99d13c02-d367-47aa-8fd5-2062219c6ebb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-0.9508  \u001b[0m | \u001b[0m0.08749  \u001b[0m | \u001b[0m5.951    \u001b[0m | \u001b[0m301.2    \u001b[0m | \u001b[0m0.7993   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-0.9503  \u001b[0m | \u001b[95m0.08312  \u001b[0m | \u001b[95m5.156    \u001b[0m | \u001b[95m254.1    \u001b[0m | \u001b[95m0.9331   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-0.9519  \u001b[0m | \u001b[0m0.09202  \u001b[0m | \u001b[0m5.708    \u001b[0m | \u001b[0m251.4    \u001b[0m | \u001b[0m0.985    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-0.9518  \u001b[0m | \u001b[0m0.09665  \u001b[0m | \u001b[0m5.212    \u001b[0m | \u001b[0m262.7    \u001b[0m | \u001b[0m0.5917   \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-0.9495  \u001b[0m | \u001b[95m0.08608  \u001b[0m | \u001b[95m5.525    \u001b[0m | \u001b[95m280.2    \u001b[0m | \u001b[95m0.6456   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-0.9501  \u001b[0m | \u001b[0m0.09224  \u001b[0m | \u001b[0m5.139    \u001b[0m | \u001b[0m270.5    \u001b[0m | \u001b[0m0.6832   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-0.9542  \u001b[0m | \u001b[0m0.08912  \u001b[0m | \u001b[0m5.785    \u001b[0m | \u001b[0m264.0    \u001b[0m | \u001b[0m0.7571   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-0.9557  \u001b[0m | \u001b[0m0.09185  \u001b[0m | \u001b[0m5.046    \u001b[0m | \u001b[0m292.5    \u001b[0m | \u001b[0m0.5853   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-0.9518  \u001b[0m | \u001b[0m0.0813   \u001b[0m | \u001b[0m5.949    \u001b[0m | \u001b[0m317.6    \u001b[0m | \u001b[0m0.9042   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-0.9539  \u001b[0m | \u001b[0m0.08609  \u001b[0m | \u001b[0m5.098    \u001b[0m | \u001b[0m297.9    \u001b[0m | \u001b[0m0.7201   \u001b[0m |\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m-0.9493  \u001b[0m | \u001b[95m0.08244  \u001b[0m | \u001b[95m5.495    \u001b[0m | \u001b[95m252.4    \u001b[0m | \u001b[95m0.9547   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-0.9509  \u001b[0m | \u001b[0m0.08518  \u001b[0m | \u001b[0m5.663    \u001b[0m | \u001b[0m271.8    \u001b[0m | \u001b[0m0.76     \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-0.9604  \u001b[0m | \u001b[0m0.09093  \u001b[0m | \u001b[0m5.185    \u001b[0m | \u001b[0m317.9    \u001b[0m | \u001b[0m0.8876   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-0.9521  \u001b[0m | \u001b[0m0.09879  \u001b[0m | \u001b[0m5.895    \u001b[0m | \u001b[0m291.9    \u001b[0m | \u001b[0m0.9609   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-0.9516  \u001b[0m | \u001b[0m0.08177  \u001b[0m | \u001b[0m5.196    \u001b[0m | \u001b[0m253.2    \u001b[0m | \u001b[0m0.6627   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-0.9508  \u001b[0m | \u001b[0m0.08777  \u001b[0m | \u001b[0m5.271    \u001b[0m | \u001b[0m308.0    \u001b[0m | \u001b[0m0.6784   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-0.9538  \u001b[0m | \u001b[0m0.08562  \u001b[0m | \u001b[0m5.543    \u001b[0m | \u001b[0m259.9    \u001b[0m | \u001b[0m0.9011   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-0.9523  \u001b[0m | \u001b[0m0.08149  \u001b[0m | \u001b[0m5.987    \u001b[0m | \u001b[0m304.1    \u001b[0m | \u001b[0m0.5994   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-0.9516  \u001b[0m | \u001b[0m0.08011  \u001b[0m | \u001b[0m5.815    \u001b[0m | \u001b[0m299.5    \u001b[0m | \u001b[0m0.8645   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-0.9611  \u001b[0m | \u001b[0m0.09543  \u001b[0m | \u001b[0m5.074    \u001b[0m | \u001b[0m275.1    \u001b[0m | \u001b[0m0.5579   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-0.9564  \u001b[0m | \u001b[0m0.09726  \u001b[0m | \u001b[0m5.623    \u001b[0m | \u001b[0m273.2    \u001b[0m | \u001b[0m0.5318   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-0.9523  \u001b[0m | \u001b[0m0.08622  \u001b[0m | \u001b[0m5.325    \u001b[0m | \u001b[0m301.1    \u001b[0m | \u001b[0m0.8188   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-0.9547  \u001b[0m | \u001b[0m0.09774  \u001b[0m | \u001b[0m5.472    \u001b[0m | \u001b[0m258.4    \u001b[0m | \u001b[0m0.8566   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-0.9532  \u001b[0m | \u001b[0m0.09522  \u001b[0m | \u001b[0m5.561    \u001b[0m | \u001b[0m304.0    \u001b[0m | \u001b[0m0.7469   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-0.9551  \u001b[0m | \u001b[0m0.09045  \u001b[0m | \u001b[0m5.428    \u001b[0m | \u001b[0m251.8    \u001b[0m | \u001b[0m0.5539   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-0.954   \u001b[0m | \u001b[0m0.08063  \u001b[0m | \u001b[0m5.636    \u001b[0m | \u001b[0m272.0    \u001b[0m | \u001b[0m0.7543   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-0.9511  \u001b[0m | \u001b[0m0.09815  \u001b[0m | \u001b[0m5.249    \u001b[0m | \u001b[0m278.7    \u001b[0m | \u001b[0m0.8778   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-0.9537  \u001b[0m | \u001b[0m0.08458  \u001b[0m | \u001b[0m5.077    \u001b[0m | \u001b[0m270.3    \u001b[0m | \u001b[0m0.5806   \u001b[0m |\n",
      "| \u001b[95m29       \u001b[0m | \u001b[95m-0.9487  \u001b[0m | \u001b[95m0.09859  \u001b[0m | \u001b[95m5.808    \u001b[0m | \u001b[95m294.3    \u001b[0m | \u001b[95m0.9357   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-0.9533  \u001b[0m | \u001b[0m0.09607  \u001b[0m | \u001b[0m5.187    \u001b[0m | \u001b[0m312.5    \u001b[0m | \u001b[0m0.7697   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-0.9536  \u001b[0m | \u001b[0m0.09615  \u001b[0m | \u001b[0m5.896    \u001b[0m | \u001b[0m272.3    \u001b[0m | \u001b[0m0.555    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-0.9506  \u001b[0m | \u001b[0m0.08456  \u001b[0m | \u001b[0m5.427    \u001b[0m | \u001b[0m307.3    \u001b[0m | \u001b[0m0.9304   \u001b[0m |\n",
      "| \u001b[95m33       \u001b[0m | \u001b[95m-0.9485  \u001b[0m | \u001b[95m0.08014  \u001b[0m | \u001b[95m5.511    \u001b[0m | \u001b[95m279.2    \u001b[0m | \u001b[95m0.6111   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-0.95    \u001b[0m | \u001b[0m0.0824   \u001b[0m | \u001b[0m5.338    \u001b[0m | \u001b[0m316.0    \u001b[0m | \u001b[0m0.6616   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-0.954   \u001b[0m | \u001b[0m0.09038  \u001b[0m | \u001b[0m5.703    \u001b[0m | \u001b[0m275.5    \u001b[0m | \u001b[0m0.9859   \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-0.951   \u001b[0m | \u001b[0m0.09925  \u001b[0m | \u001b[0m5.252    \u001b[0m | \u001b[0m284.8    \u001b[0m | \u001b[0m0.6504   \u001b[0m |\n",
      "| \u001b[95m37       \u001b[0m | \u001b[95m-0.9484  \u001b[0m | \u001b[95m0.0857   \u001b[0m | \u001b[95m5.037    \u001b[0m | \u001b[95m292.7    \u001b[0m | \u001b[95m0.7513   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-0.9514  \u001b[0m | \u001b[0m0.08103  \u001b[0m | \u001b[0m5.279    \u001b[0m | \u001b[0m313.6    \u001b[0m | \u001b[0m0.6198   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-0.9517  \u001b[0m | \u001b[0m0.0829   \u001b[0m | \u001b[0m5.489    \u001b[0m | \u001b[0m319.0    \u001b[0m | \u001b[0m0.621    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-0.9485  \u001b[0m | \u001b[0m0.09344  \u001b[0m | \u001b[0m5.762    \u001b[0m | \u001b[0m266.6    \u001b[0m | \u001b[0m0.8641   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-0.9495  \u001b[0m | \u001b[0m0.08736  \u001b[0m | \u001b[0m5.632    \u001b[0m | \u001b[0m294.3    \u001b[0m | \u001b[0m0.7679   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-0.9542  \u001b[0m | \u001b[0m0.08181  \u001b[0m | \u001b[0m5.835    \u001b[0m | \u001b[0m272.5    \u001b[0m | \u001b[0m0.5933   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-0.956   \u001b[0m | \u001b[0m0.08082  \u001b[0m | \u001b[0m5.591    \u001b[0m | \u001b[0m297.4    \u001b[0m | \u001b[0m0.5083   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-0.952   \u001b[0m | \u001b[0m0.09024  \u001b[0m | \u001b[0m5.226    \u001b[0m | \u001b[0m295.2    \u001b[0m | \u001b[0m0.5872   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-0.9543  \u001b[0m | \u001b[0m0.09382  \u001b[0m | \u001b[0m5.387    \u001b[0m | \u001b[0m315.6    \u001b[0m | \u001b[0m0.5688   \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-0.9572  \u001b[0m | \u001b[0m0.08682  \u001b[0m | \u001b[0m5.113    \u001b[0m | \u001b[0m314.7    \u001b[0m | \u001b[0m0.9387   \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-0.951   \u001b[0m | \u001b[0m0.08516  \u001b[0m | \u001b[0m5.66     \u001b[0m | \u001b[0m307.2    \u001b[0m | \u001b[0m0.7776   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-0.9506  \u001b[0m | \u001b[0m0.09059  \u001b[0m | \u001b[0m5.242    \u001b[0m | \u001b[0m256.5    \u001b[0m | \u001b[0m0.9486   \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-0.9514  \u001b[0m | \u001b[0m0.09801  \u001b[0m | \u001b[0m5.633    \u001b[0m | \u001b[0m273.7    \u001b[0m | \u001b[0m0.6746   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-0.9534  \u001b[0m | \u001b[0m0.09452  \u001b[0m | \u001b[0m5.897    \u001b[0m | \u001b[0m312.1    \u001b[0m | \u001b[0m0.8899   \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-0.9534  \u001b[0m | \u001b[0m0.09284  \u001b[0m | \u001b[0m5.084    \u001b[0m | \u001b[0m261.3    \u001b[0m | \u001b[0m0.9493   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-0.9496  \u001b[0m | \u001b[0m0.09213  \u001b[0m | \u001b[0m5.009    \u001b[0m | \u001b[0m257.1    \u001b[0m | \u001b[0m0.8318   \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-0.9485  \u001b[0m | \u001b[0m0.0801   \u001b[0m | \u001b[0m5.161    \u001b[0m | \u001b[0m288.4    \u001b[0m | \u001b[0m0.8459   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-0.9528  \u001b[0m | \u001b[0m0.09304  \u001b[0m | \u001b[0m5.224    \u001b[0m | \u001b[0m299.9    \u001b[0m | \u001b[0m0.6186   \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-0.9516  \u001b[0m | \u001b[0m0.08651  \u001b[0m | \u001b[0m5.746    \u001b[0m | \u001b[0m295.5    \u001b[0m | \u001b[0m0.9246   \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m-0.9514  \u001b[0m | \u001b[0m0.09315  \u001b[0m | \u001b[0m5.568    \u001b[0m | \u001b[0m256.6    \u001b[0m | \u001b[0m0.6839   \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m-0.9533  \u001b[0m | \u001b[0m0.0853   \u001b[0m | \u001b[0m5.244    \u001b[0m | \u001b[0m318.1    \u001b[0m | \u001b[0m0.6965   \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m-0.9518  \u001b[0m | \u001b[0m0.09784  \u001b[0m | \u001b[0m5.631    \u001b[0m | \u001b[0m305.6    \u001b[0m | \u001b[0m0.7513   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-0.9488  \u001b[0m | \u001b[0m0.09154  \u001b[0m | \u001b[0m5.493    \u001b[0m | \u001b[0m263.7    \u001b[0m | \u001b[0m0.8612   \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-0.9546  \u001b[0m | \u001b[0m0.08562  \u001b[0m | \u001b[0m5.024    \u001b[0m | \u001b[0m295.2    \u001b[0m | \u001b[0m0.5886   \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-0.9545  \u001b[0m | \u001b[0m0.09881  \u001b[0m | \u001b[0m5.954    \u001b[0m | \u001b[0m314.0    \u001b[0m | \u001b[0m0.6851   \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-0.9504  \u001b[0m | \u001b[0m0.08031  \u001b[0m | \u001b[0m5.928    \u001b[0m | \u001b[0m280.0    \u001b[0m | \u001b[0m0.9833   \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-0.9534  \u001b[0m | \u001b[0m0.09927  \u001b[0m | \u001b[0m5.853    \u001b[0m | \u001b[0m270.6    \u001b[0m | \u001b[0m0.6925   \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-0.9523  \u001b[0m | \u001b[0m0.09702  \u001b[0m | \u001b[0m5.317    \u001b[0m | \u001b[0m261.9    \u001b[0m | \u001b[0m0.7784   \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-0.9585  \u001b[0m | \u001b[0m0.09872  \u001b[0m | \u001b[0m5.696    \u001b[0m | \u001b[0m289.9    \u001b[0m | \u001b[0m0.5486   \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-0.9517  \u001b[0m | \u001b[0m0.0923   \u001b[0m | \u001b[0m5.99     \u001b[0m | \u001b[0m259.8    \u001b[0m | \u001b[0m0.7592   \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-0.9517  \u001b[0m | \u001b[0m0.09755  \u001b[0m | \u001b[0m5.741    \u001b[0m | \u001b[0m298.8    \u001b[0m | \u001b[0m0.8512   \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-0.9515  \u001b[0m | \u001b[0m0.08719  \u001b[0m | \u001b[0m5.294    \u001b[0m | \u001b[0m306.7    \u001b[0m | \u001b[0m0.9051   \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m-0.9517  \u001b[0m | \u001b[0m0.09734  \u001b[0m | \u001b[0m5.913    \u001b[0m | \u001b[0m285.8    \u001b[0m | \u001b[0m0.7508   \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-0.9544  \u001b[0m | \u001b[0m0.09597  \u001b[0m | \u001b[0m5.65     \u001b[0m | \u001b[0m299.1    \u001b[0m | \u001b[0m0.8979   \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-0.9539  \u001b[0m | \u001b[0m0.0978   \u001b[0m | \u001b[0m5.338    \u001b[0m | \u001b[0m276.3    \u001b[0m | \u001b[0m0.547    \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m-0.9498  \u001b[0m | \u001b[0m0.09157  \u001b[0m | \u001b[0m5.036    \u001b[0m | \u001b[0m282.6    \u001b[0m | \u001b[0m0.7713   \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-0.9528  \u001b[0m | \u001b[0m0.08573  \u001b[0m | \u001b[0m5.591    \u001b[0m | \u001b[0m252.1    \u001b[0m | \u001b[0m0.5187   \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-0.9594  \u001b[0m | \u001b[0m0.09645  \u001b[0m | \u001b[0m5.36     \u001b[0m | \u001b[0m258.9    \u001b[0m | \u001b[0m0.7611   \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m-0.9552  \u001b[0m | \u001b[0m0.0954   \u001b[0m | \u001b[0m5.216    \u001b[0m | \u001b[0m293.6    \u001b[0m | \u001b[0m0.5427   \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-0.9518  \u001b[0m | \u001b[0m0.08103  \u001b[0m | \u001b[0m5.531    \u001b[0m | \u001b[0m287.8    \u001b[0m | \u001b[0m0.8187   \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-0.9565  \u001b[0m | \u001b[0m0.09452  \u001b[0m | \u001b[0m5.976    \u001b[0m | \u001b[0m286.1    \u001b[0m | \u001b[0m0.6615   \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-0.9515  \u001b[0m | \u001b[0m0.0959   \u001b[0m | \u001b[0m5.271    \u001b[0m | \u001b[0m280.7    \u001b[0m | \u001b[0m0.5392   \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m-0.952   \u001b[0m | \u001b[0m0.08051  \u001b[0m | \u001b[0m5.963    \u001b[0m | \u001b[0m308.5    \u001b[0m | \u001b[0m0.848    \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m-0.953   \u001b[0m | \u001b[0m0.08818  \u001b[0m | \u001b[0m5.173    \u001b[0m | \u001b[0m261.0    \u001b[0m | \u001b[0m0.6251   \u001b[0m |\n",
      "| \u001b[0m81       \u001b[0m | \u001b[0m-0.9591  \u001b[0m | \u001b[0m0.09098  \u001b[0m | \u001b[0m5.715    \u001b[0m | \u001b[0m296.2    \u001b[0m | \u001b[0m0.64     \u001b[0m |\n",
      "| \u001b[0m82       \u001b[0m | \u001b[0m-0.951   \u001b[0m | \u001b[0m0.0991   \u001b[0m | \u001b[0m5.738    \u001b[0m | \u001b[0m288.8    \u001b[0m | \u001b[0m0.8059   \u001b[0m |\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m-0.9496  \u001b[0m | \u001b[0m0.08839  \u001b[0m | \u001b[0m5.248    \u001b[0m | \u001b[0m274.9    \u001b[0m | \u001b[0m0.8789   \u001b[0m |\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m-0.9547  \u001b[0m | \u001b[0m0.08029  \u001b[0m | \u001b[0m5.116    \u001b[0m | \u001b[0m253.2    \u001b[0m | \u001b[0m0.5204   \u001b[0m |\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m-0.9534  \u001b[0m | \u001b[0m0.09711  \u001b[0m | \u001b[0m5.704    \u001b[0m | \u001b[0m283.2    \u001b[0m | \u001b[0m0.5489   \u001b[0m |\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m-0.9497  \u001b[0m | \u001b[0m0.08983  \u001b[0m | \u001b[0m5.473    \u001b[0m | \u001b[0m262.1    \u001b[0m | \u001b[0m0.7169   \u001b[0m |\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m-0.953   \u001b[0m | \u001b[0m0.08797  \u001b[0m | \u001b[0m5.616    \u001b[0m | \u001b[0m294.5    \u001b[0m | \u001b[0m0.5227   \u001b[0m |\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m-0.9492  \u001b[0m | \u001b[0m0.08749  \u001b[0m | \u001b[0m5.626    \u001b[0m | \u001b[0m285.2    \u001b[0m | \u001b[0m0.9282   \u001b[0m |\n",
      "| \u001b[0m89       \u001b[0m | \u001b[0m-0.9493  \u001b[0m | \u001b[0m0.09317  \u001b[0m | \u001b[0m5.163    \u001b[0m | \u001b[0m254.9    \u001b[0m | \u001b[0m0.8212   \u001b[0m |\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m-0.9531  \u001b[0m | \u001b[0m0.08053  \u001b[0m | \u001b[0m5.586    \u001b[0m | \u001b[0m315.8    \u001b[0m | \u001b[0m0.7877   \u001b[0m |\n",
      "| \u001b[0m91       \u001b[0m | \u001b[0m-0.9508  \u001b[0m | \u001b[0m0.08776  \u001b[0m | \u001b[0m5.643    \u001b[0m | \u001b[0m282.1    \u001b[0m | \u001b[0m0.7728   \u001b[0m |\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m-0.9486  \u001b[0m | \u001b[0m0.09883  \u001b[0m | \u001b[0m5.386    \u001b[0m | \u001b[0m317.3    \u001b[0m | \u001b[0m0.9527   \u001b[0m |\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m-0.9536  \u001b[0m | \u001b[0m0.08392  \u001b[0m | \u001b[0m5.069    \u001b[0m | \u001b[0m257.1    \u001b[0m | \u001b[0m0.5091   \u001b[0m |\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m-0.9514  \u001b[0m | \u001b[0m0.08189  \u001b[0m | \u001b[0m5.683    \u001b[0m | \u001b[0m255.0    \u001b[0m | \u001b[0m0.6595   \u001b[0m |\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m-0.9566  \u001b[0m | \u001b[0m0.0969   \u001b[0m | \u001b[0m5.023    \u001b[0m | \u001b[0m307.0    \u001b[0m | \u001b[0m0.6409   \u001b[0m |\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m-0.9521  \u001b[0m | \u001b[0m0.08236  \u001b[0m | \u001b[0m5.697    \u001b[0m | \u001b[0m294.0    \u001b[0m | \u001b[0m0.9387   \u001b[0m |\n",
      "| \u001b[0m97       \u001b[0m | \u001b[0m-0.9526  \u001b[0m | \u001b[0m0.0947   \u001b[0m | \u001b[0m5.803    \u001b[0m | \u001b[0m269.7    \u001b[0m | \u001b[0m0.5887   \u001b[0m |\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m-0.9524  \u001b[0m | \u001b[0m0.09501  \u001b[0m | \u001b[0m5.807    \u001b[0m | \u001b[0m319.3    \u001b[0m | \u001b[0m0.7063   \u001b[0m |\n",
      "| \u001b[0m99       \u001b[0m | \u001b[0m-0.9532  \u001b[0m | \u001b[0m0.08744  \u001b[0m | \u001b[0m5.776    \u001b[0m | \u001b[0m273.9    \u001b[0m | \u001b[0m0.9654   \u001b[0m |\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m-0.9497  \u001b[0m | \u001b[0m0.09717  \u001b[0m | \u001b[0m5.429    \u001b[0m | \u001b[0m302.6    \u001b[0m | \u001b[0m0.8773   \u001b[0m |\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m-0.955   \u001b[0m | \u001b[0m0.09446  \u001b[0m | \u001b[0m5.668    \u001b[0m | \u001b[0m265.6    \u001b[0m | \u001b[0m0.5319   \u001b[0m |\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m-0.9511  \u001b[0m | \u001b[0m0.08098  \u001b[0m | \u001b[0m5.018    \u001b[0m | \u001b[0m292.0    \u001b[0m | \u001b[0m0.8619   \u001b[0m |\n",
      "| \u001b[0m103      \u001b[0m | \u001b[0m-0.9531  \u001b[0m | \u001b[0m0.08009  \u001b[0m | \u001b[0m5.04     \u001b[0m | \u001b[0m282.7    \u001b[0m | \u001b[0m0.6761   \u001b[0m |\n",
      "| \u001b[0m104      \u001b[0m | \u001b[0m-0.95    \u001b[0m | \u001b[0m0.09942  \u001b[0m | \u001b[0m5.71     \u001b[0m | \u001b[0m319.6    \u001b[0m | \u001b[0m0.687    \u001b[0m |\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m-0.9588  \u001b[0m | \u001b[0m0.08943  \u001b[0m | \u001b[0m5.16     \u001b[0m | \u001b[0m306.1    \u001b[0m | \u001b[0m0.5483   \u001b[0m |\n",
      "| \u001b[0m106      \u001b[0m | \u001b[0m-0.953   \u001b[0m | \u001b[0m0.09877  \u001b[0m | \u001b[0m5.706    \u001b[0m | \u001b[0m281.5    \u001b[0m | \u001b[0m0.9992   \u001b[0m |\n",
      "| \u001b[0m107      \u001b[0m | \u001b[0m-0.9557  \u001b[0m | \u001b[0m0.0955   \u001b[0m | \u001b[0m5.882    \u001b[0m | \u001b[0m265.9    \u001b[0m | \u001b[0m0.6862   \u001b[0m |\n",
      "| \u001b[0m108      \u001b[0m | \u001b[0m-0.9496  \u001b[0m | \u001b[0m0.08387  \u001b[0m | \u001b[0m5.621    \u001b[0m | \u001b[0m267.4    \u001b[0m | \u001b[0m0.8839   \u001b[0m |\n",
      "| \u001b[0m109      \u001b[0m | \u001b[0m-0.9541  \u001b[0m | \u001b[0m0.08013  \u001b[0m | \u001b[0m5.459    \u001b[0m | \u001b[0m318.4    \u001b[0m | \u001b[0m0.7634   \u001b[0m |\n",
      "| \u001b[0m110      \u001b[0m | \u001b[0m-0.9555  \u001b[0m | \u001b[0m0.09485  \u001b[0m | \u001b[0m5.525    \u001b[0m | \u001b[0m271.0    \u001b[0m | \u001b[0m0.5098   \u001b[0m |\n",
      "| \u001b[0m111      \u001b[0m | \u001b[0m-0.9515  \u001b[0m | \u001b[0m0.09774  \u001b[0m | \u001b[0m5.531    \u001b[0m | \u001b[0m268.0    \u001b[0m | \u001b[0m0.7656   \u001b[0m |\n",
      "| \u001b[0m112      \u001b[0m | \u001b[0m-0.9569  \u001b[0m | \u001b[0m0.08412  \u001b[0m | \u001b[0m5.97     \u001b[0m | \u001b[0m251.0    \u001b[0m | \u001b[0m0.5347   \u001b[0m |\n",
      "| \u001b[0m113      \u001b[0m | \u001b[0m-0.9506  \u001b[0m | \u001b[0m0.08897  \u001b[0m | \u001b[0m5.088    \u001b[0m | \u001b[0m253.6    \u001b[0m | \u001b[0m0.9185   \u001b[0m |\n",
      "| \u001b[0m114      \u001b[0m | \u001b[0m-0.953   \u001b[0m | \u001b[0m0.08166  \u001b[0m | \u001b[0m5.798    \u001b[0m | \u001b[0m314.5    \u001b[0m | \u001b[0m0.9858   \u001b[0m |\n",
      "| \u001b[0m115      \u001b[0m | \u001b[0m-0.9495  \u001b[0m | \u001b[0m0.08729  \u001b[0m | \u001b[0m5.287    \u001b[0m | \u001b[0m298.5    \u001b[0m | \u001b[0m0.8337   \u001b[0m |\n",
      "| \u001b[0m116      \u001b[0m | \u001b[0m-0.9521  \u001b[0m | \u001b[0m0.09974  \u001b[0m | \u001b[0m5.605    \u001b[0m | \u001b[0m313.0    \u001b[0m | \u001b[0m0.8785   \u001b[0m |\n",
      "| \u001b[0m117      \u001b[0m | \u001b[0m-0.9522  \u001b[0m | \u001b[0m0.09428  \u001b[0m | \u001b[0m5.748    \u001b[0m | \u001b[0m253.0    \u001b[0m | \u001b[0m0.7014   \u001b[0m |\n",
      "| \u001b[0m118      \u001b[0m | \u001b[0m-0.9505  \u001b[0m | \u001b[0m0.09691  \u001b[0m | \u001b[0m5.718    \u001b[0m | \u001b[0m270.7    \u001b[0m | \u001b[0m0.7704   \u001b[0m |\n",
      "| \u001b[0m119      \u001b[0m | \u001b[0m-0.9513  \u001b[0m | \u001b[0m0.08169  \u001b[0m | \u001b[0m5.81     \u001b[0m | \u001b[0m298.4    \u001b[0m | \u001b[0m0.8026   \u001b[0m |\n",
      "| \u001b[0m120      \u001b[0m | \u001b[0m-0.9542  \u001b[0m | \u001b[0m0.09585  \u001b[0m | \u001b[0m5.974    \u001b[0m | \u001b[0m301.0    \u001b[0m | \u001b[0m0.5193   \u001b[0m |\n",
      "| \u001b[0m121      \u001b[0m | \u001b[0m-0.9506  \u001b[0m | \u001b[0m0.08462  \u001b[0m | \u001b[0m5.405    \u001b[0m | \u001b[0m316.2    \u001b[0m | \u001b[0m0.9308   \u001b[0m |\n",
      "| \u001b[0m122      \u001b[0m | \u001b[0m-0.9488  \u001b[0m | \u001b[0m0.08117  \u001b[0m | \u001b[0m5.129    \u001b[0m | \u001b[0m288.5    \u001b[0m | \u001b[0m0.9348   \u001b[0m |\n",
      "| \u001b[0m123      \u001b[0m | \u001b[0m-0.9503  \u001b[0m | \u001b[0m0.09895  \u001b[0m | \u001b[0m5.604    \u001b[0m | \u001b[0m261.8    \u001b[0m | \u001b[0m0.7201   \u001b[0m |\n",
      "| \u001b[0m124      \u001b[0m | \u001b[0m-0.9507  \u001b[0m | \u001b[0m0.08297  \u001b[0m | \u001b[0m5.942    \u001b[0m | \u001b[0m287.5    \u001b[0m | \u001b[0m0.8086   \u001b[0m |\n",
      "| \u001b[0m125      \u001b[0m | \u001b[0m-0.9524  \u001b[0m | \u001b[0m0.08123  \u001b[0m | \u001b[0m5.516    \u001b[0m | \u001b[0m279.9    \u001b[0m | \u001b[0m0.9765   \u001b[0m |\n",
      "| \u001b[0m126      \u001b[0m | \u001b[0m-0.9499  \u001b[0m | \u001b[0m0.08655  \u001b[0m | \u001b[0m5.208    \u001b[0m | \u001b[0m288.5    \u001b[0m | \u001b[0m0.8536   \u001b[0m |\n",
      "| \u001b[0m127      \u001b[0m | \u001b[0m-0.9518  \u001b[0m | \u001b[0m0.08292  \u001b[0m | \u001b[0m5.033    \u001b[0m | \u001b[0m292.7    \u001b[0m | \u001b[0m0.8261   \u001b[0m |\n",
      "| \u001b[0m128      \u001b[0m | \u001b[0m-0.9564  \u001b[0m | \u001b[0m0.09847  \u001b[0m | \u001b[0m5.532    \u001b[0m | \u001b[0m279.3    \u001b[0m | \u001b[0m0.5576   \u001b[0m |\n",
      "| \u001b[0m129      \u001b[0m | \u001b[0m-0.9528  \u001b[0m | \u001b[0m0.09433  \u001b[0m | \u001b[0m5.052    \u001b[0m | \u001b[0m283.2    \u001b[0m | \u001b[0m0.5879   \u001b[0m |\n",
      "| \u001b[0m130      \u001b[0m | \u001b[0m-0.9568  \u001b[0m | \u001b[0m0.098    \u001b[0m | \u001b[0m5.21     \u001b[0m | \u001b[0m282.3    \u001b[0m | \u001b[0m0.5719   \u001b[0m |\n",
      "| \u001b[0m131      \u001b[0m | \u001b[0m-0.9524  \u001b[0m | \u001b[0m0.09676  \u001b[0m | \u001b[0m5.294    \u001b[0m | \u001b[0m312.0    \u001b[0m | \u001b[0m0.8452   \u001b[0m |\n",
      "| \u001b[0m132      \u001b[0m | \u001b[0m-0.9518  \u001b[0m | \u001b[0m0.09658  \u001b[0m | \u001b[0m5.112    \u001b[0m | \u001b[0m264.7    \u001b[0m | \u001b[0m0.9288   \u001b[0m |\n",
      "| \u001b[0m133      \u001b[0m | \u001b[0m-0.951   \u001b[0m | \u001b[0m0.09201  \u001b[0m | \u001b[0m5.174    \u001b[0m | \u001b[0m290.2    \u001b[0m | \u001b[0m0.8925   \u001b[0m |\n",
      "| \u001b[0m134      \u001b[0m | \u001b[0m-0.9518  \u001b[0m | \u001b[0m0.09597  \u001b[0m | \u001b[0m5.008    \u001b[0m | \u001b[0m254.7    \u001b[0m | \u001b[0m0.9499   \u001b[0m |\n",
      "| \u001b[0m135      \u001b[0m | \u001b[0m-0.9559  \u001b[0m | \u001b[0m0.08165  \u001b[0m | \u001b[0m5.166    \u001b[0m | \u001b[0m315.9    \u001b[0m | \u001b[0m0.9732   \u001b[0m |\n",
      "| \u001b[0m136      \u001b[0m | \u001b[0m-0.9525  \u001b[0m | \u001b[0m0.09236  \u001b[0m | \u001b[0m5.773    \u001b[0m | \u001b[0m309.9    \u001b[0m | \u001b[0m0.7181   \u001b[0m |\n",
      "| \u001b[0m137      \u001b[0m | \u001b[0m-0.9522  \u001b[0m | \u001b[0m0.08457  \u001b[0m | \u001b[0m5.943    \u001b[0m | \u001b[0m273.6    \u001b[0m | \u001b[0m0.9508   \u001b[0m |\n",
      "| \u001b[0m138      \u001b[0m | \u001b[0m-0.9493  \u001b[0m | \u001b[0m0.08449  \u001b[0m | \u001b[0m5.59     \u001b[0m | \u001b[0m316.4    \u001b[0m | \u001b[0m0.9353   \u001b[0m |\n",
      "| \u001b[0m139      \u001b[0m | \u001b[0m-0.9533  \u001b[0m | \u001b[0m0.09283  \u001b[0m | \u001b[0m5.456    \u001b[0m | \u001b[0m303.6    \u001b[0m | \u001b[0m0.9053   \u001b[0m |\n",
      "| \u001b[0m140      \u001b[0m | \u001b[0m-0.9573  \u001b[0m | \u001b[0m0.08448  \u001b[0m | \u001b[0m5.807    \u001b[0m | \u001b[0m273.0    \u001b[0m | \u001b[0m0.607    \u001b[0m |\n",
      "| \u001b[0m141      \u001b[0m | \u001b[0m-0.9534  \u001b[0m | \u001b[0m0.08232  \u001b[0m | \u001b[0m5.872    \u001b[0m | \u001b[0m260.9    \u001b[0m | \u001b[0m0.5491   \u001b[0m |\n",
      "| \u001b[0m142      \u001b[0m | \u001b[0m-0.9506  \u001b[0m | \u001b[0m0.0853   \u001b[0m | \u001b[0m5.992    \u001b[0m | \u001b[0m286.7    \u001b[0m | \u001b[0m0.9861   \u001b[0m |\n",
      "| \u001b[0m143      \u001b[0m | \u001b[0m-0.9534  \u001b[0m | \u001b[0m0.09574  \u001b[0m | \u001b[0m5.967    \u001b[0m | \u001b[0m311.7    \u001b[0m | \u001b[0m0.7634   \u001b[0m |\n",
      "| \u001b[0m144      \u001b[0m | \u001b[0m-0.9568  \u001b[0m | \u001b[0m0.09413  \u001b[0m | \u001b[0m5.106    \u001b[0m | \u001b[0m259.0    \u001b[0m | \u001b[0m0.6274   \u001b[0m |\n",
      "| \u001b[0m145      \u001b[0m | \u001b[0m-0.9531  \u001b[0m | \u001b[0m0.08421  \u001b[0m | \u001b[0m5.789    \u001b[0m | \u001b[0m311.1    \u001b[0m | \u001b[0m0.6981   \u001b[0m |\n",
      "| \u001b[0m146      \u001b[0m | \u001b[0m-0.9526  \u001b[0m | \u001b[0m0.08781  \u001b[0m | \u001b[0m5.844    \u001b[0m | \u001b[0m299.9    \u001b[0m | \u001b[0m0.7012   \u001b[0m |\n",
      "| \u001b[0m147      \u001b[0m | \u001b[0m-0.953   \u001b[0m | \u001b[0m0.09299  \u001b[0m | \u001b[0m5.792    \u001b[0m | \u001b[0m295.3    \u001b[0m | \u001b[0m0.96     \u001b[0m |\n",
      "| \u001b[0m148      \u001b[0m | \u001b[0m-0.9549  \u001b[0m | \u001b[0m0.09696  \u001b[0m | \u001b[0m5.023    \u001b[0m | \u001b[0m298.2    \u001b[0m | \u001b[0m0.5709   \u001b[0m |\n",
      "| \u001b[0m149      \u001b[0m | \u001b[0m-0.9553  \u001b[0m | \u001b[0m0.08649  \u001b[0m | \u001b[0m5.358    \u001b[0m | \u001b[0m310.5    \u001b[0m | \u001b[0m0.6727   \u001b[0m |\n",
      "| \u001b[0m150      \u001b[0m | \u001b[0m-0.9521  \u001b[0m | \u001b[0m0.08505  \u001b[0m | \u001b[0m5.595    \u001b[0m | \u001b[0m312.6    \u001b[0m | \u001b[0m0.693    \u001b[0m |\n",
      "=========================================================================\n",
      "Best parameters: {'learning_rate': 0.08569680988754935, 'max_depth': 5.036886947354533, 'n_estimators': 292.66950337859276, 'subsample': 0.7513395116144308}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 准备测试数据\n",
    "X_train, y_train = prepare_test_data(train_df, 3) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "\n",
    "X_test, y_test = prepare_test_data(test_df, 3)\n",
    "\n",
    "def xgb_eval(max_depth, learning_rate, n_estimators, subsample): # , gamma, min_child_weight, colsample_bytree\n",
    "    model = XGBRegressor(\n",
    "        max_depth=int(max_depth),\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=int(n_estimators),\n",
    "        subsample=subsample,\n",
    "        # gamma=gamma,\n",
    "        # min_child_weight=min_child_weight,\n",
    "        # colsample_bytree=colsample_bytree,\n",
    "        objective='reg:squarederror',\n",
    "        verbosity=0,  # 使用正确的参数控制输出\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    \n",
    "    # 使用测试数据评估模型\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    # 返回负RMSE，因为贝叶斯优化默认是最大化目标函数\n",
    "    return -rmse\n",
    "\n",
    "# 参数边界\n",
    "pbounds = {\n",
    "    'max_depth': (5, 6),\n",
    "    'learning_rate': (0.08, 0.1),\n",
    "    'n_estimators': (250, 320),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    # 'gamma': (0.65, 0.75),\n",
    "    # 'min_child_weight': (3, 5),\n",
    "    # 'colsample_bytree': (0.67, 0.7),\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(f=xgb_eval, pbounds=pbounds, random_state=42)\n",
    "optimizer.maximize(init_points=100, n_iter=50)\n",
    "\n",
    "print(\"Best parameters:\", optimizer.max['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6466de-8ab2-4a84-81d7-2821d568975a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "3\n",
    "Best parameters: {'learning_rate': 0.08288064461501718, 'max_depth': 4.704925810006415, \n",
    "                  'n_estimators': 304.68373839140463, 'subsample': 0.6838579015297168}\n",
    "\n",
    "-0.9463\n",
    "\n",
    "# Best parameters: {'learning_rate': 0.07173423081368346, 'max_depth': 3.9789055205551263, \n",
    "#                   'n_estimators': 318.56504541106005, 'subsample': 0.8484110543023001}\n",
    "# -0.9478\n",
    "\n",
    "4\n",
    "Best parameters: {'learning_rate': 0.18299396047960448, 'max_depth': 3.717897930418724, \n",
    "                  'n_estimators': 249.53928852131315, 'subsample': 0.9081495526065285}\n",
    "-0.9327\n",
    "\n",
    "2\n",
    "Best parameters: {'learning_rate': 0.12350751460907078, 'max_depth': 3.097672114006384, \n",
    "                  'n_estimators': 288.4233026512157, 'subsample': 0.8880304987479203}\n",
    "-0.8718\n",
    "\n",
    "# Best parameters: {'learning_rate': 0.12350751460907078, 'max_depth': 3.097672114006384, \n",
    "#                   'n_estimators': 302.63495397682357, 'subsample': 0.8880304987479203}\n",
    "# -0.8718\n",
    "\n",
    "# Best parameters: {'learning_rate': 0.09913727843230384, 'max_depth': 3.798413063437975, \n",
    "#                   'n_estimators': 314.5428334929617, 'subsample': 0.8343921895955786}\n",
    "# -0.8718\n",
    "\n",
    "# Best parameters: {'learning_rate': 0.052015138549577726, 'max_depth': 3.040366245098638, \n",
    "#                   'n_estimators': 282.65168237360854, 'subsample': 0.36408083754707765}\n",
    "# -0.872\n",
    "\n",
    "\n",
    "0\n",
    "\n",
    "Best parameters: {'learning_rate': 0.04246778091879101, 'max_depth': 6.332694494015188, \n",
    "                  'n_estimators': 491.29196986785007, 'subsample': 0.8689265095175513}\n",
    "\n",
    "-0.9824\n",
    "\n",
    "# Best parameters: {'learning_rate': 0.04246778091879101, 'max_depth': 6.332694494015188, \n",
    "#                   'n_estimators': 444.1946465785667, 'subsample': 0.8689265095175513}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8c87b0e-7cdf-42ac-b193-ab1a9037de4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   depth   | l2_lea... | learni... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-0.8753  \u001b[0m | \u001b[0m6.375    \u001b[0m | \u001b[0m19.51    \u001b[0m | \u001b[0m0.5196   \u001b[0m | \u001b[0m155.9    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-0.8746  \u001b[0m | \u001b[95m6.156    \u001b[0m | \u001b[95m11.56    \u001b[0m | \u001b[95m0.3174   \u001b[0m | \u001b[95m172.0    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-0.8756  \u001b[0m | \u001b[0m6.601    \u001b[0m | \u001b[0m17.08    \u001b[0m | \u001b[0m0.3062   \u001b[0m | \u001b[0m178.2    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-0.8759  \u001b[0m | \u001b[0m6.832    \u001b[0m | \u001b[0m12.12    \u001b[0m | \u001b[0m0.3545   \u001b[0m | \u001b[0m131.0    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-0.8773  \u001b[0m | \u001b[0m6.304    \u001b[0m | \u001b[0m15.25    \u001b[0m | \u001b[0m0.4296   \u001b[0m | \u001b[0m137.5    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-0.8762  \u001b[0m | \u001b[0m6.612    \u001b[0m | \u001b[0m11.39    \u001b[0m | \u001b[0m0.3876   \u001b[0m | \u001b[0m142.0    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-0.8747  \u001b[0m | \u001b[0m6.456    \u001b[0m | \u001b[0m17.85    \u001b[0m | \u001b[0m0.3599   \u001b[0m | \u001b[0m150.9    \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m-0.8745  \u001b[0m | \u001b[95m6.592    \u001b[0m | \u001b[95m10.46    \u001b[0m | \u001b[95m0.4823   \u001b[0m | \u001b[95m130.2    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-0.8781  \u001b[0m | \u001b[0m6.065    \u001b[0m | \u001b[0m19.49    \u001b[0m | \u001b[0m0.5897   \u001b[0m | \u001b[0m168.5    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-0.8749  \u001b[0m | \u001b[0m6.305    \u001b[0m | \u001b[0m10.98    \u001b[0m | \u001b[0m0.5053   \u001b[0m | \u001b[0m146.4    \u001b[0m |\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m-0.8734  \u001b[0m | \u001b[95m6.122    \u001b[0m | \u001b[95m14.95    \u001b[0m | \u001b[95m0.3103   \u001b[0m | \u001b[95m174.6    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-0.8769  \u001b[0m | \u001b[0m6.259    \u001b[0m | \u001b[0m16.63    \u001b[0m | \u001b[0m0.3935   \u001b[0m | \u001b[0m151.2    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-0.8773  \u001b[0m | \u001b[0m6.547    \u001b[0m | \u001b[0m11.85    \u001b[0m | \u001b[0m0.5909   \u001b[0m | \u001b[0m166.5    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-0.8753  \u001b[0m | \u001b[0m6.939    \u001b[0m | \u001b[0m18.95    \u001b[0m | \u001b[0m0.4794   \u001b[0m | \u001b[0m175.3    \u001b[0m |\n",
      "| \u001b[95m15       \u001b[0m | \u001b[95m-0.8732  \u001b[0m | \u001b[95m6.088    \u001b[0m | \u001b[95m11.96    \u001b[0m | \u001b[95m0.3136   \u001b[0m | \u001b[95m139.5    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.389    \u001b[0m | \u001b[0m12.71    \u001b[0m | \u001b[0m0.5486   \u001b[0m | \u001b[0m141.4    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-0.8761  \u001b[0m | \u001b[0m6.281    \u001b[0m | \u001b[0m15.43    \u001b[0m | \u001b[0m0.3423   \u001b[0m | \u001b[0m168.1    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-0.8761  \u001b[0m | \u001b[0m6.075    \u001b[0m | \u001b[0m19.87    \u001b[0m | \u001b[0m0.5317   \u001b[0m | \u001b[0m131.9    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-0.8749  \u001b[0m | \u001b[0m6.006    \u001b[0m | \u001b[0m18.15    \u001b[0m | \u001b[0m0.5121   \u001b[0m | \u001b[0m163.7    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-0.8768  \u001b[0m | \u001b[0m6.771    \u001b[0m | \u001b[0m10.74    \u001b[0m | \u001b[0m0.4075   \u001b[0m | \u001b[0m127.0    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-0.8767  \u001b[0m | \u001b[0m6.863    \u001b[0m | \u001b[0m16.23    \u001b[0m | \u001b[0m0.3993   \u001b[0m | \u001b[0m123.8    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-0.8758  \u001b[0m | \u001b[0m6.311    \u001b[0m | \u001b[0m13.25    \u001b[0m | \u001b[0m0.5189   \u001b[0m | \u001b[0m158.3    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-0.8743  \u001b[0m | \u001b[0m6.887    \u001b[0m | \u001b[0m14.72    \u001b[0m | \u001b[0m0.3359   \u001b[0m | \u001b[0m162.8    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-0.8749  \u001b[0m | \u001b[0m6.761    \u001b[0m | \u001b[0m15.61    \u001b[0m | \u001b[0m0.5313   \u001b[0m | \u001b[0m149.6    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-0.877   \u001b[0m | \u001b[0m6.523    \u001b[0m | \u001b[0m14.28    \u001b[0m | \u001b[0m0.3076   \u001b[0m | \u001b[0m126.5    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-0.8734  \u001b[0m | \u001b[0m6.031    \u001b[0m | \u001b[0m16.36    \u001b[0m | \u001b[0m0.3943   \u001b[0m | \u001b[0m150.5    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-0.8743  \u001b[0m | \u001b[0m6.908    \u001b[0m | \u001b[0m12.49    \u001b[0m | \u001b[0m0.4231   \u001b[0m | \u001b[0m165.3    \u001b[0m |\n",
      "| \u001b[95m28       \u001b[0m | \u001b[95m-0.8729  \u001b[0m | \u001b[95m6.229    \u001b[0m | \u001b[95m10.77    \u001b[0m | \u001b[95m0.3869   \u001b[0m | \u001b[95m129.7    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-0.8764  \u001b[0m | \u001b[0m6.93     \u001b[0m | \u001b[0m18.08    \u001b[0m | \u001b[0m0.49     \u001b[0m | \u001b[0m172.3    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-0.8777  \u001b[0m | \u001b[0m6.804    \u001b[0m | \u001b[0m11.87    \u001b[0m | \u001b[0m0.5678   \u001b[0m | \u001b[0m152.4    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-0.8771  \u001b[0m | \u001b[0m6.807    \u001b[0m | \u001b[0m18.96    \u001b[0m | \u001b[0m0.3954   \u001b[0m | \u001b[0m126.6    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-0.8763  \u001b[0m | \u001b[0m6.228    \u001b[0m | \u001b[0m14.27    \u001b[0m | \u001b[0m0.5454   \u001b[0m | \u001b[0m171.6    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-0.8753  \u001b[0m | \u001b[0m6.007    \u001b[0m | \u001b[0m15.11    \u001b[0m | \u001b[0m0.4252   \u001b[0m | \u001b[0m133.3    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-0.8786  \u001b[0m | \u001b[0m6.12     \u001b[0m | \u001b[0m13.38    \u001b[0m | \u001b[0m0.5829   \u001b[0m | \u001b[0m139.4    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-0.8742  \u001b[0m | \u001b[0m6.519    \u001b[0m | \u001b[0m17.03    \u001b[0m | \u001b[0m0.4091   \u001b[0m | \u001b[0m178.3    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-0.8753  \u001b[0m | \u001b[0m6.962    \u001b[0m | \u001b[0m12.52    \u001b[0m | \u001b[0m0.4492   \u001b[0m | \u001b[0m138.1    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-0.8754  \u001b[0m | \u001b[0m6.285    \u001b[0m | \u001b[0m10.37    \u001b[0m | \u001b[0m0.4829   \u001b[0m | \u001b[0m150.2    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-0.8778  \u001b[0m | \u001b[0m6.051    \u001b[0m | \u001b[0m12.79    \u001b[0m | \u001b[0m0.5725   \u001b[0m | \u001b[0m134.4    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-0.8755  \u001b[0m | \u001b[0m6.145    \u001b[0m | \u001b[0m14.89    \u001b[0m | \u001b[0m0.5957   \u001b[0m | \u001b[0m134.5    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-0.8748  \u001b[0m | \u001b[0m6.672    \u001b[0m | \u001b[0m17.62    \u001b[0m | \u001b[0m0.3713   \u001b[0m | \u001b[0m163.7    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-0.8754  \u001b[0m | \u001b[0m6.368    \u001b[0m | \u001b[0m16.32    \u001b[0m | \u001b[0m0.4901   \u001b[0m | \u001b[0m152.1    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-0.8743  \u001b[0m | \u001b[0m6.09     \u001b[0m | \u001b[0m18.35    \u001b[0m | \u001b[0m0.3962   \u001b[0m | \u001b[0m131.2    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-0.8759  \u001b[0m | \u001b[0m6.041    \u001b[0m | \u001b[0m15.91    \u001b[0m | \u001b[0m0.5033   \u001b[0m | \u001b[0m121.0    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-0.8756  \u001b[0m | \u001b[0m6.512    \u001b[0m | \u001b[0m12.26    \u001b[0m | \u001b[0m0.4936   \u001b[0m | \u001b[0m130.5    \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-0.8781  \u001b[0m | \u001b[0m6.691    \u001b[0m | \u001b[0m13.87    \u001b[0m | \u001b[0m0.581    \u001b[0m | \u001b[0m128.3    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-0.8779  \u001b[0m | \u001b[0m6.341    \u001b[0m | \u001b[0m11.13    \u001b[0m | \u001b[0m0.5774   \u001b[0m | \u001b[0m172.6    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-0.878   \u001b[0m | \u001b[0m6.258    \u001b[0m | \u001b[0m16.6     \u001b[0m | \u001b[0m0.5452   \u001b[0m | \u001b[0m153.3    \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-0.8755  \u001b[0m | \u001b[0m6.53     \u001b[0m | \u001b[0m12.42    \u001b[0m | \u001b[0m0.3279   \u001b[0m | \u001b[0m173.8    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-0.8774  \u001b[0m | \u001b[0m6.9      \u001b[0m | \u001b[0m16.33    \u001b[0m | \u001b[0m0.4017   \u001b[0m | \u001b[0m141.0    \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-0.8757  \u001b[0m | \u001b[0m6.726    \u001b[0m | \u001b[0m18.97    \u001b[0m | \u001b[0m0.5661   \u001b[0m | \u001b[0m166.8    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-0.8739  \u001b[0m | \u001b[0m6.642    \u001b[0m | \u001b[0m10.84    \u001b[0m | \u001b[0m0.3485   \u001b[0m | \u001b[0m173.9    \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-0.8767  \u001b[0m | \u001b[0m6.606    \u001b[0m | \u001b[0m10.09    \u001b[0m | \u001b[0m0.3304   \u001b[0m | \u001b[0m159.8    \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-0.8749  \u001b[0m | \u001b[0m6.005    \u001b[0m | \u001b[0m11.61    \u001b[0m | \u001b[0m0.4646   \u001b[0m | \u001b[0m161.5    \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.652    \u001b[0m | \u001b[0m12.24    \u001b[0m | \u001b[0m0.5137   \u001b[0m | \u001b[0m134.2    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-0.8755  \u001b[0m | \u001b[0m6.325    \u001b[0m | \u001b[0m17.46    \u001b[0m | \u001b[0m0.4949   \u001b[0m | \u001b[0m171.0    \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m-0.8752  \u001b[0m | \u001b[0m6.658    \u001b[0m | \u001b[0m15.68    \u001b[0m | \u001b[0m0.3281   \u001b[0m | \u001b[0m142.1    \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m-0.8774  \u001b[0m | \u001b[0m6.265    \u001b[0m | \u001b[0m12.44    \u001b[0m | \u001b[0m0.5919   \u001b[0m | \u001b[0m143.6    \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m-0.878   \u001b[0m | \u001b[0m6.892    \u001b[0m | \u001b[0m16.31    \u001b[0m | \u001b[0m0.5384   \u001b[0m | \u001b[0m150.2    \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-0.8735  \u001b[0m | \u001b[0m6.577    \u001b[0m | \u001b[0m14.93    \u001b[0m | \u001b[0m0.3586   \u001b[0m | \u001b[0m163.3    \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-0.8768  \u001b[0m | \u001b[0m6.281    \u001b[0m | \u001b[0m10.24    \u001b[0m | \u001b[0m0.4936   \u001b[0m | \u001b[0m130.6    \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-0.8761  \u001b[0m | \u001b[0m6.94     \u001b[0m | \u001b[0m19.54    \u001b[0m | \u001b[0m0.5745   \u001b[0m | \u001b[0m142.2    \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-0.8759  \u001b[0m | \u001b[0m6.015    \u001b[0m | \u001b[0m19.28    \u001b[0m | \u001b[0m0.4285   \u001b[0m | \u001b[0m178.0    \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-0.8737  \u001b[0m | \u001b[0m6.964    \u001b[0m | \u001b[0m18.53    \u001b[0m | \u001b[0m0.3883   \u001b[0m | \u001b[0m143.1    \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-0.8741  \u001b[0m | \u001b[0m6.851    \u001b[0m | \u001b[0m13.17    \u001b[0m | \u001b[0m0.3508   \u001b[0m | \u001b[0m153.4    \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-0.8736  \u001b[0m | \u001b[0m6.936    \u001b[0m | \u001b[0m16.96    \u001b[0m | \u001b[0m0.471    \u001b[0m | \u001b[0m125.8    \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-0.8729  \u001b[0m | \u001b[0m6.615    \u001b[0m | \u001b[0m19.9     \u001b[0m | \u001b[0m0.342    \u001b[0m | \u001b[0m151.1    \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-0.8735  \u001b[0m | \u001b[0m6.877    \u001b[0m | \u001b[0m17.41    \u001b[0m | \u001b[0m0.5091   \u001b[0m | \u001b[0m162.1    \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-0.8774  \u001b[0m | \u001b[0m6.359    \u001b[0m | \u001b[0m12.94    \u001b[0m | \u001b[0m0.5428   \u001b[0m | \u001b[0m168.6    \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m-0.8755  \u001b[0m | \u001b[0m6.867    \u001b[0m | \u001b[0m19.13    \u001b[0m | \u001b[0m0.4534   \u001b[0m | \u001b[0m150.1    \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-0.8734  \u001b[0m | \u001b[0m6.798    \u001b[0m | \u001b[0m16.5     \u001b[0m | \u001b[0m0.5106   \u001b[0m | \u001b[0m167.7    \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-0.8773  \u001b[0m | \u001b[0m6.89     \u001b[0m | \u001b[0m13.38    \u001b[0m | \u001b[0m0.4127   \u001b[0m | \u001b[0m125.6    \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m-0.8733  \u001b[0m | \u001b[0m6.578    \u001b[0m | \u001b[0m10.36    \u001b[0m | \u001b[0m0.4397   \u001b[0m | \u001b[0m152.6    \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-0.8743  \u001b[0m | \u001b[0m6.287    \u001b[0m | \u001b[0m15.91    \u001b[0m | \u001b[0m0.3092   \u001b[0m | \u001b[0m122.2    \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-0.8737  \u001b[0m | \u001b[0m6.823    \u001b[0m | \u001b[0m13.6     \u001b[0m | \u001b[0m0.3381   \u001b[0m | \u001b[0m151.3    \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m-0.8746  \u001b[0m | \u001b[0m6.77     \u001b[0m | \u001b[0m12.16    \u001b[0m | \u001b[0m0.4869   \u001b[0m | \u001b[0m125.1    \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.052    \u001b[0m | \u001b[0m15.31    \u001b[0m | \u001b[0m0.4622   \u001b[0m | \u001b[0m158.2    \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-0.8759  \u001b[0m | \u001b[0m6.726    \u001b[0m | \u001b[0m19.76    \u001b[0m | \u001b[0m0.4549   \u001b[0m | \u001b[0m139.4    \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-0.8742  \u001b[0m | \u001b[0m6.795    \u001b[0m | \u001b[0m12.71    \u001b[0m | \u001b[0m0.4317   \u001b[0m | \u001b[0m124.7    \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m-0.8766  \u001b[0m | \u001b[0m6.025    \u001b[0m | \u001b[0m19.63    \u001b[0m | \u001b[0m0.5508   \u001b[0m | \u001b[0m161.8    \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m-0.8756  \u001b[0m | \u001b[0m6.409    \u001b[0m | \u001b[0m11.73    \u001b[0m | \u001b[0m0.3469   \u001b[0m | \u001b[0m135.0    \u001b[0m |\n",
      "| \u001b[95m81       \u001b[0m | \u001b[95m-0.8727  \u001b[0m | \u001b[95m6.549    \u001b[0m | \u001b[95m17.15    \u001b[0m | \u001b[95m0.4981   \u001b[0m | \u001b[95m136.8    \u001b[0m |\n",
      "| \u001b[0m82       \u001b[0m | \u001b[0m-0.874   \u001b[0m | \u001b[0m6.955    \u001b[0m | \u001b[0m17.38    \u001b[0m | \u001b[0m0.4663   \u001b[0m | \u001b[0m156.7    \u001b[0m |\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m-0.874   \u001b[0m | \u001b[0m6.42     \u001b[0m | \u001b[0m12.48    \u001b[0m | \u001b[0m0.4068   \u001b[0m | \u001b[0m165.5    \u001b[0m |\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m-0.8746  \u001b[0m | \u001b[0m6.014    \u001b[0m | \u001b[0m11.16    \u001b[0m | \u001b[0m0.3138   \u001b[0m | \u001b[0m122.4    \u001b[0m |\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m-0.8733  \u001b[0m | \u001b[0m6.855    \u001b[0m | \u001b[0m17.04    \u001b[0m | \u001b[0m0.4423   \u001b[0m | \u001b[0m125.9    \u001b[0m |\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m-0.8787  \u001b[0m | \u001b[0m6.492    \u001b[0m | \u001b[0m14.73    \u001b[0m | \u001b[0m0.352    \u001b[0m | \u001b[0m146.0    \u001b[0m |\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m-0.8754  \u001b[0m | \u001b[0m6.399    \u001b[0m | \u001b[0m16.16    \u001b[0m | \u001b[0m0.4905   \u001b[0m | \u001b[0m122.7    \u001b[0m |\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m-0.8745  \u001b[0m | \u001b[0m6.375    \u001b[0m | \u001b[0m16.26    \u001b[0m | \u001b[0m0.4509   \u001b[0m | \u001b[0m171.4    \u001b[0m |\n",
      "| \u001b[0m89       \u001b[0m | \u001b[0m-0.8746  \u001b[0m | \u001b[0m6.659    \u001b[0m | \u001b[0m11.63    \u001b[0m | \u001b[0m0.3212   \u001b[0m | \u001b[0m158.5    \u001b[0m |\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m-0.8764  \u001b[0m | \u001b[0m6.027    \u001b[0m | \u001b[0m15.86    \u001b[0m | \u001b[0m0.5821   \u001b[0m | \u001b[0m154.5    \u001b[0m |\n",
      "| \u001b[0m91       \u001b[0m | \u001b[0m-0.8765  \u001b[0m | \u001b[0m6.388    \u001b[0m | \u001b[0m16.43    \u001b[0m | \u001b[0m0.4375   \u001b[0m | \u001b[0m152.7    \u001b[0m |\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m-0.8797  \u001b[0m | \u001b[0m6.941    \u001b[0m | \u001b[0m13.86    \u001b[0m | \u001b[0m0.5884   \u001b[0m | \u001b[0m174.3    \u001b[0m |\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m-0.8753  \u001b[0m | \u001b[0m6.196    \u001b[0m | \u001b[0m10.69    \u001b[0m | \u001b[0m0.3302   \u001b[0m | \u001b[0m121.1    \u001b[0m |\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m-0.8773  \u001b[0m | \u001b[0m6.094    \u001b[0m | \u001b[0m16.83    \u001b[0m | \u001b[0m0.3214   \u001b[0m | \u001b[0m139.1    \u001b[0m |\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m-0.8752  \u001b[0m | \u001b[0m6.845    \u001b[0m | \u001b[0m10.23    \u001b[0m | \u001b[0m0.5443   \u001b[0m | \u001b[0m136.9    \u001b[0m |\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m-0.8775  \u001b[0m | \u001b[0m6.118    \u001b[0m | \u001b[0m16.97    \u001b[0m | \u001b[0m0.4887   \u001b[0m | \u001b[0m172.6    \u001b[0m |\n",
      "| \u001b[95m97       \u001b[0m | \u001b[95m-0.8716  \u001b[0m | \u001b[95m6.735    \u001b[0m | \u001b[95m18.03    \u001b[0m | \u001b[95m0.3846   \u001b[0m | \u001b[95m130.6    \u001b[0m |\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m-0.8799  \u001b[0m | \u001b[0m6.751    \u001b[0m | \u001b[0m18.07    \u001b[0m | \u001b[0m0.5972   \u001b[0m | \u001b[0m144.8    \u001b[0m |\n",
      "| \u001b[0m99       \u001b[0m | \u001b[0m-0.8761  \u001b[0m | \u001b[0m6.372    \u001b[0m | \u001b[0m17.76    \u001b[0m | \u001b[0m0.4022   \u001b[0m | \u001b[0m175.8    \u001b[0m |\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m-0.8763  \u001b[0m | \u001b[0m6.858    \u001b[0m | \u001b[0m14.29    \u001b[0m | \u001b[0m0.5253   \u001b[0m | \u001b[0m165.3    \u001b[0m |\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m-0.8736  \u001b[0m | \u001b[0m6.103    \u001b[0m | \u001b[0m19.03    \u001b[0m | \u001b[0m0.4516   \u001b[0m | \u001b[0m169.6    \u001b[0m |\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m-0.8766  \u001b[0m | \u001b[0m6.32     \u001b[0m | \u001b[0m18.96    \u001b[0m | \u001b[0m0.4168   \u001b[0m | \u001b[0m120.7    \u001b[0m |\n",
      "| \u001b[0m103      \u001b[0m | \u001b[0m-0.8773  \u001b[0m | \u001b[0m6.905    \u001b[0m | \u001b[0m10.91    \u001b[0m | \u001b[0m0.3958   \u001b[0m | \u001b[0m177.0    \u001b[0m |\n",
      "| \u001b[0m104      \u001b[0m | \u001b[0m-0.8737  \u001b[0m | \u001b[0m6.951    \u001b[0m | \u001b[0m15.73    \u001b[0m | \u001b[0m0.4896   \u001b[0m | \u001b[0m146.9    \u001b[0m |\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m-0.8758  \u001b[0m | \u001b[0m6.293    \u001b[0m | \u001b[0m13.29    \u001b[0m | \u001b[0m0.5018   \u001b[0m | \u001b[0m165.1    \u001b[0m |\n",
      "| \u001b[0m106      \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.792    \u001b[0m | \u001b[0m17.9     \u001b[0m | \u001b[0m0.3274   \u001b[0m | \u001b[0m149.7    \u001b[0m |\n",
      "| \u001b[0m107      \u001b[0m | \u001b[0m-0.8772  \u001b[0m | \u001b[0m6.058    \u001b[0m | \u001b[0m15.5     \u001b[0m | \u001b[0m0.4325   \u001b[0m | \u001b[0m173.3    \u001b[0m |\n",
      "| \u001b[0m108      \u001b[0m | \u001b[0m-0.8749  \u001b[0m | \u001b[0m6.351    \u001b[0m | \u001b[0m11.17    \u001b[0m | \u001b[0m0.3429   \u001b[0m | \u001b[0m165.7    \u001b[0m |\n",
      "| \u001b[0m109      \u001b[0m | \u001b[0m-0.874   \u001b[0m | \u001b[0m6.618    \u001b[0m | \u001b[0m11.01    \u001b[0m | \u001b[0m0.3252   \u001b[0m | \u001b[0m162.1    \u001b[0m |\n",
      "| \u001b[0m110      \u001b[0m | \u001b[0m-0.8749  \u001b[0m | \u001b[0m6.073    \u001b[0m | \u001b[0m18.22    \u001b[0m | \u001b[0m0.5119   \u001b[0m | \u001b[0m124.9    \u001b[0m |\n",
      "| \u001b[0m111      \u001b[0m | \u001b[0m-0.8762  \u001b[0m | \u001b[0m6.085    \u001b[0m | \u001b[0m19.87    \u001b[0m | \u001b[0m0.4123   \u001b[0m | \u001b[0m142.2    \u001b[0m |\n",
      "| \u001b[0m112      \u001b[0m | \u001b[0m-0.8784  \u001b[0m | \u001b[0m6.813    \u001b[0m | \u001b[0m19.47    \u001b[0m | \u001b[0m0.5958   \u001b[0m | \u001b[0m165.2    \u001b[0m |\n",
      "| \u001b[0m113      \u001b[0m | \u001b[0m-0.8751  \u001b[0m | \u001b[0m6.376    \u001b[0m | \u001b[0m10.84    \u001b[0m | \u001b[0m0.5331   \u001b[0m | \u001b[0m153.5    \u001b[0m |\n",
      "| \u001b[0m114      \u001b[0m | \u001b[0m-0.8758  \u001b[0m | \u001b[0m6.424    \u001b[0m | \u001b[0m19.06    \u001b[0m | \u001b[0m0.3334   \u001b[0m | \u001b[0m149.6    \u001b[0m |\n",
      "| \u001b[0m115      \u001b[0m | \u001b[0m-0.8766  \u001b[0m | \u001b[0m6.011    \u001b[0m | \u001b[0m14.69    \u001b[0m | \u001b[0m0.3169   \u001b[0m | \u001b[0m127.1    \u001b[0m |\n",
      "| \u001b[0m116      \u001b[0m | \u001b[0m-0.8753  \u001b[0m | \u001b[0m6.118    \u001b[0m | \u001b[0m16.49    \u001b[0m | \u001b[0m0.5238   \u001b[0m | \u001b[0m155.0    \u001b[0m |\n",
      "| \u001b[0m117      \u001b[0m | \u001b[0m-0.8771  \u001b[0m | \u001b[0m6.962    \u001b[0m | \u001b[0m13.75    \u001b[0m | \u001b[0m0.3857   \u001b[0m | \u001b[0m172.1    \u001b[0m |\n",
      "| \u001b[0m118      \u001b[0m | \u001b[0m-0.8739  \u001b[0m | \u001b[0m6.224    \u001b[0m | \u001b[0m19.63    \u001b[0m | \u001b[0m0.3036   \u001b[0m | \u001b[0m178.2    \u001b[0m |\n",
      "| \u001b[0m119      \u001b[0m | \u001b[0m-0.8738  \u001b[0m | \u001b[0m6.043    \u001b[0m | \u001b[0m18.91    \u001b[0m | \u001b[0m0.4583   \u001b[0m | \u001b[0m179.6    \u001b[0m |\n",
      "| \u001b[0m120      \u001b[0m | \u001b[0m-0.8768  \u001b[0m | \u001b[0m6.074    \u001b[0m | \u001b[0m15.54    \u001b[0m | \u001b[0m0.5908   \u001b[0m | \u001b[0m151.4    \u001b[0m |\n",
      "| \u001b[0m121      \u001b[0m | \u001b[0m-0.876   \u001b[0m | \u001b[0m6.629    \u001b[0m | \u001b[0m16.96    \u001b[0m | \u001b[0m0.4364   \u001b[0m | \u001b[0m157.7    \u001b[0m |\n",
      "| \u001b[0m122      \u001b[0m | \u001b[0m-0.8757  \u001b[0m | \u001b[0m6.584    \u001b[0m | \u001b[0m19.01    \u001b[0m | \u001b[0m0.3136   \u001b[0m | \u001b[0m136.9    \u001b[0m |\n",
      "| \u001b[0m123      \u001b[0m | \u001b[0m-0.8768  \u001b[0m | \u001b[0m6.95     \u001b[0m | \u001b[0m18.9     \u001b[0m | \u001b[0m0.4367   \u001b[0m | \u001b[0m157.2    \u001b[0m |\n",
      "| \u001b[0m124      \u001b[0m | \u001b[0m-0.8739  \u001b[0m | \u001b[0m6.277    \u001b[0m | \u001b[0m11.88    \u001b[0m | \u001b[0m0.4391   \u001b[0m | \u001b[0m141.2    \u001b[0m |\n",
      "| \u001b[0m125      \u001b[0m | \u001b[0m-0.8772  \u001b[0m | \u001b[0m6.584    \u001b[0m | \u001b[0m10.78    \u001b[0m | \u001b[0m0.5923   \u001b[0m | \u001b[0m179.2    \u001b[0m |\n",
      "| \u001b[0m126      \u001b[0m | \u001b[0m-0.8743  \u001b[0m | \u001b[0m6.698    \u001b[0m | \u001b[0m15.36    \u001b[0m | \u001b[0m0.3929   \u001b[0m | \u001b[0m168.8    \u001b[0m |\n",
      "| \u001b[0m127      \u001b[0m | \u001b[0m-0.8777  \u001b[0m | \u001b[0m6.685    \u001b[0m | \u001b[0m11.63    \u001b[0m | \u001b[0m0.5733   \u001b[0m | \u001b[0m169.4    \u001b[0m |\n",
      "| \u001b[0m128      \u001b[0m | \u001b[0m-0.8753  \u001b[0m | \u001b[0m6.95     \u001b[0m | \u001b[0m17.26    \u001b[0m | \u001b[0m0.484    \u001b[0m | \u001b[0m145.1    \u001b[0m |\n",
      "| \u001b[0m129      \u001b[0m | \u001b[0m-0.8757  \u001b[0m | \u001b[0m6.933    \u001b[0m | \u001b[0m18.66    \u001b[0m | \u001b[0m0.3136   \u001b[0m | \u001b[0m121.6    \u001b[0m |\n",
      "| \u001b[0m130      \u001b[0m | \u001b[0m-0.8793  \u001b[0m | \u001b[0m6.376    \u001b[0m | \u001b[0m18.11    \u001b[0m | \u001b[0m0.5962   \u001b[0m | \u001b[0m129.0    \u001b[0m |\n",
      "| \u001b[0m131      \u001b[0m | \u001b[0m-0.8769  \u001b[0m | \u001b[0m6.594    \u001b[0m | \u001b[0m13.81    \u001b[0m | \u001b[0m0.591    \u001b[0m | \u001b[0m170.5    \u001b[0m |\n",
      "| \u001b[0m132      \u001b[0m | \u001b[0m-0.8746  \u001b[0m | \u001b[0m6.838    \u001b[0m | \u001b[0m14.69    \u001b[0m | \u001b[0m0.4244   \u001b[0m | \u001b[0m136.4    \u001b[0m |\n",
      "| \u001b[0m133      \u001b[0m | \u001b[0m-0.8769  \u001b[0m | \u001b[0m6.056    \u001b[0m | \u001b[0m18.65    \u001b[0m | \u001b[0m0.5439   \u001b[0m | \u001b[0m180.0    \u001b[0m |\n",
      "| \u001b[0m134      \u001b[0m | \u001b[0m-0.8755  \u001b[0m | \u001b[0m6.997    \u001b[0m | \u001b[0m15.55    \u001b[0m | \u001b[0m0.5307   \u001b[0m | \u001b[0m176.7    \u001b[0m |\n",
      "| \u001b[0m135      \u001b[0m | \u001b[0m-0.8751  \u001b[0m | \u001b[0m6.85     \u001b[0m | \u001b[0m12.47    \u001b[0m | \u001b[0m0.4352   \u001b[0m | \u001b[0m127.7    \u001b[0m |\n",
      "| \u001b[0m136      \u001b[0m | \u001b[0m-0.8741  \u001b[0m | \u001b[0m6.954    \u001b[0m | \u001b[0m16.06    \u001b[0m | \u001b[0m0.3686   \u001b[0m | \u001b[0m160.3    \u001b[0m |\n",
      "| \u001b[0m137      \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.618    \u001b[0m | \u001b[0m13.58    \u001b[0m | \u001b[0m0.3341   \u001b[0m | \u001b[0m160.3    \u001b[0m |\n",
      "| \u001b[0m138      \u001b[0m | \u001b[0m-0.8742  \u001b[0m | \u001b[0m6.52     \u001b[0m | \u001b[0m17.72    \u001b[0m | \u001b[0m0.456    \u001b[0m | \u001b[0m171.1    \u001b[0m |\n",
      "| \u001b[0m139      \u001b[0m | \u001b[0m-0.8768  \u001b[0m | \u001b[0m6.552    \u001b[0m | \u001b[0m15.61    \u001b[0m | \u001b[0m0.563    \u001b[0m | \u001b[0m144.2    \u001b[0m |\n",
      "| \u001b[0m140      \u001b[0m | \u001b[0m-0.874   \u001b[0m | \u001b[0m6.134    \u001b[0m | \u001b[0m10.29    \u001b[0m | \u001b[0m0.5265   \u001b[0m | \u001b[0m157.2    \u001b[0m |\n",
      "| \u001b[0m141      \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.704    \u001b[0m | \u001b[0m12.13    \u001b[0m | \u001b[0m0.3409   \u001b[0m | \u001b[0m120.9    \u001b[0m |\n",
      "| \u001b[0m142      \u001b[0m | \u001b[0m-0.8729  \u001b[0m | \u001b[0m6.351    \u001b[0m | \u001b[0m15.9     \u001b[0m | \u001b[0m0.4177   \u001b[0m | \u001b[0m146.2    \u001b[0m |\n",
      "| \u001b[0m143      \u001b[0m | \u001b[0m-0.8743  \u001b[0m | \u001b[0m6.904    \u001b[0m | \u001b[0m13.48    \u001b[0m | \u001b[0m0.4542   \u001b[0m | \u001b[0m167.0    \u001b[0m |\n",
      "| \u001b[0m144      \u001b[0m | \u001b[0m-0.8789  \u001b[0m | \u001b[0m6.397    \u001b[0m | \u001b[0m16.22    \u001b[0m | \u001b[0m0.5587   \u001b[0m | \u001b[0m177.0    \u001b[0m |\n",
      "| \u001b[0m145      \u001b[0m | \u001b[0m-0.8777  \u001b[0m | \u001b[0m6.147    \u001b[0m | \u001b[0m19.27    \u001b[0m | \u001b[0m0.4476   \u001b[0m | \u001b[0m135.5    \u001b[0m |\n",
      "| \u001b[0m146      \u001b[0m | \u001b[0m-0.8789  \u001b[0m | \u001b[0m6.459    \u001b[0m | \u001b[0m19.8     \u001b[0m | \u001b[0m0.4478   \u001b[0m | \u001b[0m139.7    \u001b[0m |\n",
      "| \u001b[0m147      \u001b[0m | \u001b[0m-0.8755  \u001b[0m | \u001b[0m6.633    \u001b[0m | \u001b[0m12.4     \u001b[0m | \u001b[0m0.3228   \u001b[0m | \u001b[0m127.7    \u001b[0m |\n",
      "| \u001b[0m148      \u001b[0m | \u001b[0m-0.8749  \u001b[0m | \u001b[0m6.128    \u001b[0m | \u001b[0m11.52    \u001b[0m | \u001b[0m0.3416   \u001b[0m | \u001b[0m158.5    \u001b[0m |\n",
      "| \u001b[0m149      \u001b[0m | \u001b[0m-0.8737  \u001b[0m | \u001b[0m6.182    \u001b[0m | \u001b[0m13.46    \u001b[0m | \u001b[0m0.569    \u001b[0m | \u001b[0m148.4    \u001b[0m |\n",
      "| \u001b[0m150      \u001b[0m | \u001b[0m-0.8753  \u001b[0m | \u001b[0m6.668    \u001b[0m | \u001b[0m11.72    \u001b[0m | \u001b[0m0.3577   \u001b[0m | \u001b[0m122.5    \u001b[0m |\n",
      "| \u001b[0m151      \u001b[0m | \u001b[0m-0.8756  \u001b[0m | \u001b[0m6.169    \u001b[0m | \u001b[0m12.79    \u001b[0m | \u001b[0m0.3531   \u001b[0m | \u001b[0m125.3    \u001b[0m |\n",
      "| \u001b[0m152      \u001b[0m | \u001b[0m-0.8749  \u001b[0m | \u001b[0m6.121    \u001b[0m | \u001b[0m14.61    \u001b[0m | \u001b[0m0.3619   \u001b[0m | \u001b[0m141.9    \u001b[0m |\n",
      "| \u001b[0m153      \u001b[0m | \u001b[0m-0.8733  \u001b[0m | \u001b[0m6.503    \u001b[0m | \u001b[0m16.9     \u001b[0m | \u001b[0m0.3118   \u001b[0m | \u001b[0m168.0    \u001b[0m |\n",
      "| \u001b[0m154      \u001b[0m | \u001b[0m-0.8777  \u001b[0m | \u001b[0m6.628    \u001b[0m | \u001b[0m10.82    \u001b[0m | \u001b[0m0.5621   \u001b[0m | \u001b[0m175.3    \u001b[0m |\n",
      "| \u001b[0m155      \u001b[0m | \u001b[0m-0.8774  \u001b[0m | \u001b[0m6.061    \u001b[0m | \u001b[0m12.77    \u001b[0m | \u001b[0m0.5419   \u001b[0m | \u001b[0m164.9    \u001b[0m |\n",
      "| \u001b[0m156      \u001b[0m | \u001b[0m-0.8751  \u001b[0m | \u001b[0m6.185    \u001b[0m | \u001b[0m12.09    \u001b[0m | \u001b[0m0.4111   \u001b[0m | \u001b[0m149.1    \u001b[0m |\n",
      "| \u001b[0m157      \u001b[0m | \u001b[0m-0.8756  \u001b[0m | \u001b[0m6.618    \u001b[0m | \u001b[0m13.69    \u001b[0m | \u001b[0m0.4388   \u001b[0m | \u001b[0m164.8    \u001b[0m |\n",
      "| \u001b[0m158      \u001b[0m | \u001b[0m-0.8745  \u001b[0m | \u001b[0m6.037    \u001b[0m | \u001b[0m12.52    \u001b[0m | \u001b[0m0.514    \u001b[0m | \u001b[0m173.7    \u001b[0m |\n",
      "| \u001b[0m159      \u001b[0m | \u001b[0m-0.8764  \u001b[0m | \u001b[0m6.512    \u001b[0m | \u001b[0m15.32    \u001b[0m | \u001b[0m0.3322   \u001b[0m | \u001b[0m146.8    \u001b[0m |\n",
      "| \u001b[0m160      \u001b[0m | \u001b[0m-0.8768  \u001b[0m | \u001b[0m6.533    \u001b[0m | \u001b[0m12.42    \u001b[0m | \u001b[0m0.3808   \u001b[0m | \u001b[0m142.6    \u001b[0m |\n",
      "| \u001b[0m161      \u001b[0m | \u001b[0m-0.8747  \u001b[0m | \u001b[0m6.02     \u001b[0m | \u001b[0m13.22    \u001b[0m | \u001b[0m0.3634   \u001b[0m | \u001b[0m139.6    \u001b[0m |\n",
      "| \u001b[0m162      \u001b[0m | \u001b[0m-0.8743  \u001b[0m | \u001b[0m6.12     \u001b[0m | \u001b[0m18.91    \u001b[0m | \u001b[0m0.4781   \u001b[0m | \u001b[0m160.7    \u001b[0m |\n",
      "| \u001b[0m163      \u001b[0m | \u001b[0m-0.873   \u001b[0m | \u001b[0m6.789    \u001b[0m | \u001b[0m14.98    \u001b[0m | \u001b[0m0.3261   \u001b[0m | \u001b[0m152.2    \u001b[0m |\n",
      "| \u001b[0m164      \u001b[0m | \u001b[0m-0.8739  \u001b[0m | \u001b[0m6.587    \u001b[0m | \u001b[0m17.45    \u001b[0m | \u001b[0m0.4295   \u001b[0m | \u001b[0m127.7    \u001b[0m |\n",
      "| \u001b[0m165      \u001b[0m | \u001b[0m-0.8748  \u001b[0m | \u001b[0m6.284    \u001b[0m | \u001b[0m13.63    \u001b[0m | \u001b[0m0.4938   \u001b[0m | \u001b[0m154.2    \u001b[0m |\n",
      "| \u001b[0m166      \u001b[0m | \u001b[0m-0.8746  \u001b[0m | \u001b[0m6.356    \u001b[0m | \u001b[0m19.87    \u001b[0m | \u001b[0m0.4817   \u001b[0m | \u001b[0m134.2    \u001b[0m |\n",
      "| \u001b[0m167      \u001b[0m | \u001b[0m-0.8746  \u001b[0m | \u001b[0m6.102    \u001b[0m | \u001b[0m11.53    \u001b[0m | \u001b[0m0.3738   \u001b[0m | \u001b[0m129.6    \u001b[0m |\n",
      "| \u001b[0m168      \u001b[0m | \u001b[0m-0.8735  \u001b[0m | \u001b[0m6.187    \u001b[0m | \u001b[0m12.85    \u001b[0m | \u001b[0m0.352    \u001b[0m | \u001b[0m173.8    \u001b[0m |\n",
      "| \u001b[0m169      \u001b[0m | \u001b[0m-0.8739  \u001b[0m | \u001b[0m6.08     \u001b[0m | \u001b[0m15.25    \u001b[0m | \u001b[0m0.4231   \u001b[0m | \u001b[0m178.9    \u001b[0m |\n",
      "| \u001b[0m170      \u001b[0m | \u001b[0m-0.8732  \u001b[0m | \u001b[0m6.112    \u001b[0m | \u001b[0m13.98    \u001b[0m | \u001b[0m0.5908   \u001b[0m | \u001b[0m171.9    \u001b[0m |\n",
      "| \u001b[0m171      \u001b[0m | \u001b[0m-0.8746  \u001b[0m | \u001b[0m6.817    \u001b[0m | \u001b[0m12.58    \u001b[0m | \u001b[0m0.3513   \u001b[0m | \u001b[0m160.1    \u001b[0m |\n",
      "| \u001b[0m172      \u001b[0m | \u001b[0m-0.8769  \u001b[0m | \u001b[0m6.929    \u001b[0m | \u001b[0m15.57    \u001b[0m | \u001b[0m0.4715   \u001b[0m | \u001b[0m136.8    \u001b[0m |\n",
      "| \u001b[0m173      \u001b[0m | \u001b[0m-0.876   \u001b[0m | \u001b[0m6.769    \u001b[0m | \u001b[0m11.87    \u001b[0m | \u001b[0m0.3971   \u001b[0m | \u001b[0m145.5    \u001b[0m |\n",
      "| \u001b[0m174      \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.508    \u001b[0m | \u001b[0m12.42    \u001b[0m | \u001b[0m0.3345   \u001b[0m | \u001b[0m156.6    \u001b[0m |\n",
      "| \u001b[0m175      \u001b[0m | \u001b[0m-0.8761  \u001b[0m | \u001b[0m6.289    \u001b[0m | \u001b[0m15.81    \u001b[0m | \u001b[0m0.3463   \u001b[0m | \u001b[0m148.9    \u001b[0m |\n",
      "| \u001b[0m176      \u001b[0m | \u001b[0m-0.8776  \u001b[0m | \u001b[0m6.533    \u001b[0m | \u001b[0m10.52    \u001b[0m | \u001b[0m0.401    \u001b[0m | \u001b[0m128.1    \u001b[0m |\n",
      "| \u001b[0m177      \u001b[0m | \u001b[0m-0.8769  \u001b[0m | \u001b[0m6.063    \u001b[0m | \u001b[0m19.9     \u001b[0m | \u001b[0m0.3967   \u001b[0m | \u001b[0m168.6    \u001b[0m |\n",
      "| \u001b[0m178      \u001b[0m | \u001b[0m-0.8778  \u001b[0m | \u001b[0m6.255    \u001b[0m | \u001b[0m16.82    \u001b[0m | \u001b[0m0.5281   \u001b[0m | \u001b[0m155.7    \u001b[0m |\n",
      "| \u001b[0m179      \u001b[0m | \u001b[0m-0.8736  \u001b[0m | \u001b[0m6.472    \u001b[0m | \u001b[0m14.12    \u001b[0m | \u001b[0m0.4047   \u001b[0m | \u001b[0m175.8    \u001b[0m |\n",
      "| \u001b[0m180      \u001b[0m | \u001b[0m-0.8743  \u001b[0m | \u001b[0m6.831    \u001b[0m | \u001b[0m19.65    \u001b[0m | \u001b[0m0.3373   \u001b[0m | \u001b[0m163.9    \u001b[0m |\n",
      "| \u001b[0m181      \u001b[0m | \u001b[0m-0.8757  \u001b[0m | \u001b[0m6.938    \u001b[0m | \u001b[0m11.81    \u001b[0m | \u001b[0m0.3199   \u001b[0m | \u001b[0m164.5    \u001b[0m |\n",
      "| \u001b[0m182      \u001b[0m | \u001b[0m-0.8781  \u001b[0m | \u001b[0m6.574    \u001b[0m | \u001b[0m18.42    \u001b[0m | \u001b[0m0.3419   \u001b[0m | \u001b[0m167.7    \u001b[0m |\n",
      "| \u001b[0m183      \u001b[0m | \u001b[0m-0.8751  \u001b[0m | \u001b[0m6.202    \u001b[0m | \u001b[0m11.64    \u001b[0m | \u001b[0m0.3493   \u001b[0m | \u001b[0m168.9    \u001b[0m |\n",
      "| \u001b[0m184      \u001b[0m | \u001b[0m-0.8741  \u001b[0m | \u001b[0m6.665    \u001b[0m | \u001b[0m15.23    \u001b[0m | \u001b[0m0.4076   \u001b[0m | \u001b[0m172.6    \u001b[0m |\n",
      "| \u001b[0m185      \u001b[0m | \u001b[0m-0.8769  \u001b[0m | \u001b[0m6.392    \u001b[0m | \u001b[0m18.17    \u001b[0m | \u001b[0m0.4317   \u001b[0m | \u001b[0m142.6    \u001b[0m |\n",
      "| \u001b[0m186      \u001b[0m | \u001b[0m-0.8762  \u001b[0m | \u001b[0m6.463    \u001b[0m | \u001b[0m13.01    \u001b[0m | \u001b[0m0.5243   \u001b[0m | \u001b[0m150.2    \u001b[0m |\n",
      "| \u001b[0m187      \u001b[0m | \u001b[0m-0.8766  \u001b[0m | \u001b[0m6.232    \u001b[0m | \u001b[0m19.0     \u001b[0m | \u001b[0m0.4152   \u001b[0m | \u001b[0m152.6    \u001b[0m |\n",
      "| \u001b[0m188      \u001b[0m | \u001b[0m-0.8734  \u001b[0m | \u001b[0m6.906    \u001b[0m | \u001b[0m16.24    \u001b[0m | \u001b[0m0.3351   \u001b[0m | \u001b[0m176.4    \u001b[0m |\n",
      "| \u001b[0m189      \u001b[0m | \u001b[0m-0.8755  \u001b[0m | \u001b[0m6.628    \u001b[0m | \u001b[0m13.35    \u001b[0m | \u001b[0m0.3418   \u001b[0m | \u001b[0m167.6    \u001b[0m |\n",
      "| \u001b[0m190      \u001b[0m | \u001b[0m-0.8781  \u001b[0m | \u001b[0m6.62     \u001b[0m | \u001b[0m15.33    \u001b[0m | \u001b[0m0.5682   \u001b[0m | \u001b[0m167.3    \u001b[0m |\n",
      "| \u001b[0m191      \u001b[0m | \u001b[0m-0.8762  \u001b[0m | \u001b[0m6.152    \u001b[0m | \u001b[0m13.12    \u001b[0m | \u001b[0m0.3745   \u001b[0m | \u001b[0m164.6    \u001b[0m |\n",
      "| \u001b[0m192      \u001b[0m | \u001b[0m-0.8778  \u001b[0m | \u001b[0m6.034    \u001b[0m | \u001b[0m15.7     \u001b[0m | \u001b[0m0.5287   \u001b[0m | \u001b[0m172.6    \u001b[0m |\n",
      "| \u001b[0m193      \u001b[0m | \u001b[0m-0.8744  \u001b[0m | \u001b[0m6.342    \u001b[0m | \u001b[0m18.21    \u001b[0m | \u001b[0m0.3332   \u001b[0m | \u001b[0m170.8    \u001b[0m |\n",
      "| \u001b[0m194      \u001b[0m | \u001b[0m-0.8769  \u001b[0m | \u001b[0m6.127    \u001b[0m | \u001b[0m13.97    \u001b[0m | \u001b[0m0.5392   \u001b[0m | \u001b[0m129.0    \u001b[0m |\n",
      "| \u001b[0m195      \u001b[0m | \u001b[0m-0.8777  \u001b[0m | \u001b[0m6.229    \u001b[0m | \u001b[0m17.22    \u001b[0m | \u001b[0m0.516    \u001b[0m | \u001b[0m158.5    \u001b[0m |\n",
      "| \u001b[0m196      \u001b[0m | \u001b[0m-0.8722  \u001b[0m | \u001b[0m6.694    \u001b[0m | \u001b[0m15.43    \u001b[0m | \u001b[0m0.3755   \u001b[0m | \u001b[0m140.7    \u001b[0m |\n",
      "| \u001b[0m197      \u001b[0m | \u001b[0m-0.8744  \u001b[0m | \u001b[0m6.182    \u001b[0m | \u001b[0m19.08    \u001b[0m | \u001b[0m0.475    \u001b[0m | \u001b[0m144.1    \u001b[0m |\n",
      "| \u001b[0m198      \u001b[0m | \u001b[0m-0.8738  \u001b[0m | \u001b[0m6.462    \u001b[0m | \u001b[0m19.47    \u001b[0m | \u001b[0m0.346    \u001b[0m | \u001b[0m155.2    \u001b[0m |\n",
      "| \u001b[0m199      \u001b[0m | \u001b[0m-0.8761  \u001b[0m | \u001b[0m6.506    \u001b[0m | \u001b[0m16.11    \u001b[0m | \u001b[0m0.3054   \u001b[0m | \u001b[0m172.3    \u001b[0m |\n",
      "| \u001b[0m200      \u001b[0m | \u001b[0m-0.8737  \u001b[0m | \u001b[0m6.932    \u001b[0m | \u001b[0m15.65    \u001b[0m | \u001b[0m0.509    \u001b[0m | \u001b[0m175.3    \u001b[0m |\n",
      "| \u001b[0m201      \u001b[0m | \u001b[0m-0.8734  \u001b[0m | \u001b[0m6.602    \u001b[0m | \u001b[0m18.1     \u001b[0m | \u001b[0m0.3893   \u001b[0m | \u001b[0m130.8    \u001b[0m |\n",
      "| \u001b[0m202      \u001b[0m | \u001b[0m-0.874   \u001b[0m | \u001b[0m6.475    \u001b[0m | \u001b[0m14.09    \u001b[0m | \u001b[0m0.4028   \u001b[0m | \u001b[0m175.7    \u001b[0m |\n",
      "| \u001b[0m203      \u001b[0m | \u001b[0m-0.8733  \u001b[0m | \u001b[0m6.004    \u001b[0m | \u001b[0m10.4     \u001b[0m | \u001b[0m0.4399   \u001b[0m | \u001b[0m141.1    \u001b[0m |\n",
      "| \u001b[0m204      \u001b[0m | \u001b[0m-0.8766  \u001b[0m | \u001b[0m6.798    \u001b[0m | \u001b[0m17.88    \u001b[0m | \u001b[0m0.4149   \u001b[0m | \u001b[0m130.6    \u001b[0m |\n",
      "| \u001b[0m205      \u001b[0m | \u001b[0m-0.8768  \u001b[0m | \u001b[0m6.813    \u001b[0m | \u001b[0m18.09    \u001b[0m | \u001b[0m0.5292   \u001b[0m | \u001b[0m130.8    \u001b[0m |\n",
      "| \u001b[0m206      \u001b[0m | \u001b[0m-0.8746  \u001b[0m | \u001b[0m6.938    \u001b[0m | \u001b[0m17.06    \u001b[0m | \u001b[0m0.435    \u001b[0m | \u001b[0m179.9    \u001b[0m |\n",
      "| \u001b[0m207      \u001b[0m | \u001b[0m-0.8772  \u001b[0m | \u001b[0m6.775    \u001b[0m | \u001b[0m18.82    \u001b[0m | \u001b[0m0.3682   \u001b[0m | \u001b[0m142.3    \u001b[0m |\n",
      "| \u001b[0m208      \u001b[0m | \u001b[0m-0.8741  \u001b[0m | \u001b[0m6.765    \u001b[0m | \u001b[0m14.94    \u001b[0m | \u001b[0m0.4512   \u001b[0m | \u001b[0m152.2    \u001b[0m |\n",
      "| \u001b[0m209      \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.006    \u001b[0m | \u001b[0m14.59    \u001b[0m | \u001b[0m0.593    \u001b[0m | \u001b[0m151.6    \u001b[0m |\n",
      "| \u001b[0m210      \u001b[0m | \u001b[0m-0.8743  \u001b[0m | \u001b[0m6.743    \u001b[0m | \u001b[0m15.25    \u001b[0m | \u001b[0m0.3901   \u001b[0m | \u001b[0m121.2    \u001b[0m |\n",
      "| \u001b[0m211      \u001b[0m | \u001b[0m-0.8729  \u001b[0m | \u001b[0m6.738    \u001b[0m | \u001b[0m15.23    \u001b[0m | \u001b[0m0.414    \u001b[0m | \u001b[0m121.1    \u001b[0m |\n",
      "| \u001b[0m212      \u001b[0m | \u001b[0m-0.8739  \u001b[0m | \u001b[0m6.206    \u001b[0m | \u001b[0m19.7     \u001b[0m | \u001b[0m0.3043   \u001b[0m | \u001b[0m124.2    \u001b[0m |\n",
      "| \u001b[0m213      \u001b[0m | \u001b[0m-0.8745  \u001b[0m | \u001b[0m6.448    \u001b[0m | \u001b[0m10.88    \u001b[0m | \u001b[0m0.3155   \u001b[0m | \u001b[0m170.2    \u001b[0m |\n",
      "| \u001b[0m214      \u001b[0m | \u001b[0m-0.8775  \u001b[0m | \u001b[0m6.083    \u001b[0m | \u001b[0m17.98    \u001b[0m | \u001b[0m0.5766   \u001b[0m | \u001b[0m178.3    \u001b[0m |\n",
      "| \u001b[0m215      \u001b[0m | \u001b[0m-0.876   \u001b[0m | \u001b[0m6.365    \u001b[0m | \u001b[0m12.87    \u001b[0m | \u001b[0m0.5077   \u001b[0m | \u001b[0m160.0    \u001b[0m |\n",
      "| \u001b[0m216      \u001b[0m | \u001b[0m-0.8737  \u001b[0m | \u001b[0m6.332    \u001b[0m | \u001b[0m15.95    \u001b[0m | \u001b[0m0.4958   \u001b[0m | \u001b[0m146.2    \u001b[0m |\n",
      "| \u001b[0m217      \u001b[0m | \u001b[0m-0.8775  \u001b[0m | \u001b[0m6.714    \u001b[0m | \u001b[0m17.48    \u001b[0m | \u001b[0m0.313    \u001b[0m | \u001b[0m144.2    \u001b[0m |\n",
      "| \u001b[0m218      \u001b[0m | \u001b[0m-0.8762  \u001b[0m | \u001b[0m6.845    \u001b[0m | \u001b[0m17.18    \u001b[0m | \u001b[0m0.3886   \u001b[0m | \u001b[0m152.4    \u001b[0m |\n",
      "| \u001b[0m219      \u001b[0m | \u001b[0m-0.876   \u001b[0m | \u001b[0m6.084    \u001b[0m | \u001b[0m18.1     \u001b[0m | \u001b[0m0.5074   \u001b[0m | \u001b[0m156.3    \u001b[0m |\n",
      "| \u001b[0m220      \u001b[0m | \u001b[0m-0.8748  \u001b[0m | \u001b[0m6.88     \u001b[0m | \u001b[0m14.92    \u001b[0m | \u001b[0m0.3374   \u001b[0m | \u001b[0m152.2    \u001b[0m |\n",
      "| \u001b[0m221      \u001b[0m | \u001b[0m-0.8773  \u001b[0m | \u001b[0m6.73     \u001b[0m | \u001b[0m18.08    \u001b[0m | \u001b[0m0.3646   \u001b[0m | \u001b[0m130.6    \u001b[0m |\n",
      "| \u001b[0m222      \u001b[0m | \u001b[0m-0.8751  \u001b[0m | \u001b[0m6.058    \u001b[0m | \u001b[0m11.29    \u001b[0m | \u001b[0m0.4651   \u001b[0m | \u001b[0m172.2    \u001b[0m |\n",
      "| \u001b[0m223      \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.947    \u001b[0m | \u001b[0m16.04    \u001b[0m | \u001b[0m0.3506   \u001b[0m | \u001b[0m146.4    \u001b[0m |\n",
      "| \u001b[0m224      \u001b[0m | \u001b[0m-0.8745  \u001b[0m | \u001b[0m6.149    \u001b[0m | \u001b[0m19.42    \u001b[0m | \u001b[0m0.4605   \u001b[0m | \u001b[0m157.0    \u001b[0m |\n",
      "| \u001b[0m225      \u001b[0m | \u001b[0m-0.8773  \u001b[0m | \u001b[0m6.061    \u001b[0m | \u001b[0m15.16    \u001b[0m | \u001b[0m0.4281   \u001b[0m | \u001b[0m177.2    \u001b[0m |\n",
      "| \u001b[0m226      \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.347    \u001b[0m | \u001b[0m12.17    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m129.6    \u001b[0m |\n",
      "| \u001b[0m227      \u001b[0m | \u001b[0m-0.8735  \u001b[0m | \u001b[0m6.159    \u001b[0m | \u001b[0m15.4     \u001b[0m | \u001b[0m0.3945   \u001b[0m | \u001b[0m156.6    \u001b[0m |\n",
      "| \u001b[0m228      \u001b[0m | \u001b[0m-0.8754  \u001b[0m | \u001b[0m6.093    \u001b[0m | \u001b[0m17.51    \u001b[0m | \u001b[0m0.4969   \u001b[0m | \u001b[0m170.7    \u001b[0m |\n",
      "| \u001b[0m229      \u001b[0m | \u001b[0m-0.875   \u001b[0m | \u001b[0m6.716    \u001b[0m | \u001b[0m10.52    \u001b[0m | \u001b[0m0.4423   \u001b[0m | \u001b[0m130.5    \u001b[0m |\n",
      "| \u001b[0m230      \u001b[0m | \u001b[0m-0.8736  \u001b[0m | \u001b[0m6.9      \u001b[0m | \u001b[0m12.1     \u001b[0m | \u001b[0m0.4384   \u001b[0m | \u001b[0m128.6    \u001b[0m |\n",
      "| \u001b[0m231      \u001b[0m | \u001b[0m-0.8758  \u001b[0m | \u001b[0m6.838    \u001b[0m | \u001b[0m12.94    \u001b[0m | \u001b[0m0.5656   \u001b[0m | \u001b[0m161.4    \u001b[0m |\n",
      "| \u001b[0m232      \u001b[0m | \u001b[0m-0.8771  \u001b[0m | \u001b[0m6.829    \u001b[0m | \u001b[0m11.12    \u001b[0m | \u001b[0m0.3631   \u001b[0m | \u001b[0m171.5    \u001b[0m |\n",
      "| \u001b[0m233      \u001b[0m | \u001b[0m-0.8743  \u001b[0m | \u001b[0m6.601    \u001b[0m | \u001b[0m11.74    \u001b[0m | \u001b[0m0.4721   \u001b[0m | \u001b[0m167.1    \u001b[0m |\n",
      "| \u001b[0m234      \u001b[0m | \u001b[0m-0.8745  \u001b[0m | \u001b[0m6.798    \u001b[0m | \u001b[0m10.08    \u001b[0m | \u001b[0m0.3202   \u001b[0m | \u001b[0m174.0    \u001b[0m |\n",
      "| \u001b[0m235      \u001b[0m | \u001b[0m-0.8764  \u001b[0m | \u001b[0m6.082    \u001b[0m | \u001b[0m11.66    \u001b[0m | \u001b[0m0.5826   \u001b[0m | \u001b[0m176.8    \u001b[0m |\n",
      "| \u001b[0m236      \u001b[0m | \u001b[0m-0.8768  \u001b[0m | \u001b[0m6.618    \u001b[0m | \u001b[0m17.73    \u001b[0m | \u001b[0m0.5566   \u001b[0m | \u001b[0m146.2    \u001b[0m |\n",
      "| \u001b[0m237      \u001b[0m | \u001b[0m-0.8744  \u001b[0m | \u001b[0m6.228    \u001b[0m | \u001b[0m19.43    \u001b[0m | \u001b[0m0.4013   \u001b[0m | \u001b[0m174.1    \u001b[0m |\n",
      "| \u001b[0m238      \u001b[0m | \u001b[0m-0.8774  \u001b[0m | \u001b[0m6.225    \u001b[0m | \u001b[0m15.9     \u001b[0m | \u001b[0m0.5846   \u001b[0m | \u001b[0m172.2    \u001b[0m |\n",
      "| \u001b[0m239      \u001b[0m | \u001b[0m-0.8763  \u001b[0m | \u001b[0m6.641    \u001b[0m | \u001b[0m14.56    \u001b[0m | \u001b[0m0.5299   \u001b[0m | \u001b[0m168.6    \u001b[0m |\n",
      "| \u001b[0m240      \u001b[0m | \u001b[0m-0.8746  \u001b[0m | \u001b[0m6.224    \u001b[0m | \u001b[0m18.07    \u001b[0m | \u001b[0m0.3988   \u001b[0m | \u001b[0m132.8    \u001b[0m |\n",
      "| \u001b[0m241      \u001b[0m | \u001b[0m-0.8759  \u001b[0m | \u001b[0m6.116    \u001b[0m | \u001b[0m18.72    \u001b[0m | \u001b[0m0.3465   \u001b[0m | \u001b[0m125.9    \u001b[0m |\n",
      "| \u001b[0m242      \u001b[0m | \u001b[0m-0.8751  \u001b[0m | \u001b[0m6.265    \u001b[0m | \u001b[0m19.92    \u001b[0m | \u001b[0m0.4573   \u001b[0m | \u001b[0m178.3    \u001b[0m |\n",
      "| \u001b[0m243      \u001b[0m | \u001b[0m-0.8747  \u001b[0m | \u001b[0m6.787    \u001b[0m | \u001b[0m19.67    \u001b[0m | \u001b[0m0.5643   \u001b[0m | \u001b[0m151.6    \u001b[0m |\n",
      "| \u001b[0m244      \u001b[0m | \u001b[0m-0.8759  \u001b[0m | \u001b[0m6.707    \u001b[0m | \u001b[0m11.06    \u001b[0m | \u001b[0m0.3385   \u001b[0m | \u001b[0m135.3    \u001b[0m |\n",
      "| \u001b[0m245      \u001b[0m | \u001b[0m-0.8775  \u001b[0m | \u001b[0m6.21     \u001b[0m | \u001b[0m17.89    \u001b[0m | \u001b[0m0.5618   \u001b[0m | \u001b[0m143.8    \u001b[0m |\n",
      "| \u001b[0m246      \u001b[0m | \u001b[0m-0.8755  \u001b[0m | \u001b[0m6.39     \u001b[0m | \u001b[0m18.44    \u001b[0m | \u001b[0m0.5139   \u001b[0m | \u001b[0m144.1    \u001b[0m |\n",
      "| \u001b[0m247      \u001b[0m | \u001b[0m-0.8747  \u001b[0m | \u001b[0m6.65     \u001b[0m | \u001b[0m17.92    \u001b[0m | \u001b[0m0.494    \u001b[0m | \u001b[0m175.2    \u001b[0m |\n",
      "| \u001b[0m248      \u001b[0m | \u001b[0m-0.8749  \u001b[0m | \u001b[0m6.848    \u001b[0m | \u001b[0m10.23    \u001b[0m | \u001b[0m0.5066   \u001b[0m | \u001b[0m128.5    \u001b[0m |\n",
      "| \u001b[0m249      \u001b[0m | \u001b[0m-0.8758  \u001b[0m | \u001b[0m6.325    \u001b[0m | \u001b[0m13.58    \u001b[0m | \u001b[0m0.5592   \u001b[0m | \u001b[0m140.7    \u001b[0m |\n",
      "| \u001b[0m250      \u001b[0m | \u001b[0m-0.8745  \u001b[0m | \u001b[0m6.253    \u001b[0m | \u001b[0m15.95    \u001b[0m | \u001b[0m0.5682   \u001b[0m | \u001b[0m143.2    \u001b[0m |\n",
      "=========================================================================\n",
      "Best parameters found: {'depth': 6.735071043803885, 'l2_leaf_reg': 18.034809303848483, 'learning_rate': 0.3846103717713919, 'n_estimators': 130.64637262678337}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, y_train = prepare_test_data(train_df, 2) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "\n",
    "X_test, y_test = prepare_test_data(test_df, 2)\n",
    "# 定义目标函数\n",
    "def catboost_eval(depth, l2_leaf_reg, learning_rate, n_estimators):\n",
    "    params = {\n",
    "        'depth': int(depth),\n",
    "        'l2_leaf_reg': l2_leaf_reg,\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators': int(n_estimators),\n",
    "        'loss_function': 'RMSE',\n",
    "        'verbose': False\n",
    "    }\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    return -rmse\n",
    "\n",
    "# 参数边界\n",
    "pbounds = {\n",
    "    'depth': (6, 7),  # 紧缩depth的范围\n",
    "    'l2_leaf_reg': (10, 20),  # 在更小的l2_leaf_reg范围内搜索\n",
    "    'learning_rate': (0.3, 0.6),  # 根据前面的结果，集中在较高的学习率\n",
    "    'n_estimators': (120, 180)  # 根据有效范围调整\n",
    "}\n",
    "\n",
    "# 实例化贝叶斯优化对象\n",
    "optimizer = BayesianOptimization(f=catboost_eval, pbounds=pbounds, random_state=42)\n",
    "optimizer.maximize(init_points=200, n_iter=50)\n",
    "\n",
    "print(\"Best parameters found:\", optimizer.max['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad48f7-9b12-4d2b-b7d4-9976f4208593",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "4 (searchspace from 3)\n",
    "Best parameters found: {'depth': 4.011353644767419, 'l2_leaf_reg': 0.21811963851964758, \n",
    "                        'learning_rate': 0.19112606551363676, 'n_estimators': 52.9704479067018}\n",
    "-0.9314\n",
    "\n",
    "2\n",
    "Best parameters found: {'depth': 6.467060867155791, 'l2_leaf_reg': 17.065903814470666, \n",
    "                        'learning_rate': 0.3860353293082986, 'n_estimators': 145.27827823278525}\n",
    "-0.8712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d281270d-8bca-4f9a-81ec-1f77543eb5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b60a6d86-75fa-4460-9e30-f9bd2254508b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cat/Xgb ratio for cluster 0: 0.7000000000000001 with RMSE: 0.9864837540160966\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    0: {'learning_rate': 0.04246778091879101, 'max_depth': 6, 'n_estimators': 491, 'subsample': 0.8689},\n",
    "    2: {'learning_rate': 0.12350751460907078, 'max_depth': 3, 'n_estimators': 288, 'subsample': 0.8880},\n",
    "    3: {'learning_rate': 0.08288064461501718, 'max_depth': 5, 'n_estimators': 305, 'subsample': 0.6839},\n",
    "    4: {'learning_rate': 0.18299396047960448, 'max_depth': 4, 'n_estimators': 250, 'subsample': 0.9081}\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    0: {'depth': 12, 'l2_leaf_reg': 18.15, 'learning_rate': 0.06229, 'n_estimators': 1486},\n",
    "    2: {'depth': 6, 'l2_leaf_reg': 28.02, 'learning_rate': 0.1090, 'n_estimators': 176},\n",
    "    3: {'depth': 5, 'l2_leaf_reg': 0.2358, 'learning_rate': 0.1968, 'n_estimators': 62},\n",
    "    4: {'depth': 4, 'l2_leaf_reg': 0.3376, 'learning_rate': 0.1914, 'n_estimators': 46}\n",
    "}\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def find_best_weight(cluster, X_train, y_train, X_test, y_test):\n",
    "    # 初始化模型\n",
    "    cb_model = CatBoostRegressor(**catboost_params[cluster], verbose=False)\n",
    "    xgb_model = XGBRegressor(**xgb_params[cluster], objective='reg:squarederror', verbosity=0)\n",
    "\n",
    "    # 训练模型\n",
    "    cb_model.fit(X_train, y_train)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # 预测\n",
    "    cb_preds = cb_model.predict(X_test).clip(1, 5)\n",
    "    xgb_preds = xgb_model.predict(X_test).clip(1, 5)\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    best_ratio = 0\n",
    "    \n",
    "    for ratio in np.linspace(0, 1, 21):  # 测试21个不同的比例\n",
    "        final_preds = ratio * cb_preds + (1 - ratio) * xgb_preds\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, final_preds))\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_ratio = ratio\n",
    "\n",
    "    return best_ratio, best_rmse\n",
    "\n",
    "# Example usage\n",
    "cluster = 0\n",
    "X_train, y_train = prepare_test_data(train_df, cluster) \n",
    "X_test, y_test = prepare_test_data(val_df, cluster)\n",
    "best_ratio, best_rmse = find_best_weight(cluster, X_train, y_train, X_test, y_test)\n",
    "print(f\"Best Cat/Xgb ratio for cluster {cluster}: {best_ratio} with RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3699d817-7125-4431-85c5-abeb693ce0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780ea6a-9a0a-4683-9345-f7a554330641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e425b-1913-4d7c-a477-8c6a5703985b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b198ee-3f9d-40b8-b0c6-c6e5c1ee3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Cat/Xgb ratio for cluster 0: 0.30 with RMSE: 0.9815215776560651\n",
    "Best Cat/Xgb ratio for cluster 2: 0.65 with RMSE: 0.8709046585277763\n",
    "\n",
    "\n",
    "#-------------------use catboost only\n",
    "Best Cat/Xgb ratio for cluster 4: 0.8 with RMSE: 0.9325884893451591\n",
    "Best Cat/Xgb ratio for cluster 3: 0.85 with RMSE: 0.9466939722254089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e103155-5065-475d-80fe-f5822746090e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75560a03-70b3-4392-95e3-c5fbfd39f4a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "\n",
    "# def prepare_data(df, cluster):\n",
    "#     cluster_data = df[df['Cluster'] == cluster] if cluster != -1 else df\n",
    "#     X = cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "#     y = cluster_data['stars']\n",
    "#     return X, y\n",
    "\n",
    "# def train_and_feature_importance(cluster, train_df, test_df, best_params):\n",
    "#     # 准备数据\n",
    "#     X_train, y_train = prepare_data(train_df, cluster)\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "#     X_test, y_test = prepare_data(test_df, cluster)\n",
    "    \n",
    "#     # 初始化模型\n",
    "#     params = best_params[cluster]\n",
    "#     model = CatBoostRegressor(**params, verbose=False)\n",
    "    \n",
    "#     # 训练模型\n",
    "#     model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=10)\n",
    "    \n",
    "#     # 获取特征重要性\n",
    "#     feature_importances = model.get_feature_importance()\n",
    "#     important_features_indices = [i for i, importance in enumerate(feature_importances) if importance >= 0.001]\n",
    "#     important_features_names = [X_train.columns[i] for i in important_features_indices]  # Assuming X_train is a DataFrame\n",
    "\n",
    "#     # 预测\n",
    "#     preds = model.predict(X_test)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "#     return rmse, important_features_names\n",
    "\n",
    "# # 参数配置\n",
    "# best_params = {\n",
    "#     'catboost': catboost_params,\n",
    "#     'xgb': xgb_params\n",
    "# }\n",
    "\n",
    "# # 评估每个大型Cluster\n",
    "# for model_type, params in best_params.items():\n",
    "#     print(f\"Evaluating using {model_type} parameters:\")\n",
    "#     for cluster in [2]:\n",
    "#         rmse, important_features = train_and_feature_importance(cluster, train_df, test_df, params)\n",
    "#         print(f\"Cluster {cluster} RMSE: {rmse}\")\n",
    "#         print(f\"Cluster {cluster} Important features: {important_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754cdae-0165-4761-b318-ce2cbc6d8f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1cdb0-f9e4-4631-afae-325c27b2d3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf20ff-1045-4428-be1c-4ce05f89c35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa99f8c-aa91-4f36-9470-7b93beb0fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster 0 C/X ratio\n",
    "Best ratio: 0.5 with RMSE:0.9819137040333653\n",
    "\n",
    "Cluster 2\n",
    "same params as C0\n",
    "Best ratio: 0.70 with RMSE: 0.872879930616473\n",
    "\n",
    "Cluster 3\n",
    "same params as C0\n",
    "Best ratio: 0.8 with RMSE: 0.9518091202077188\n",
    "\n",
    "Cluster 4\n",
    "Best ratio: 0.70 with RMSE: 0.9450906040132107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c4efc56-6d3f-4b3c-8df4-1b139e2976a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking RMSE for cluster 3: 0.8713790528792243\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import StackingRegressor\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# cluster = 2\n",
    "# X_train, y_train = prepare_test_data(train_df, cluster) \n",
    "# X_test, y_test = prepare_test_data(test_df, cluster)\n",
    "\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# # 定义基模型\n",
    "# estimators = [\n",
    "#     ('xgboost', XGBRegressor(**xgb_params[cluster])),\n",
    "#     ('catboost', CatBoostRegressor(**catboost_params[cluster], verbose=False))\n",
    "# ]\n",
    "\n",
    "# # 使用岭回归作为元学习器\n",
    "# final_estimator = Ridge(alpha=1)\n",
    "\n",
    "# # 创建Stacking集成模型\n",
    "# stacking_regressor = StackingRegressor(estimators=estimators, final_estimator=final_estimator, cv=3)\n",
    "\n",
    "# # 训练模型\n",
    "# stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# # 预测和评估\n",
    "# stacking_preds = stacking_regressor.predict(X_test)\n",
    "# stacking_rmse = np.sqrt(mean_squared_error(y_test, stacking_preds))\n",
    "# print(f\"Stacking RMSE for cluster 3: {stacking_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45e9dcd-1f75-4add-bdb4-896eab18ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE for Cluster 0: 0.9875197193474762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 准备数据\n",
    "X_train, y_train = prepare_test_data(train_df, 4) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "\n",
    "X_test, y_test = prepare_test_data(test_df, 4)\n",
    "\n",
    "# 初始化模型使用最佳参数\n",
    "cb_model = CatBoostRegressor(\n",
    "    iterations=int(1486),  # 使用最佳迭代次数，转换为整数\n",
    "    depth=int(13),       # 使用最佳深度，转换为整数\n",
    "    learning_rate=0.06229424029098117,   # 使用最佳学习率\n",
    "    l2_leaf_reg=18.150895075720104,      # 使用最佳L2正则化\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    max_depth=int(6),                    # 使用最佳深度\n",
    "    learning_rate=0.04246778091879101,   # 使用最佳学习率\n",
    "    n_estimators=int(491),               # 使用最佳树的数量，转换为整数\n",
    "    subsample=0.8689265095175513,        # 使用最佳子采样率\n",
    "    objective='reg:squarederror',        # 指定目标函数\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "cb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 使用测试集进行评估\n",
    "cb_preds = cb_model.predict(X_test).clip(1, 5)  # 预测值限制在1到5之间\n",
    "xgb_preds = xgb_model.predict(X_test).clip(1, 5)\n",
    "\n",
    "# 集成预测，这里使用平均集成\n",
    "final_preds = 0.5 * cb_preds + 0.5 * xgb_preds\n",
    "\n",
    "# 计算RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, final_preds))\n",
    "print(f\"Test RMSE for Cluster 0: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad344e8-3474-4f4b-9e13-5680124e1913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "feba86a1-2ee3-4875-9742-2a4879839d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ratio: 0.7000000000000001 with RMSE: 0.9450906040132107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 假设 cb_preds 和 xgb_preds 已经准备好\n",
    "best_rmse = float('inf')\n",
    "best_ratio = 0\n",
    "\n",
    "# 尝试不同的权重比例\n",
    "for ratio in np.arange(0, 1.05, 0.05):  # 从0到1，步长为0.05\n",
    "    final_preds = ratio * cb_preds + (1 - ratio) * xgb_preds\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, final_preds))\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_ratio = ratio\n",
    "\n",
    "print(f\"Best ratio: {best_ratio} with RMSE: {best_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd8dd6-c48a-4433-aca7-105d359a1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster 0 C/X ratio\n",
    "Best ratio: 0.5 with RMSE:0.9819137040333653\n",
    "\n",
    "Cluster 2\n",
    "same params as C0\n",
    "Best ratio: 0.70 with RMSE: 0.872879930616473\n",
    "\n",
    "Cluster 3\n",
    "same params as C0\n",
    "Best ratio: 0.8 with RMSE: 0.9518091202077188\n",
    "\n",
    "Cluster 4\n",
    "Best ratio: 0.70 with RMSE: 0.9450906040132107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6296cee4-b999-46dd-9a02-4d90a70490d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# '''using bayes to try on all data'''\n",
    "# from bayes_opt import BayesianOptimization\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.feature_selection import RFECV\n",
    "# from sklearn.model_selection import StratifiedKFold, KFold\n",
    "# import numpy as np\n",
    "\n",
    "# X_train, y_train = prepare_test_data(train_df, -1) \n",
    "# X_test, y_test = prepare_test_data(test_df, -1)\n",
    "\n",
    "# def catboost_eval(depth, learning_rate, n_estimators, l2_leaf_reg):\n",
    "#     # 确保参数是适当的数据类型\n",
    "#     depth = int(depth)\n",
    "#     n_estimators = int(n_estimators)\n",
    "    \n",
    "#     # 初始化和训练模型\n",
    "#     model = CatBoostRegressor(\n",
    "#         depth=depth,\n",
    "#         learning_rate=learning_rate,\n",
    "#         n_estimators=n_estimators,\n",
    "#         l2_leaf_reg=l2_leaf_reg,\n",
    "#         verbose=False\n",
    "#     )\n",
    "    \n",
    "#     # 特征选择\n",
    "#     selector = RFECV(model, step=1, cv=KFold(2), scoring='neg_mean_squared_error') # StratifiedKFold\n",
    "#     selector.fit(X_train, y_train)\n",
    "#     X_train_selected = selector.transform(X_train)\n",
    "#     X_test_selected = selector.transform(X_test)\n",
    "\n",
    "#     model.fit(X_train_selected, y_train, eval_set=(X_test_selected, y_test), early_stopping_rounds=10)\n",
    "    \n",
    "#     # 计算RMSE\n",
    "#     predictions = model.predict(X_test_selected)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    \n",
    "#     # 负RMSE，因为我们要最大化目标函数\n",
    "#     print(\"Selected features indices:\", selector.get_support(indices=True))\n",
    "#     return -rmse\n",
    "\n",
    "# # 参数边界\n",
    "# pbounds = {\n",
    "#     'depth': (3, 8),\n",
    "#     'learning_rate': (0.01, 0.1),\n",
    "#     'n_estimators': (100, 1000),\n",
    "#     'l2_leaf_reg': (1, 10),\n",
    "# }\n",
    "\n",
    "# optimizer = BayesianOptimization(f=catboost_eval, pbounds=pbounds, random_state=42)\n",
    "# optimizer.maximize(init_points=2, n_iter=5)\n",
    "\n",
    "# print(\"Best parameters:\", optimizer.max['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28cf8bd-5448-46ae-9abe-64053b2a23f8",
   "metadata": {},
   "source": [
    "### Moderate Sample Clusters (5, 7, 8) Boosting\n",
    "\n",
    "Best RMSEs for each cluster: {5: 1.0007843912278394, 7: 1.0156949948241945, 8: 0.9990973587899347}\n",
    "***best_params = {5: {'depth': 2.536426180826484, 'l2_leaf_reg': 2.1469803776077248, 'learning_rate': 0.7397939925293111}, \n",
    "               7: {'depth': 6.87137925586567, 'l2_leaf_reg': 18.323103915785264, 'learning_rate': 0.8392475333120256}, \n",
    "               8: {'depth': 2.3176722810449486, 'l2_leaf_reg': 7.572561905566506, 'learning_rate': 0.3547615081241711}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "894c5f26-1645-492c-ae62-002ef23fc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    5: {'depth': 3, 'l2_leaf_reg': 0.415375550656062, 'learning_rate': 0.9017553809036529}, \n",
    "    7: {'depth': 6, 'l2_leaf_reg': 18.3792029910461, 'learning_rate': 0.9372003134293689}, \n",
    "    8: {'depth': 1, 'l2_leaf_reg': 7.440376345058953, 'learning_rate': 0.4049807340854126},\n",
    "    6: {'depth': 2.0, 'l2_leaf_reg': 1.1835517768726047, 'learning_rate': 0.38770112704134657}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290f03a7-70e7-4c9c-acae-f46551d1a1d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 5 RMSE: 1.0282390060477125\n",
      "Cluster 5 Important features: ['cool', 'elite_years', 'compliment_writer', 'avg_ufc_count_per_review', 'bus_stars', 'city_encoded']\n",
      "Cluster 7 RMSE: 0.6417139710941048\n",
      "Cluster 7 Important features: ['score', 'average_stars', 'user_review_count', 'fans', 'useful', 'funny', 'cool', 'num_interactions', 'yelping_since', 'friends_count', 'elite_years', 'compliments', 'compliment_hot', 'compliment_more', 'compliment_profile', 'compliment_note', 'compliment_plain', 'compliment_cool', 'compliment_writer', 'compliment_photos', 'total_ufc_count_per_year', 'avg_ufc_count_per_review', 'bus_stars', 'bus_review_count', 'is_open', 'city_encoded', 'log_affinity_score']\n",
      "Cluster 8 RMSE: 1.009791395972113\n",
      "Cluster 8 Important features: ['average_stars', 'compliments', 'bus_stars']\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def train_and_feature_importance(cluster, train_df, test_df, importance_threshold=0.01):\n",
    "    # 准备数据\n",
    "    X_train, y_train = prepare_test_data(test_df, cluster)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "    X_test, y_test = prepare_test_data(test_df, cluster)\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = CatBoostRegressor(**best_params[cluster])\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=10, verbose=False)\n",
    "    \n",
    "    # 获取特征重要性\n",
    "    feature_importances = model.get_feature_importance()\n",
    "    important_features_indices = [i for i, importance in enumerate(feature_importances) if importance >= importance_threshold]\n",
    "    important_features_names = [X_train.columns[i] for i in important_features_indices]  # Assuming X_train is a DataFrame\n",
    "\n",
    "    # preict\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    return rmse, important_features_names\n",
    "\n",
    "# 评估每个Cluster并打印重要特征\n",
    "for cluster in [5, 7, 8]:\n",
    "    rmse, important_features = train_and_feature_importance(cluster, train_df, test_df)\n",
    "    print(f\"Cluster {cluster} RMSE: {rmse}\")\n",
    "    print(f\"Cluster {cluster} Important features: {important_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e9a18-79ce-4391-8200-da88d538427f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def prepare_data(test_df, cluster):\n",
    "    if cluster == -1:\n",
    "        test_cluster_data = test_df\n",
    "    else:\n",
    "        test_cluster_data = test_df[test_df['Cluster'] == cluster]\n",
    "        \n",
    "    X_test = test_cluster_data.drop(columns=['stars', 'user_id', 'business_id', 'log_affinity_score''_affi])\n",
    "    y_test = test_cluster_data['stars']\n",
    "    return X_test, y_test\n",
    "\n",
    "def train_and_feature_importance(cluster, train_df, test_df, importance_threshold=0.001):\n",
    "    # 准备数据\n",
    "    X_train, y_train = prepare_data(test_df, cluster)\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "    X_test, y_test = prepare_data(test_df, cluster)\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = CatBoostRegressor(**best_params[cluster], verbose=False)\n",
    "    \n",
    "    # 训练模型\n",
    "    # model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=10, verbose=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    # 获取特征重要性\n",
    "    feature_importances = model.get_feature_importance()\n",
    "    important_features_indices = [i for i, importance in enumerate(feature_importances) if importance >= importance_threshold]\n",
    "    important_features_names = [X_train.columns[i] for i in important_features_indices]  # Assuming X_train is a DataFrame\n",
    "\n",
    "    # preict\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    return rmse, important_features_names\n",
    "\n",
    "# 评估每个Cluster并打印重要特征\n",
    "for cluster in [6]:\n",
    "    rmse, important_features = train_and_feature_importance(cluster, train_df, test_df)\n",
    "    print(f\"Cluster {cluster} RMSE: {rmse}\")\n",
    "    # print(f\"Cluster {cluster} Important features: {important_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60848210-cc7d-4a6e-8f95-a4e2fe1507f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733d612-5fbc-4283-80ca-10aba67bb32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24361bd1-4ce1-4ddd-8c5f-adabd64dbb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'business_id', 'stars', 'score', 'average_stars', 'user_review_count', 'fans',\n",
       "       'useful', 'funny', 'cool', 'num_interactions', 'yelping_since', 'friends_count',\n",
       "       'elite_years', 'compliments', 'compliment_hot', 'compliment_more', 'compliment_profile',\n",
       "       'compliment_cute', 'compliment_list', 'compliment_note', 'compliment_plain',\n",
       "       'compliment_cool', 'compliment_writer', 'compliment_photos', 'total_ufc_count_per_year',\n",
       "       'avg_ufc_count_per_review', 'bus_stars', 'bus_review_count', 'is_open', 'city_encoded',\n",
       "       'log_affinity_score', 'binary_affinity_score', 'Cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7d9b1-1bb5-4e55-b68e-6e729162a28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cacfea-9fbf-414a-aea6-8c10d16817a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be400d1f-2984-4b9b-91d8-7646565a3bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3d79e8e-0e5c-4109-8844-8472808ddc61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.model_selection import train_test_split, KFold, GroupKFold\n",
    "# from sklearn.feature_selection import RFECV\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def train_and_feature_importance_with_rfecv(cluster, train_df, test_df, best_params):\n",
    "#     # 准备数据\n",
    "#     X_train, y_train = prepare_test_data(train_df, cluster)\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "#     X_test, y_test = prepare_test_data(test_df, cluster)\n",
    "    \n",
    "#     # 确保 X_train 是 DataFrame\n",
    "#     if isinstance(X_train, np.ndarray):\n",
    "#         X_train = pd.DataFrame(X_train)\n",
    "#         X_val = pd.DataFrame(X_val)\n",
    "#         X_test = pd.DataFrame(X_test)\n",
    "\n",
    "#     # 初始化模型\n",
    "#     model = CatBoostRegressor(**best_params[cluster], verbose=0)\n",
    "\n",
    "#     # 使用RFECV进行特征选择\n",
    "#     selector = RFECV(estimator=model, step=1, cv=KFold(5), scoring='neg_mean_squared_error', min_features_to_select=10)\n",
    "#     selector.fit(X_train, y_train)\n",
    "    \n",
    "#     # 选择的最佳特征\n",
    "#     X_train_selected = X_train.iloc[:, selector.support_]\n",
    "#     X_val_selected = X_val.iloc[:, selector.support_]\n",
    "#     X_test_selected = X_test.iloc[:, selector.support_]\n",
    "#     important_features_names = X_train.columns[selector.support_].tolist()\n",
    "\n",
    "#     # 在选择的特征上重新训练模型\n",
    "#     # model.fit(X_train_selected, y_train, eval_set=(X_val_selected, y_val), early_stopping_rounds=10, verbose=False)\n",
    "#     model.fit(X_train_selected, y_train)\n",
    "\n",
    "#     # 预测和计算RMSE\n",
    "#     preds = model.predict(X_test_selected)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "#     return rmse, important_features_names\n",
    "\n",
    "# for cluster in [5, 7, 8]:\n",
    "#     rmse, important_features = train_and_feature_importance_with_rfecv(cluster, train_df, test_df, best_params)\n",
    "#     print(f\"Cluster {cluster} RMSE: {rmse}\")\n",
    "#     print(f\"Cluster {cluster} Important features: {important_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "585e1c61-8c09-4f33-9253-69477acdbd7a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.8/dist-packages (0.12.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "# !pip install bayesian-optimization\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bdadeee-2ec3-41fd-8cda-217a3b4ce9f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 初始化一个字典来存储每个Cluster的最优模型和对应的RMSE\n",
    "best_params = {}\n",
    "best_rmses = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf154d9c-45f9-4d2e-9b19-0b37cc1458db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XGB, 1: 1.014988119592079, 5: 1.0896717324335012, 6: 0.9023332514439544, 7: 1.0593137926993073, 8: 1.0335643721328076}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c755f-9470-4f70-89de-ceb3fc963583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973721b2-811a-4af4-a7fa-7d6b08ebe4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fb0baa1-5d42-497d-b657-0945eb2540c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 7: RMSE = 1.0367451814338553\n",
      "Cluster 6: RMSE = 0.886017087790363\n",
      "Cluster 8: RMSE = 1.008438304190436\n",
      "Cluster 5: RMSE = 1.033039277638755\n"
     ]
    }
   ],
   "source": [
    "\"\"\"trying catboost\"\"\"\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "for cluster in [7, 6, 8, 5]:\n",
    "    train_cluster_data = train_df[train_df['Cluster'] == cluster]\n",
    "    X= train_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y = train_cluster_data['stars']\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "    def prepare_test_data(test_df, cluster):\n",
    "        test_cluster_data = test_df[test_df['Cluster'] == cluster]\n",
    "        X_test = test_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "        y_test = test_cluster_data['stars']\n",
    "        return X_test, y_test\n",
    "\n",
    "    X_test, y_test = prepare_test_data(test_df, cluster)\n",
    "\n",
    "    # 初始化CatBoostRegressor\n",
    "    model = CatBoostRegressor(iterations=1000,\n",
    "                              depth=3,\n",
    "                              learning_rate=0.1,\n",
    "                              loss_function='RMSE',\n",
    "                              verbose=False)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
    "\n",
    "    # 验证模型效果\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    print(f\"Cluster {cluster}: RMSE = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe1bfd-5d7c-4a9f-b4eb-df94769c6ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d5a7c-5137-42cd-9d1d-50d54b6ff64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe11c4-ed1a-4617-98c0-9c393af09582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc4aaf4d-6f0f-45c2-a764-842fb4753e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   depth   | l2_lea... | learni... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-1.028   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7476   \u001b[0m | \u001b[0m0.8518   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-1.017   \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m0.4034   \u001b[0m | \u001b[95m0.861    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-1.017   \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m0.5227   \u001b[0m | \u001b[95m0.8914   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5669   \u001b[0m | \u001b[0m0.9203   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8422   \u001b[0m | \u001b[0m0.8545   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5658   \u001b[0m | \u001b[0m0.9076   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4342   \u001b[0m | \u001b[0m0.9318   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5034   \u001b[0m | \u001b[0m0.921    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8521   \u001b[0m | \u001b[0m0.8603   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4173   \u001b[0m | \u001b[0m0.9396   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.568    \u001b[0m | \u001b[0m0.9475   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7305   \u001b[0m | \u001b[0m0.8833   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8162   \u001b[0m | \u001b[0m0.8536   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.9087   \u001b[0m | \u001b[0m0.9266   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7889   \u001b[0m | \u001b[0m0.8621   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8605   \u001b[0m | \u001b[0m0.8811   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-1.02    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3934   \u001b[0m | \u001b[0m0.8537   \u001b[0m |\n",
      "| \u001b[95m18       \u001b[0m | \u001b[95m-1.017   \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m0.4424   \u001b[0m | \u001b[95m0.8783   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3474   \u001b[0m | \u001b[0m0.9092   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.669    \u001b[0m | \u001b[0m0.9217   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5638   \u001b[0m | \u001b[0m0.9212   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3453   \u001b[0m | \u001b[0m0.9053   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6243   \u001b[0m | \u001b[0m0.9462   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-1.018   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8574   \u001b[0m | \u001b[0m0.8655   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7998   \u001b[0m | \u001b[0m0.8915   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8719   \u001b[0m | \u001b[0m0.8865   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.751    \u001b[0m | \u001b[0m0.9401   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7659   \u001b[0m | \u001b[0m0.8866   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8529   \u001b[0m | \u001b[0m0.8946   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7134   \u001b[0m | \u001b[0m0.9139   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8851   \u001b[0m | \u001b[0m0.8967   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5603   \u001b[0m | \u001b[0m0.8755   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6596   \u001b[0m | \u001b[0m0.852    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5114   \u001b[0m | \u001b[0m0.9045   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5297   \u001b[0m | \u001b[0m0.9426   \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3249   \u001b[0m | \u001b[0m0.9447   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-1.018   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.9138   \u001b[0m | \u001b[0m0.869    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8749   \u001b[0m | \u001b[0m0.9214   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7687   \u001b[0m | \u001b[0m0.9271   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7423   \u001b[0m | \u001b[0m0.8642   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-1.02    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3311   \u001b[0m | \u001b[0m0.8546   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8314   \u001b[0m | \u001b[0m0.9056   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8206   \u001b[0m | \u001b[0m0.8642   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6668   \u001b[0m | \u001b[0m0.9487   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3266   \u001b[0m | \u001b[0m0.9318   \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7996   \u001b[0m | \u001b[0m0.8905   \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7636   \u001b[0m | \u001b[0m0.9074   \u001b[0m |\n",
      "| \u001b[95m48       \u001b[0m | \u001b[95m-1.017   \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m0.3513   \u001b[0m | \u001b[95m0.8639   \u001b[0m |\n",
      "| \u001b[95m49       \u001b[0m | \u001b[95m-1.017   \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m0.3799   \u001b[0m | \u001b[95m0.8743   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6512   \u001b[0m | \u001b[0m0.853    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8957   \u001b[0m | \u001b[0m0.9086   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4668   \u001b[0m | \u001b[0m0.9261   \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6642   \u001b[0m | \u001b[0m0.9488   \u001b[0m |\n",
      "| \u001b[95m54       \u001b[0m | \u001b[95m-1.017   \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m0.4593   \u001b[0m | \u001b[95m0.9011   \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8128   \u001b[0m | \u001b[0m0.8674   \u001b[0m |\n",
      "| \u001b[95m56       \u001b[0m | \u001b[95m-1.017   \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m0.3574   \u001b[0m | \u001b[95m0.9004   \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6567   \u001b[0m | \u001b[0m0.8835   \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6632   \u001b[0m | \u001b[0m0.8898   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7626   \u001b[0m | \u001b[0m0.9187   \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3552   \u001b[0m | \u001b[0m0.8888   \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4415   \u001b[0m | \u001b[0m0.927    \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4716   \u001b[0m | \u001b[0m0.9322   \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-1.021   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6991   \u001b[0m | \u001b[0m0.9042   \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-1.021   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4734   \u001b[0m | \u001b[0m0.8584   \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7787   \u001b[0m | \u001b[0m0.9425   \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3237   \u001b[0m | \u001b[0m0.8752   \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8848   \u001b[0m | \u001b[0m0.9468   \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8647   \u001b[0m | \u001b[0m0.9159   \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.607    \u001b[0m | \u001b[0m0.9122   \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8711   \u001b[0m | \u001b[0m0.9436   \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-1.018   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8933   \u001b[0m | \u001b[0m0.8692   \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3964   \u001b[0m | \u001b[0m0.9023   \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8842   \u001b[0m | \u001b[0m0.9345   \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4211   \u001b[0m | \u001b[0m0.885    \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8011   \u001b[0m | \u001b[0m0.8862   \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6646   \u001b[0m | \u001b[0m0.9396   \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8586   \u001b[0m | \u001b[0m0.8977   \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7945   \u001b[0m | \u001b[0m0.8803   \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6748   \u001b[0m | \u001b[0m0.8533   \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5756   \u001b[0m | \u001b[0m0.9325   \u001b[0m |\n",
      "| \u001b[0m81       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8511   \u001b[0m | \u001b[0m0.9095   \u001b[0m |\n",
      "| \u001b[0m82       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7881   \u001b[0m | \u001b[0m0.913    \u001b[0m |\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5675   \u001b[0m | \u001b[0m0.9197   \u001b[0m |\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3156   \u001b[0m | \u001b[0m0.9494   \u001b[0m |\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8996   \u001b[0m | \u001b[0m0.9122   \u001b[0m |\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6602   \u001b[0m | \u001b[0m0.9146   \u001b[0m |\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6675   \u001b[0m | \u001b[0m0.9268   \u001b[0m |\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7684   \u001b[0m | \u001b[0m0.9216   \u001b[0m |\n",
      "| \u001b[0m89       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.509    \u001b[0m | \u001b[0m0.9188   \u001b[0m |\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5446   \u001b[0m | \u001b[0m0.8928   \u001b[0m |\n",
      "| \u001b[0m91       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5058   \u001b[0m | \u001b[0m0.9139   \u001b[0m |\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8997   \u001b[0m | \u001b[0m0.9195   \u001b[0m |\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5714   \u001b[0m | \u001b[0m0.8861   \u001b[0m |\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8434   \u001b[0m | \u001b[0m0.9421   \u001b[0m |\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4775   \u001b[0m | \u001b[0m0.877    \u001b[0m |\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.632    \u001b[0m | \u001b[0m0.932    \u001b[0m |\n",
      "| \u001b[0m97       \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7553   \u001b[0m | \u001b[0m0.9037   \u001b[0m |\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6567   \u001b[0m | \u001b[0m0.8983   \u001b[0m |\n",
      "| \u001b[0m99       \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3563   \u001b[0m | \u001b[0m0.8895   \u001b[0m |\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m-1.018   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.9051   \u001b[0m | \u001b[0m0.8699   \u001b[0m |\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8404   \u001b[0m | \u001b[0m0.9206   \u001b[0m |\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.412    \u001b[0m | \u001b[0m0.8984   \u001b[0m |\n",
      "| \u001b[0m103      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4504   \u001b[0m | \u001b[0m0.911    \u001b[0m |\n",
      "| \u001b[0m104      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8652   \u001b[0m | \u001b[0m0.9427   \u001b[0m |\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3819   \u001b[0m | \u001b[0m0.8711   \u001b[0m |\n",
      "| \u001b[0m106      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7525   \u001b[0m | \u001b[0m0.8726   \u001b[0m |\n",
      "| \u001b[0m107      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8264   \u001b[0m | \u001b[0m0.8933   \u001b[0m |\n",
      "| \u001b[0m108      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4556   \u001b[0m | \u001b[0m0.862    \u001b[0m |\n",
      "| \u001b[0m109      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6017   \u001b[0m | \u001b[0m0.867    \u001b[0m |\n",
      "| \u001b[0m110      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6418   \u001b[0m | \u001b[0m0.9172   \u001b[0m |\n",
      "| \u001b[0m111      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7663   \u001b[0m | \u001b[0m0.874    \u001b[0m |\n",
      "| \u001b[0m112      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7866   \u001b[0m | \u001b[0m0.854    \u001b[0m |\n",
      "| \u001b[0m113      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8391   \u001b[0m | \u001b[0m0.9362   \u001b[0m |\n",
      "| \u001b[0m114      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8353   \u001b[0m | \u001b[0m0.9467   \u001b[0m |\n",
      "| \u001b[0m115      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8278   \u001b[0m | \u001b[0m0.8616   \u001b[0m |\n",
      "| \u001b[0m116      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7375   \u001b[0m | \u001b[0m0.9128   \u001b[0m |\n",
      "| \u001b[0m117      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3361   \u001b[0m | \u001b[0m0.9288   \u001b[0m |\n",
      "| \u001b[0m118      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4712   \u001b[0m | \u001b[0m0.8775   \u001b[0m |\n",
      "| \u001b[0m119      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5226   \u001b[0m | \u001b[0m0.9314   \u001b[0m |\n",
      "| \u001b[0m120      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.785    \u001b[0m | \u001b[0m0.9508   \u001b[0m |\n",
      "| \u001b[0m121      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4012   \u001b[0m | \u001b[0m0.9419   \u001b[0m |\n",
      "| \u001b[0m122      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.9002   \u001b[0m | \u001b[0m0.9154   \u001b[0m |\n",
      "| \u001b[0m123      \u001b[0m | \u001b[0m-1.021   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.643    \u001b[0m | \u001b[0m0.9044   \u001b[0m |\n",
      "| \u001b[0m124      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5288   \u001b[0m | \u001b[0m0.8544   \u001b[0m |\n",
      "| \u001b[0m125      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7628   \u001b[0m | \u001b[0m0.8548   \u001b[0m |\n",
      "| \u001b[0m126      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8328   \u001b[0m | \u001b[0m0.921    \u001b[0m |\n",
      "| \u001b[0m127      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4286   \u001b[0m | \u001b[0m0.8959   \u001b[0m |\n",
      "| \u001b[0m128      \u001b[0m | \u001b[0m-1.018   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.9092   \u001b[0m | \u001b[0m0.8721   \u001b[0m |\n",
      "| \u001b[0m129      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4727   \u001b[0m | \u001b[0m0.9268   \u001b[0m |\n",
      "| \u001b[0m130      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3495   \u001b[0m | \u001b[0m0.9026   \u001b[0m |\n",
      "| \u001b[0m131      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7945   \u001b[0m | \u001b[0m0.8815   \u001b[0m |\n",
      "| \u001b[0m132      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6714   \u001b[0m | \u001b[0m0.9361   \u001b[0m |\n",
      "| \u001b[0m133      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7653   \u001b[0m | \u001b[0m0.9029   \u001b[0m |\n",
      "| \u001b[0m134      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.891    \u001b[0m | \u001b[0m0.9322   \u001b[0m |\n",
      "| \u001b[0m135      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.741    \u001b[0m | \u001b[0m0.8983   \u001b[0m |\n",
      "| \u001b[0m136      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4482   \u001b[0m | \u001b[0m0.8785   \u001b[0m |\n",
      "| \u001b[0m137      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5725   \u001b[0m | \u001b[0m0.8627   \u001b[0m |\n",
      "| \u001b[0m138      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7972   \u001b[0m | \u001b[0m0.9214   \u001b[0m |\n",
      "| \u001b[0m139      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5208   \u001b[0m | \u001b[0m0.9363   \u001b[0m |\n",
      "| \u001b[0m140      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8098   \u001b[0m | \u001b[0m0.9144   \u001b[0m |\n",
      "| \u001b[0m141      \u001b[0m | \u001b[0m-1.02    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3624   \u001b[0m | \u001b[0m0.8536   \u001b[0m |\n",
      "| \u001b[0m142      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5905   \u001b[0m | \u001b[0m0.8631   \u001b[0m |\n",
      "| \u001b[0m143      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7683   \u001b[0m | \u001b[0m0.8912   \u001b[0m |\n",
      "| \u001b[0m144      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5868   \u001b[0m | \u001b[0m0.8968   \u001b[0m |\n",
      "| \u001b[0m145      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5998   \u001b[0m | \u001b[0m0.9321   \u001b[0m |\n",
      "| \u001b[0m146      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8582   \u001b[0m | \u001b[0m0.8555   \u001b[0m |\n",
      "| \u001b[0m147      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3908   \u001b[0m | \u001b[0m0.9136   \u001b[0m |\n",
      "| \u001b[0m148      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6386   \u001b[0m | \u001b[0m0.8521   \u001b[0m |\n",
      "| \u001b[0m149      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8586   \u001b[0m | \u001b[0m0.9314   \u001b[0m |\n",
      "| \u001b[0m150      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4027   \u001b[0m | \u001b[0m0.8675   \u001b[0m |\n",
      "| \u001b[0m151      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6889   \u001b[0m | \u001b[0m0.9423   \u001b[0m |\n",
      "| \u001b[0m152      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.742    \u001b[0m | \u001b[0m0.9249   \u001b[0m |\n",
      "| \u001b[0m153      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5559   \u001b[0m | \u001b[0m0.8767   \u001b[0m |\n",
      "| \u001b[0m154      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.387    \u001b[0m | \u001b[0m0.933    \u001b[0m |\n",
      "| \u001b[0m155      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.474    \u001b[0m | \u001b[0m0.9337   \u001b[0m |\n",
      "| \u001b[0m156      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.9048   \u001b[0m | \u001b[0m0.8784   \u001b[0m |\n",
      "| \u001b[0m157      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5041   \u001b[0m | \u001b[0m0.9428   \u001b[0m |\n",
      "| \u001b[0m158      \u001b[0m | \u001b[0m-1.021   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5755   \u001b[0m | \u001b[0m0.903    \u001b[0m |\n",
      "| \u001b[0m159      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3339   \u001b[0m | \u001b[0m0.9234   \u001b[0m |\n",
      "| \u001b[0m160      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3317   \u001b[0m | \u001b[0m0.904    \u001b[0m |\n",
      "| \u001b[0m161      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8311   \u001b[0m | \u001b[0m0.9076   \u001b[0m |\n",
      "| \u001b[0m162      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5871   \u001b[0m | \u001b[0m0.9146   \u001b[0m |\n",
      "| \u001b[0m163      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.321    \u001b[0m | \u001b[0m0.9094   \u001b[0m |\n",
      "| \u001b[0m164      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6257   \u001b[0m | \u001b[0m0.9434   \u001b[0m |\n",
      "| \u001b[0m165      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4638   \u001b[0m | \u001b[0m0.8889   \u001b[0m |\n",
      "| \u001b[0m166      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8775   \u001b[0m | \u001b[0m0.9362   \u001b[0m |\n",
      "| \u001b[0m167      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4521   \u001b[0m | \u001b[0m0.8605   \u001b[0m |\n",
      "| \u001b[0m168      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.504    \u001b[0m | \u001b[0m0.8692   \u001b[0m |\n",
      "| \u001b[0m169      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5635   \u001b[0m | \u001b[0m0.9334   \u001b[0m |\n",
      "| \u001b[0m170      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7365   \u001b[0m | \u001b[0m0.8758   \u001b[0m |\n",
      "| \u001b[0m171      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5248   \u001b[0m | \u001b[0m0.8575   \u001b[0m |\n",
      "| \u001b[0m172      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7138   \u001b[0m | \u001b[0m0.9015   \u001b[0m |\n",
      "| \u001b[0m173      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4202   \u001b[0m | \u001b[0m0.9088   \u001b[0m |\n",
      "| \u001b[0m174      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8055   \u001b[0m | \u001b[0m0.9112   \u001b[0m |\n",
      "| \u001b[0m175      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8563   \u001b[0m | \u001b[0m0.9113   \u001b[0m |\n",
      "| \u001b[0m176      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3715   \u001b[0m | \u001b[0m0.8583   \u001b[0m |\n",
      "| \u001b[0m177      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5406   \u001b[0m | \u001b[0m0.9493   \u001b[0m |\n",
      "| \u001b[0m178      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.899    \u001b[0m | \u001b[0m0.9285   \u001b[0m |\n",
      "| \u001b[0m179      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6949   \u001b[0m | \u001b[0m0.9186   \u001b[0m |\n",
      "| \u001b[95m180      \u001b[0m | \u001b[95m-1.017   \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m0.3233   \u001b[0m | \u001b[95m0.8871   \u001b[0m |\n",
      "| \u001b[0m181      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7534   \u001b[0m | \u001b[0m0.8986   \u001b[0m |\n",
      "| \u001b[0m182      \u001b[0m | \u001b[0m-1.02    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.398    \u001b[0m | \u001b[0m0.8528   \u001b[0m |\n",
      "| \u001b[0m183      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5073   \u001b[0m | \u001b[0m0.9502   \u001b[0m |\n",
      "| \u001b[0m184      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5186   \u001b[0m | \u001b[0m0.9041   \u001b[0m |\n",
      "| \u001b[0m185      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5937   \u001b[0m | \u001b[0m0.8642   \u001b[0m |\n",
      "| \u001b[0m186      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6181   \u001b[0m | \u001b[0m0.9191   \u001b[0m |\n",
      "| \u001b[0m187      \u001b[0m | \u001b[0m-1.02    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3936   \u001b[0m | \u001b[0m0.854    \u001b[0m |\n",
      "| \u001b[0m188      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8014   \u001b[0m | \u001b[0m0.853    \u001b[0m |\n",
      "| \u001b[0m189      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7275   \u001b[0m | \u001b[0m0.8967   \u001b[0m |\n",
      "| \u001b[0m190      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.702    \u001b[0m | \u001b[0m0.8523   \u001b[0m |\n",
      "| \u001b[0m191      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.831    \u001b[0m | \u001b[0m0.9348   \u001b[0m |\n",
      "| \u001b[0m192      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7196   \u001b[0m | \u001b[0m0.9096   \u001b[0m |\n",
      "| \u001b[0m193      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6517   \u001b[0m | \u001b[0m0.9189   \u001b[0m |\n",
      "| \u001b[0m194      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8289   \u001b[0m | \u001b[0m0.8713   \u001b[0m |\n",
      "| \u001b[0m195      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4891   \u001b[0m | \u001b[0m0.9291   \u001b[0m |\n",
      "| \u001b[0m196      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8      \u001b[0m | \u001b[0m0.8871   \u001b[0m |\n",
      "| \u001b[0m197      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7757   \u001b[0m | \u001b[0m0.8826   \u001b[0m |\n",
      "| \u001b[0m198      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7621   \u001b[0m | \u001b[0m0.8739   \u001b[0m |\n",
      "| \u001b[0m199      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4347   \u001b[0m | \u001b[0m0.866    \u001b[0m |\n",
      "| \u001b[0m200      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3314   \u001b[0m | \u001b[0m0.8628   \u001b[0m |\n",
      "| \u001b[0m201      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7952   \u001b[0m | \u001b[0m0.8598   \u001b[0m |\n",
      "| \u001b[0m202      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.44     \u001b[0m | \u001b[0m0.9435   \u001b[0m |\n",
      "| \u001b[0m203      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6477   \u001b[0m | \u001b[0m0.8822   \u001b[0m |\n",
      "| \u001b[0m204      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5766   \u001b[0m | \u001b[0m0.9441   \u001b[0m |\n",
      "| \u001b[0m205      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6022   \u001b[0m | \u001b[0m0.8644   \u001b[0m |\n",
      "| \u001b[0m206      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4113   \u001b[0m | \u001b[0m0.872    \u001b[0m |\n",
      "| \u001b[0m207      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5579   \u001b[0m | \u001b[0m0.8664   \u001b[0m |\n",
      "| \u001b[0m208      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4286   \u001b[0m | \u001b[0m0.9161   \u001b[0m |\n",
      "| \u001b[0m209      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4418   \u001b[0m | \u001b[0m0.9119   \u001b[0m |\n",
      "| \u001b[0m210      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6983   \u001b[0m | \u001b[0m0.9115   \u001b[0m |\n",
      "| \u001b[0m211      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7543   \u001b[0m | \u001b[0m0.9463   \u001b[0m |\n",
      "| \u001b[0m212      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7847   \u001b[0m | \u001b[0m0.8574   \u001b[0m |\n",
      "| \u001b[0m213      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4307   \u001b[0m | \u001b[0m0.8913   \u001b[0m |\n",
      "| \u001b[0m214      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3634   \u001b[0m | \u001b[0m0.9422   \u001b[0m |\n",
      "| \u001b[0m215      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6338   \u001b[0m | \u001b[0m0.9012   \u001b[0m |\n",
      "| \u001b[0m216      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4392   \u001b[0m | \u001b[0m0.8594   \u001b[0m |\n",
      "| \u001b[0m217      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4723   \u001b[0m | \u001b[0m0.8875   \u001b[0m |\n",
      "| \u001b[0m218      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7879   \u001b[0m | \u001b[0m0.8624   \u001b[0m |\n",
      "| \u001b[0m219      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4217   \u001b[0m | \u001b[0m0.909    \u001b[0m |\n",
      "| \u001b[0m220      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7876   \u001b[0m | \u001b[0m0.8707   \u001b[0m |\n",
      "| \u001b[0m221      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7594   \u001b[0m | \u001b[0m0.8667   \u001b[0m |\n",
      "| \u001b[0m222      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4453   \u001b[0m | \u001b[0m0.9277   \u001b[0m |\n",
      "| \u001b[0m223      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4213   \u001b[0m | \u001b[0m0.938    \u001b[0m |\n",
      "| \u001b[0m224      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8315   \u001b[0m | \u001b[0m0.9076   \u001b[0m |\n",
      "| \u001b[0m225      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7706   \u001b[0m | \u001b[0m0.9234   \u001b[0m |\n",
      "| \u001b[0m226      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4822   \u001b[0m | \u001b[0m0.8521   \u001b[0m |\n",
      "| \u001b[0m227      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8301   \u001b[0m | \u001b[0m0.9246   \u001b[0m |\n",
      "| \u001b[0m228      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7395   \u001b[0m | \u001b[0m0.9298   \u001b[0m |\n",
      "| \u001b[0m229      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7776   \u001b[0m | \u001b[0m0.9268   \u001b[0m |\n",
      "| \u001b[0m230      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5565   \u001b[0m | \u001b[0m0.9215   \u001b[0m |\n",
      "| \u001b[0m231      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7803   \u001b[0m | \u001b[0m0.9414   \u001b[0m |\n",
      "| \u001b[0m232      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3878   \u001b[0m | \u001b[0m0.8738   \u001b[0m |\n",
      "| \u001b[0m233      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8452   \u001b[0m | \u001b[0m0.9061   \u001b[0m |\n",
      "| \u001b[0m234      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3984   \u001b[0m | \u001b[0m0.8808   \u001b[0m |\n",
      "| \u001b[0m235      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5099   \u001b[0m | \u001b[0m0.8975   \u001b[0m |\n",
      "| \u001b[0m236      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8123   \u001b[0m | \u001b[0m0.8944   \u001b[0m |\n",
      "| \u001b[0m237      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7204   \u001b[0m | \u001b[0m0.8739   \u001b[0m |\n",
      "| \u001b[0m238      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5042   \u001b[0m | \u001b[0m0.9144   \u001b[0m |\n",
      "| \u001b[0m239      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.584    \u001b[0m | \u001b[0m0.9302   \u001b[0m |\n",
      "| \u001b[0m240      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7091   \u001b[0m | \u001b[0m0.8649   \u001b[0m |\n",
      "| \u001b[0m241      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.861    \u001b[0m | \u001b[0m0.9123   \u001b[0m |\n",
      "| \u001b[0m242      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6182   \u001b[0m | \u001b[0m0.9016   \u001b[0m |\n",
      "| \u001b[0m243      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3561   \u001b[0m | \u001b[0m0.9091   \u001b[0m |\n",
      "| \u001b[0m244      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6261   \u001b[0m | \u001b[0m0.8712   \u001b[0m |\n",
      "| \u001b[0m245      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4664   \u001b[0m | \u001b[0m0.9218   \u001b[0m |\n",
      "| \u001b[0m246      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8847   \u001b[0m | \u001b[0m0.9142   \u001b[0m |\n",
      "| \u001b[0m247      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3201   \u001b[0m | \u001b[0m0.9507   \u001b[0m |\n",
      "| \u001b[0m248      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5087   \u001b[0m | \u001b[0m0.9464   \u001b[0m |\n",
      "| \u001b[0m249      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.809    \u001b[0m | \u001b[0m0.9379   \u001b[0m |\n",
      "| \u001b[0m250      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4688   \u001b[0m | \u001b[0m0.932    \u001b[0m |\n",
      "| \u001b[0m251      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.396    \u001b[0m | \u001b[0m0.9445   \u001b[0m |\n",
      "| \u001b[0m252      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6103   \u001b[0m | \u001b[0m0.9374   \u001b[0m |\n",
      "| \u001b[0m253      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7255   \u001b[0m | \u001b[0m0.8916   \u001b[0m |\n",
      "| \u001b[0m254      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4291   \u001b[0m | \u001b[0m0.9483   \u001b[0m |\n",
      "| \u001b[0m255      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3775   \u001b[0m | \u001b[0m0.8662   \u001b[0m |\n",
      "| \u001b[0m256      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7449   \u001b[0m | \u001b[0m0.9082   \u001b[0m |\n",
      "| \u001b[0m257      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6196   \u001b[0m | \u001b[0m0.9309   \u001b[0m |\n",
      "| \u001b[0m258      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7821   \u001b[0m | \u001b[0m0.8924   \u001b[0m |\n",
      "| \u001b[0m259      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4233   \u001b[0m | \u001b[0m0.8839   \u001b[0m |\n",
      "| \u001b[0m260      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5606   \u001b[0m | \u001b[0m0.8759   \u001b[0m |\n",
      "| \u001b[0m261      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.9005   \u001b[0m | \u001b[0m0.8838   \u001b[0m |\n",
      "| \u001b[0m262      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6972   \u001b[0m | \u001b[0m0.8893   \u001b[0m |\n",
      "| \u001b[0m263      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6871   \u001b[0m | \u001b[0m0.877    \u001b[0m |\n",
      "| \u001b[0m264      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5751   \u001b[0m | \u001b[0m0.8875   \u001b[0m |\n",
      "| \u001b[0m265      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7338   \u001b[0m | \u001b[0m0.8786   \u001b[0m |\n",
      "| \u001b[0m266      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4925   \u001b[0m | \u001b[0m0.9062   \u001b[0m |\n",
      "| \u001b[0m267      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8286   \u001b[0m | \u001b[0m0.9406   \u001b[0m |\n",
      "| \u001b[0m268      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6666   \u001b[0m | \u001b[0m0.9416   \u001b[0m |\n",
      "| \u001b[0m269      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8685   \u001b[0m | \u001b[0m0.8797   \u001b[0m |\n",
      "| \u001b[0m270      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7248   \u001b[0m | \u001b[0m0.8746   \u001b[0m |\n",
      "| \u001b[0m271      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5654   \u001b[0m | \u001b[0m0.9456   \u001b[0m |\n",
      "| \u001b[0m272      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7832   \u001b[0m | \u001b[0m0.8692   \u001b[0m |\n",
      "| \u001b[0m273      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4021   \u001b[0m | \u001b[0m0.9234   \u001b[0m |\n",
      "| \u001b[0m274      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7285   \u001b[0m | \u001b[0m0.8771   \u001b[0m |\n",
      "| \u001b[0m275      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4518   \u001b[0m | \u001b[0m0.8942   \u001b[0m |\n",
      "| \u001b[0m276      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5286   \u001b[0m | \u001b[0m0.8575   \u001b[0m |\n",
      "| \u001b[0m277      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7398   \u001b[0m | \u001b[0m0.9131   \u001b[0m |\n",
      "| \u001b[0m278      \u001b[0m | \u001b[0m-1.021   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4173   \u001b[0m | \u001b[0m0.8667   \u001b[0m |\n",
      "| \u001b[0m279      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8406   \u001b[0m | \u001b[0m0.8702   \u001b[0m |\n",
      "| \u001b[0m280      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5727   \u001b[0m | \u001b[0m0.9015   \u001b[0m |\n",
      "| \u001b[0m281      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5208   \u001b[0m | \u001b[0m0.8779   \u001b[0m |\n",
      "| \u001b[0m282      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7956   \u001b[0m | \u001b[0m0.8944   \u001b[0m |\n",
      "| \u001b[0m283      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4027   \u001b[0m | \u001b[0m0.9027   \u001b[0m |\n",
      "| \u001b[0m284      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8312   \u001b[0m | \u001b[0m0.9189   \u001b[0m |\n",
      "| \u001b[0m285      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3902   \u001b[0m | \u001b[0m0.8988   \u001b[0m |\n",
      "| \u001b[0m286      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8844   \u001b[0m | \u001b[0m0.9163   \u001b[0m |\n",
      "| \u001b[0m287      \u001b[0m | \u001b[0m-1.03    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6989   \u001b[0m | \u001b[0m0.9083   \u001b[0m |\n",
      "| \u001b[0m288      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5722   \u001b[0m | \u001b[0m0.9117   \u001b[0m |\n",
      "| \u001b[0m289      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.766    \u001b[0m | \u001b[0m0.9097   \u001b[0m |\n",
      "| \u001b[0m290      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3542   \u001b[0m | \u001b[0m0.9509   \u001b[0m |\n",
      "| \u001b[0m291      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4351   \u001b[0m | \u001b[0m0.894    \u001b[0m |\n",
      "| \u001b[0m292      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6896   \u001b[0m | \u001b[0m0.8566   \u001b[0m |\n",
      "| \u001b[0m293      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.352    \u001b[0m | \u001b[0m0.9221   \u001b[0m |\n",
      "| \u001b[0m294      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5425   \u001b[0m | \u001b[0m0.8706   \u001b[0m |\n",
      "| \u001b[0m295      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5196   \u001b[0m | \u001b[0m0.9313   \u001b[0m |\n",
      "| \u001b[0m296      \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6308   \u001b[0m | \u001b[0m0.8546   \u001b[0m |\n",
      "| \u001b[0m297      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5258   \u001b[0m | \u001b[0m0.8747   \u001b[0m |\n",
      "| \u001b[0m298      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5449   \u001b[0m | \u001b[0m0.8987   \u001b[0m |\n",
      "| \u001b[0m299      \u001b[0m | \u001b[0m-1.023   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.534    \u001b[0m | \u001b[0m0.9292   \u001b[0m |\n",
      "| \u001b[0m300      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8489   \u001b[0m | \u001b[0m0.8873   \u001b[0m |\n",
      "| \u001b[0m301      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6996   \u001b[0m | \u001b[0m0.8975   \u001b[0m |\n",
      "| \u001b[0m302      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3846   \u001b[0m | \u001b[0m0.8946   \u001b[0m |\n",
      "| \u001b[0m303      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5691   \u001b[0m | \u001b[0m0.8956   \u001b[0m |\n",
      "| \u001b[0m304      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6632   \u001b[0m | \u001b[0m0.8898   \u001b[0m |\n",
      "| \u001b[0m305      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3643   \u001b[0m | \u001b[0m0.8976   \u001b[0m |\n",
      "| \u001b[0m306      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7475   \u001b[0m | \u001b[0m0.8911   \u001b[0m |\n",
      "| \u001b[0m307      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4449   \u001b[0m | \u001b[0m0.8684   \u001b[0m |\n",
      "| \u001b[0m308      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7842   \u001b[0m | \u001b[0m0.8781   \u001b[0m |\n",
      "| \u001b[0m309      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4133   \u001b[0m | \u001b[0m0.8912   \u001b[0m |\n",
      "| \u001b[0m310      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5135   \u001b[0m | \u001b[0m0.8886   \u001b[0m |\n",
      "| \u001b[0m311      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8206   \u001b[0m | \u001b[0m0.875    \u001b[0m |\n",
      "| \u001b[0m312      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7593   \u001b[0m | \u001b[0m0.8922   \u001b[0m |\n",
      "| \u001b[0m313      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4083   \u001b[0m | \u001b[0m0.8799   \u001b[0m |\n",
      "| \u001b[0m314      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8531   \u001b[0m | \u001b[0m0.8739   \u001b[0m |\n",
      "| \u001b[0m315      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3902   \u001b[0m | \u001b[0m0.8863   \u001b[0m |\n",
      "| \u001b[0m316      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7358   \u001b[0m | \u001b[0m0.8918   \u001b[0m |\n",
      "| \u001b[0m317      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8352   \u001b[0m | \u001b[0m0.8789   \u001b[0m |\n",
      "| \u001b[0m318      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5325   \u001b[0m | \u001b[0m0.8827   \u001b[0m |\n",
      "| \u001b[0m319      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3347   \u001b[0m | \u001b[0m0.8733   \u001b[0m |\n",
      "| \u001b[0m320      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3433   \u001b[0m | \u001b[0m0.8683   \u001b[0m |\n",
      "| \u001b[0m321      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3303   \u001b[0m | \u001b[0m0.8813   \u001b[0m |\n",
      "| \u001b[0m322      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6517   \u001b[0m | \u001b[0m0.8905   \u001b[0m |\n",
      "| \u001b[0m323      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4673   \u001b[0m | \u001b[0m0.8974   \u001b[0m |\n",
      "| \u001b[0m324      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6259   \u001b[0m | \u001b[0m0.8956   \u001b[0m |\n",
      "| \u001b[0m325      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8625   \u001b[0m | \u001b[0m0.8715   \u001b[0m |\n",
      "| \u001b[0m326      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.351    \u001b[0m | \u001b[0m0.8755   \u001b[0m |\n",
      "| \u001b[0m327      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.362    \u001b[0m | \u001b[0m0.8691   \u001b[0m |\n",
      "| \u001b[0m328      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4441   \u001b[0m | \u001b[0m0.8869   \u001b[0m |\n",
      "| \u001b[0m329      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3621   \u001b[0m | \u001b[0m0.8797   \u001b[0m |\n",
      "| \u001b[0m330      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5425   \u001b[0m | \u001b[0m0.8812   \u001b[0m |\n",
      "| \u001b[0m331      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5734   \u001b[0m | \u001b[0m0.874    \u001b[0m |\n",
      "| \u001b[0m332      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.699    \u001b[0m | \u001b[0m0.8776   \u001b[0m |\n",
      "| \u001b[0m333      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7125   \u001b[0m | \u001b[0m0.8894   \u001b[0m |\n",
      "| \u001b[0m334      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7737   \u001b[0m | \u001b[0m0.8997   \u001b[0m |\n",
      "| \u001b[0m335      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5336   \u001b[0m | \u001b[0m0.8932   \u001b[0m |\n",
      "| \u001b[0m336      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.709    \u001b[0m | \u001b[0m0.8768   \u001b[0m |\n",
      "| \u001b[0m337      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8864   \u001b[0m | \u001b[0m0.8849   \u001b[0m |\n",
      "| \u001b[0m338      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5031   \u001b[0m | \u001b[0m0.8902   \u001b[0m |\n",
      "| \u001b[0m339      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.588    \u001b[0m | \u001b[0m0.8869   \u001b[0m |\n",
      "| \u001b[0m340      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5061   \u001b[0m | \u001b[0m0.8782   \u001b[0m |\n",
      "| \u001b[0m341      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5869   \u001b[0m | \u001b[0m0.8741   \u001b[0m |\n",
      "| \u001b[0m342      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8188   \u001b[0m | \u001b[0m0.8866   \u001b[0m |\n",
      "| \u001b[0m343      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6866   \u001b[0m | \u001b[0m0.8875   \u001b[0m |\n",
      "| \u001b[0m344      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6365   \u001b[0m | \u001b[0m0.8895   \u001b[0m |\n",
      "| \u001b[0m345      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6269   \u001b[0m | \u001b[0m0.8824   \u001b[0m |\n",
      "| \u001b[0m346      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.636    \u001b[0m | \u001b[0m0.8776   \u001b[0m |\n",
      "| \u001b[0m347      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6915   \u001b[0m | \u001b[0m0.8978   \u001b[0m |\n",
      "| \u001b[0m348      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4592   \u001b[0m | \u001b[0m0.8752   \u001b[0m |\n",
      "| \u001b[0m349      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3702   \u001b[0m | \u001b[0m0.8734   \u001b[0m |\n",
      "| \u001b[0m350      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4945   \u001b[0m | \u001b[0m0.8782   \u001b[0m |\n",
      "| \u001b[0m351      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.4551   \u001b[0m | \u001b[0m0.8868   \u001b[0m |\n",
      "| \u001b[0m352      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.486    \u001b[0m | \u001b[0m0.8859   \u001b[0m |\n",
      "| \u001b[0m353      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3154   \u001b[0m | \u001b[0m0.8816   \u001b[0m |\n",
      "| \u001b[0m354      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3422   \u001b[0m | \u001b[0m0.8813   \u001b[0m |\n",
      "| \u001b[0m355      \u001b[0m | \u001b[0m-1.029   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.382    \u001b[0m | \u001b[0m0.9032   \u001b[0m |\n",
      "| \u001b[0m356      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3907   \u001b[0m | \u001b[0m0.8937   \u001b[0m |\n",
      "| \u001b[0m357      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.3787   \u001b[0m | \u001b[0m0.8856   \u001b[0m |\n",
      "| \u001b[0m358      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5962   \u001b[0m | \u001b[0m0.893    \u001b[0m |\n",
      "| \u001b[0m359      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.597    \u001b[0m | \u001b[0m0.8807   \u001b[0m |\n",
      "| \u001b[0m360      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6142   \u001b[0m | \u001b[0m0.8911   \u001b[0m |\n",
      "| \u001b[0m361      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6144   \u001b[0m | \u001b[0m0.8775   \u001b[0m |\n",
      "| \u001b[0m362      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6058   \u001b[0m | \u001b[0m0.8856   \u001b[0m |\n",
      "| \u001b[0m363      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.5556   \u001b[0m | \u001b[0m0.8886   \u001b[0m |\n",
      "| \u001b[0m364      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.7318   \u001b[0m | \u001b[0m0.8663   \u001b[0m |\n",
      "| \u001b[0m365      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.8801   \u001b[0m | \u001b[0m0.874    \u001b[0m |\n",
      "| \u001b[0m366      \u001b[0m | \u001b[0m-1.017   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m0.6748   \u001b[0m | \u001b[0m0.8833   \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/bayes_opt/bayesian_optimization.py:305\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_queue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/bayes_opt/bayesian_optimization.py:27\u001b[0m, in \u001b[0;36mQueue.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueue is empty, no more objects to retrieve.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 43\u001b[0m\n\u001b[1;32m     36\u001b[0m pbounds \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;28mint\u001b[39m(best_params[cluster][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(best_params[cluster][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m])),\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: (best_params[cluster][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.05\u001b[39m, best_params[cluster][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.05\u001b[39m),\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_leaf_reg\u001b[39m\u001b[38;5;124m'\u001b[39m: (best_params[cluster][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_leaf_reg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.1\u001b[39m, best_params[cluster][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_leaf_reg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     40\u001b[0m }\n\u001b[1;32m     42\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(f\u001b[38;5;241m=\u001b[39mcatboost_eval, pbounds\u001b[38;5;241m=\u001b[39mpbounds, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 初始点和迭代次数\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# 保存最佳参数和RMSE\u001b[39;00m\n\u001b[1;32m     46\u001b[0m best_params[cluster] \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mmax[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/bayes_opt/bayesian_optimization.py:308\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     util\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[0;32m--> 308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutil\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/bayes_opt/bayesian_optimization.py:220\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    219\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_constrained:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m    223\u001b[0m                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39m_constraint_values)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/gaussian_process/_gpr.py:307\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(theta, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# First optimize starting from theta specified in kernel\u001b[39;00m\n\u001b[1;32m    305\u001b[0m optima \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    306\u001b[0m     (\n\u001b[0;32m--> 307\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     )\n\u001b[1;32m    311\u001b[0m ]\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# Additional runs are performed from log-uniform chosen initial\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/gaussian_process/_gpr.py:656\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 656\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[1;32m    664\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    694\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 696\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    699\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    700\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    353\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/gaussian_process/_gpr.py:297\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 297\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/gaussian_process/_gpr.py:643\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    632\u001b[0m inner_term \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m K_inv[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# Since we are interested about the trace of\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# inner_term @ K_gradient, we don't explicitly compute the\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;66;03m# matrix-by-matrix operation and instead use an einsum. Therefore\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;66;03m#             K_gradient[..., param_idx]\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m#         )\u001b[39;00m\n\u001b[0;32m--> 643\u001b[0m log_likelihood_gradient_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mijl,jik->kl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_term\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_gradient\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# the log likehood gradient is the sum-up across the outputs\u001b[39;00m\n\u001b[1;32m    647\u001b[0m log_likelihood_gradient \u001b[38;5;241m=\u001b[39m log_likelihood_gradient_dims\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/einsumfunc.py:1371\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[1;32m   1370\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out\n\u001b[0;32m-> 1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m valid_einsum_kwargs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 初始化存储最佳参数和RMSE的字典\n",
    "# best_params = {}\n",
    "best_rmse = {}\n",
    "\n",
    "# 定义CatBoost模型的目标函数\n",
    "def catboost_eval(depth, learning_rate, l2_leaf_reg):\n",
    "    params = {\n",
    "        'iterations': 1000,\n",
    "        'depth': int(depth),\n",
    "        'learning_rate': learning_rate,\n",
    "        'l2_leaf_reg': l2_leaf_reg,\n",
    "        'loss_function': 'RMSE',\n",
    "        'verbose': False\n",
    "    }\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=20)\n",
    "    # model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    return -rmse\n",
    "\n",
    "# 进行Bayesian优化\n",
    "for cluster in [5, 7, 8]:\n",
    "    train_cluster_data = train_df[train_df['Cluster'] == cluster]\n",
    "    X_train = train_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y_train = train_cluster_data['stars']\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "\n",
    "    X_test, y_test = prepare_test_data(test_df, cluster)\n",
    "\n",
    "    pbounds = {\n",
    "        'depth': (int(best_params[cluster]['depth']), int(best_params[cluster]['depth'])),\n",
    "        'learning_rate': (best_params[cluster]['learning_rate'] - 0.05, best_params[cluster]['learning_rate'] + 0.05),\n",
    "        'l2_leaf_reg': (best_params[cluster]['l2_leaf_reg'] - 0.1, best_params[cluster]['l2_leaf_reg'] + 0.5)\n",
    "    }\n",
    "\n",
    "    optimizer = BayesianOptimization(f=catboost_eval, pbounds=pbounds, random_state=1)\n",
    "    optimizer.maximize(init_points=300, n_iter=100)  # 初始点和迭代次数\n",
    "\n",
    "    # 保存最佳参数和RMSE\n",
    "    best_params[cluster] = optimizer.max['params']\n",
    "    best_rmse[cluster] = -optimizer.max['target']\n",
    "\n",
    "    print(f\"Best parameters for Cluster {cluster}: {best_params[cluster]}\")\n",
    "    print(f\"Best RMSE for Cluster {cluster}: {best_rmse[cluster]}\")\n",
    "\n",
    "# 输出所有最佳参数和RMSE\n",
    "print(\"Best Parameters for each cluster:\", best_params)\n",
    "print(\"Best RMSEs for each cluster:\", best_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242df112-e988-4620-a5d3-fee227ab6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best RMSEs for each cluster: {5: 1.016683932307932, 7: 1.0235422827493459, 8: 1.0067979494296004}\n",
    "Best Parameters for each cluster: {5: {'depth': 2.8372035559550515, 'l2_leaf_reg': 0.415375550656062, 'learning_rate': 0.9017553809036529}, \n",
    "                                   7: {'depth': 5.629383322650899, 'l2_leaf_reg': 18.092897673552347, 'learning_rate': 0.9302409756669214}, \n",
    "                                   8: {'depth': 1.5335491744742042, 'l2_leaf_reg': 7.9441523547045145, 'learning_rate': 0.24635888070147063}}\n",
    "\n",
    "\n",
    "# Best RMSEs for each cluster: {5: 1.0167557553607258, 7: 1.024030158568109, 8: 1.006788237522231}\n",
    "# Best Parameters for each cluster: {5: {'depth': 2.1531204375035022, 'l2_leaf_reg': 0.9149735257647046, 'learning_rate': 0.854079466000547}, \n",
    "#                                    7: {'depth': 5.214188323944921, 'l2_leaf_reg': 18.292789406047262, 'learning_rate': 0.9229233425688939}, \n",
    "#                                    8: {'depth': 1.829594199526172, 'l2_leaf_reg': 7.93945174660862, 'learning_rate': 0.24655331821866988}}\n",
    "\n",
    "Best RMSEs for each cluster: {5: 1.0169264030768188, 7: 1.0235736207689943, 8: 1.0052618567763993}\n",
    "Best Parameters for each cluster: {5: {'depth': 2.575413872096655, 'l2_leaf_reg': 1.2907324679934653, 'learning_rate': 0.8549361230165192}, \n",
    "                                   7: {'depth': 5.595277607917133, 'l2_leaf_reg': 18.3792029910461, 'learning_rate': 0.9372003134293689}, \n",
    "                                   8: {'depth': 1.259435014043129, 'l2_leaf_reg': 7.440376345058953, 'learning_rate': 0.4049807340854126}}\n",
    "\n",
    "# Best RMSEs for each cluster: {5: 1.0183972296867843, 7: 1.02524269156402, 8: 1.0052728101359314}\n",
    "# Best Parameters for each cluster: {5: {'depth': 2.7171259457036654, 'l2_leaf_reg': 1.6469803776077248, 'learning_rate': 0.7897939925293112}, \n",
    "#                                    7: {'depth': 5.069375108517913, 'l2_leaf_reg': 17.99920470248267, 'learning_rate': 0.8756635310988201}, \n",
    "#                                    8: {'depth': 1.084407832239098, 'l2_leaf_reg': 7.730202335144113, 'learning_rate': 0.40387851258988705}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299343aa-b79e-4675-8e46-3b3a75e1f89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "802b915c-976a-4671-8213-57d8e09212cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best RMSEs for each cluster: {5: 1.0007843912278394, 7: 1.0156949948241945, 8: 0.9990973587899347}\n",
    "***best_params = {5: {'depth': 2.536426180826484, 'l2_leaf_reg': 2.1469803776077248, 'learning_rate': 0.7397939925293111}, \n",
    "               7: {'depth': 6.87137925586567, 'l2_leaf_reg': 18.323103915785264, 'learning_rate': 0.8392475333120256}, \n",
    "               8: {'depth': 2.3176722810449486, 'l2_leaf_reg': 7.572561905566506, 'learning_rate': 0.3547615081241711}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8026cdc-7483-4cd4-b537-52c9d944a4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8e8e9e2-d52f-41f3-b46c-f819fb53d37b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   depth   | l2_lea... | learni... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-0.8912  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.516    \u001b[0m | \u001b[0m0.3377   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-0.891   \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.172    \u001b[0m | \u001b[95m0.3469   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-0.89    \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.291    \u001b[0m | \u001b[95m0.3774   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-0.8947  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.335    \u001b[0m | \u001b[0m0.4062   \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-0.8885  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.61     \u001b[0m | \u001b[95m0.3404   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.334    \u001b[0m | \u001b[0m0.3936   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-0.8917  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.202    \u001b[0m | \u001b[0m0.4178   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-0.8934  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.272    \u001b[0m | \u001b[0m0.4069   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.62     \u001b[0m | \u001b[0m0.3462   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.185    \u001b[0m | \u001b[0m0.4255   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-0.8925  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.336    \u001b[0m | \u001b[0m0.4335   \u001b[0m |\n",
      "| \u001b[95m12       \u001b[0m | \u001b[95m-0.8884  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.499    \u001b[0m | \u001b[95m0.3693   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-0.8884  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.584    \u001b[0m | \u001b[0m0.3395   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.677    \u001b[0m | \u001b[0m0.4125   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.557    \u001b[0m | \u001b[0m0.348    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-0.8884  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.629    \u001b[0m | \u001b[0m0.3671   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-0.8931  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.162    \u001b[0m | \u001b[0m0.3396   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.211    \u001b[0m | \u001b[0m0.3643   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-0.8888  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.116    \u001b[0m | \u001b[0m0.3951   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-0.8911  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.437    \u001b[0m | \u001b[0m0.4077   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-0.8897  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.332    \u001b[0m | \u001b[0m0.4071   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-0.8888  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.114    \u001b[0m | \u001b[0m0.3913   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-0.8914  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.392    \u001b[0m | \u001b[0m0.4322   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-0.8896  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.626    \u001b[0m | \u001b[0m0.3514   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.568    \u001b[0m | \u001b[0m0.3775   \u001b[0m |\n",
      "| \u001b[95m26       \u001b[0m | \u001b[95m-0.8884  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.64     \u001b[0m | \u001b[95m0.3725   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.519    \u001b[0m | \u001b[0m0.426    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-0.891   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.534    \u001b[0m | \u001b[0m0.3726   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-0.8895  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.621    \u001b[0m | \u001b[0m0.3805   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.482    \u001b[0m | \u001b[0m0.3999   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-0.8899  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.653    \u001b[0m | \u001b[0m0.3827   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.328    \u001b[0m | \u001b[0m0.3614   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-0.8897  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.428    \u001b[0m | \u001b[0m0.338    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.28     \u001b[0m | \u001b[0m0.3904   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.298    \u001b[0m | \u001b[0m0.4286   \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-0.8914  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.093    \u001b[0m | \u001b[0m0.4306   \u001b[0m |\n",
      "| \u001b[95m37       \u001b[0m | \u001b[95m-0.8869  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.682    \u001b[0m | \u001b[95m0.3549   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-0.8881  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.643    \u001b[0m | \u001b[0m0.4074   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.537    \u001b[0m | \u001b[0m0.4131   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.51     \u001b[0m | \u001b[0m0.3501   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-0.8928  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.099    \u001b[0m | \u001b[0m0.3405   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-0.893   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.6      \u001b[0m | \u001b[0m0.3916   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.589    \u001b[0m | \u001b[0m0.3501   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-0.8925  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.435    \u001b[0m | \u001b[0m0.4347   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-0.8898  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.095    \u001b[0m | \u001b[0m0.4178   \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.568    \u001b[0m | \u001b[0m0.3765   \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-0.893   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.532    \u001b[0m | \u001b[0m0.3933   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-0.8917  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.12     \u001b[0m | \u001b[0m0.3498   \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-0.8901  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.148    \u001b[0m | \u001b[0m0.3603   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-0.8897  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.419    \u001b[0m | \u001b[0m0.339    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.664    \u001b[0m | \u001b[0m0.3945   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.235    \u001b[0m | \u001b[0m0.4121   \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-0.8925  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.432    \u001b[0m | \u001b[0m0.4347   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.227    \u001b[0m | \u001b[0m0.3871   \u001b[0m |\n",
      "| \u001b[95m55       \u001b[0m | \u001b[95m-0.8868  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.581    \u001b[0m | \u001b[95m0.3534   \u001b[0m |\n",
      "| \u001b[95m56       \u001b[0m | \u001b[95m-0.8848  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.126    \u001b[0m | \u001b[95m0.3863   \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m-0.8884  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.425    \u001b[0m | \u001b[0m0.3694   \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.431    \u001b[0m | \u001b[0m0.3757   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.531    \u001b[0m | \u001b[0m0.4046   \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.123    \u001b[0m | \u001b[0m0.3747   \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.21     \u001b[0m | \u001b[0m0.413    \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-0.8898  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.24     \u001b[0m | \u001b[0m0.4182   \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.467    \u001b[0m | \u001b[0m0.3902   \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.242    \u001b[0m | \u001b[0m0.3443   \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.547    \u001b[0m | \u001b[0m0.4285   \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.092    \u001b[0m | \u001b[0m0.3611   \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-0.8914  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.653    \u001b[0m | \u001b[0m0.4327   \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.633    \u001b[0m | \u001b[0m0.4019   \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.375    \u001b[0m | \u001b[0m0.3981   \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.639    \u001b[0m | \u001b[0m0.4296   \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-0.8869  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.662    \u001b[0m | \u001b[0m0.3551   \u001b[0m |\n",
      "| \u001b[95m72       \u001b[0m | \u001b[95m-0.8848  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.165    \u001b[0m | \u001b[95m0.3883   \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-0.8917  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.652    \u001b[0m | \u001b[0m0.4204   \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-0.8884  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.189    \u001b[0m | \u001b[0m0.3709   \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m-0.8884  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.569    \u001b[0m | \u001b[0m0.3722   \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.433    \u001b[0m | \u001b[0m0.4256   \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.627    \u001b[0m | \u001b[0m0.3837   \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.563    \u001b[0m | \u001b[0m0.3663   \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m-0.8897  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.443    \u001b[0m | \u001b[0m0.3393   \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m-0.8898  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.344    \u001b[0m | \u001b[0m0.4184   \u001b[0m |\n",
      "| \u001b[0m81       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.619    \u001b[0m | \u001b[0m0.3955   \u001b[0m |\n",
      "| \u001b[0m82       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.556    \u001b[0m | \u001b[0m0.3989   \u001b[0m |\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.336    \u001b[0m | \u001b[0m0.4056   \u001b[0m |\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m-0.8925  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.084    \u001b[0m | \u001b[0m0.4354   \u001b[0m |\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.668    \u001b[0m | \u001b[0m0.3982   \u001b[0m |\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.428    \u001b[0m | \u001b[0m0.4005   \u001b[0m |\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.436    \u001b[0m | \u001b[0m0.4127   \u001b[0m |\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m-0.8954  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.537    \u001b[0m | \u001b[0m0.4075   \u001b[0m |\n",
      "| \u001b[0m89       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.277    \u001b[0m | \u001b[0m0.4048   \u001b[0m |\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.313    \u001b[0m | \u001b[0m0.3788   \u001b[0m |\n",
      "| \u001b[0m91       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.274    \u001b[0m | \u001b[0m0.3999   \u001b[0m |\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.668    \u001b[0m | \u001b[0m0.4055   \u001b[0m |\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m-0.8911  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.34     \u001b[0m | \u001b[0m0.372    \u001b[0m |\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.612    \u001b[0m | \u001b[0m0.4281   \u001b[0m |\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.246    \u001b[0m | \u001b[0m0.3629   \u001b[0m |\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m-0.8917  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.4179   \u001b[0m |\n",
      "| \u001b[0m97       \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.523    \u001b[0m | \u001b[0m0.3896   \u001b[0m |\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.425    \u001b[0m | \u001b[0m0.3843   \u001b[0m |\n",
      "| \u001b[0m99       \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.124    \u001b[0m | \u001b[0m0.3755   \u001b[0m |\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m-0.8868  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.673    \u001b[0m | \u001b[0m0.3559   \u001b[0m |\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m-0.8881  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.609    \u001b[0m | \u001b[0m0.4065   \u001b[0m |\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.18     \u001b[0m | \u001b[0m0.3844   \u001b[0m |\n",
      "| \u001b[0m103      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.219    \u001b[0m | \u001b[0m0.397    \u001b[0m |\n",
      "| \u001b[0m104      \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.633    \u001b[0m | \u001b[0m0.4287   \u001b[0m |\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m-0.8895  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.15     \u001b[0m | \u001b[0m0.357    \u001b[0m |\n",
      "| \u001b[0m106      \u001b[0m | \u001b[0m-0.8869  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.521    \u001b[0m | \u001b[0m0.3585   \u001b[0m |\n",
      "| \u001b[0m107      \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.595    \u001b[0m | \u001b[0m0.3793   \u001b[0m |\n",
      "| \u001b[0m108      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.224    \u001b[0m | \u001b[0m0.3479   \u001b[0m |\n",
      "| \u001b[0m109      \u001b[0m | \u001b[0m-0.8896  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.37     \u001b[0m | \u001b[0m0.353    \u001b[0m |\n",
      "| \u001b[0m110      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.41     \u001b[0m | \u001b[0m0.4031   \u001b[0m |\n",
      "| \u001b[0m111      \u001b[0m | \u001b[0m-0.8869  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.534    \u001b[0m | \u001b[0m0.3599   \u001b[0m |\n",
      "| \u001b[0m112      \u001b[0m | \u001b[0m-0.8884  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.555    \u001b[0m | \u001b[0m0.3399   \u001b[0m |\n",
      "| \u001b[0m113      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.607    \u001b[0m | \u001b[0m0.4222   \u001b[0m |\n",
      "| \u001b[0m114      \u001b[0m | \u001b[0m-0.8914  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.604    \u001b[0m | \u001b[0m0.4327   \u001b[0m |\n",
      "| \u001b[0m115      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.596    \u001b[0m | \u001b[0m0.3476   \u001b[0m |\n",
      "| \u001b[0m116      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.506    \u001b[0m | \u001b[0m0.3987   \u001b[0m |\n",
      "| \u001b[0m117      \u001b[0m | \u001b[0m-0.8898  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.104    \u001b[0m | \u001b[0m0.4147   \u001b[0m |\n",
      "| \u001b[0m118      \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.239    \u001b[0m | \u001b[0m0.3634   \u001b[0m |\n",
      "| \u001b[0m119      \u001b[0m | \u001b[0m-0.8898  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.291    \u001b[0m | \u001b[0m0.4174   \u001b[0m |\n",
      "| \u001b[0m120      \u001b[0m | \u001b[0m-0.8925  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.553    \u001b[0m | \u001b[0m0.4367   \u001b[0m |\n",
      "| \u001b[0m121      \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.169    \u001b[0m | \u001b[0m0.4278   \u001b[0m |\n",
      "| \u001b[0m122      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.668    \u001b[0m | \u001b[0m0.4014   \u001b[0m |\n",
      "| \u001b[0m123      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.411    \u001b[0m | \u001b[0m0.3903   \u001b[0m |\n",
      "| \u001b[0m124      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.297    \u001b[0m | \u001b[0m0.3403   \u001b[0m |\n",
      "| \u001b[0m125      \u001b[0m | \u001b[0m-0.8917  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.531    \u001b[0m | \u001b[0m0.3407   \u001b[0m |\n",
      "| \u001b[0m126      \u001b[0m | \u001b[0m-0.8881  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.601    \u001b[0m | \u001b[0m0.407    \u001b[0m |\n",
      "| \u001b[0m127      \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.197    \u001b[0m | \u001b[0m0.3819   \u001b[0m |\n",
      "| \u001b[0m128      \u001b[0m | \u001b[0m-0.8868  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.677    \u001b[0m | \u001b[0m0.3581   \u001b[0m |\n",
      "| \u001b[0m129      \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.241    \u001b[0m | \u001b[0m0.4127   \u001b[0m |\n",
      "| \u001b[95m130      \u001b[0m | \u001b[95m-0.8848  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.118    \u001b[0m | \u001b[95m0.3886   \u001b[0m |\n",
      "| \u001b[0m131      \u001b[0m | \u001b[0m-0.8884  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.563    \u001b[0m | \u001b[0m0.3674   \u001b[0m |\n",
      "| \u001b[0m132      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.44     \u001b[0m | \u001b[0m0.4221   \u001b[0m |\n",
      "| \u001b[0m133      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.533    \u001b[0m | \u001b[0m0.3888   \u001b[0m |\n",
      "| \u001b[0m134      \u001b[0m | \u001b[0m-0.8926  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.659    \u001b[0m | \u001b[0m0.4181   \u001b[0m |\n",
      "| \u001b[0m135      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.509    \u001b[0m | \u001b[0m0.3842   \u001b[0m |\n",
      "| \u001b[0m136      \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.216    \u001b[0m | \u001b[0m0.3644   \u001b[0m |\n",
      "| \u001b[0m137      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.341    \u001b[0m | \u001b[0m0.3486   \u001b[0m |\n",
      "| \u001b[0m138      \u001b[0m | \u001b[0m-0.8954  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.565    \u001b[0m | \u001b[0m0.4074   \u001b[0m |\n",
      "| \u001b[0m139      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.289    \u001b[0m | \u001b[0m0.4223   \u001b[0m |\n",
      "| \u001b[0m140      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.578    \u001b[0m | \u001b[0m0.4004   \u001b[0m |\n",
      "| \u001b[0m141      \u001b[0m | \u001b[0m-0.8926  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.131    \u001b[0m | \u001b[0m0.3395   \u001b[0m |\n",
      "| \u001b[0m142      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.359    \u001b[0m | \u001b[0m0.349    \u001b[0m |\n",
      "| \u001b[0m143      \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.536    \u001b[0m | \u001b[0m0.3772   \u001b[0m |\n",
      "| \u001b[0m144      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.355    \u001b[0m | \u001b[0m0.3827   \u001b[0m |\n",
      "| \u001b[0m145      \u001b[0m | \u001b[0m-0.8917  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.368    \u001b[0m | \u001b[0m0.418    \u001b[0m |\n",
      "| \u001b[0m146      \u001b[0m | \u001b[0m-0.8899  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.626    \u001b[0m | \u001b[0m0.3414   \u001b[0m |\n",
      "| \u001b[0m147      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.159    \u001b[0m | \u001b[0m0.3996   \u001b[0m |\n",
      "| \u001b[0m148      \u001b[0m | \u001b[0m-0.8897  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.407    \u001b[0m | \u001b[0m0.338    \u001b[0m |\n",
      "| \u001b[0m149      \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.627    \u001b[0m | \u001b[0m0.4173   \u001b[0m |\n",
      "| \u001b[0m150      \u001b[0m | \u001b[0m-0.8895  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.171    \u001b[0m | \u001b[0m0.3535   \u001b[0m |\n",
      "| \u001b[0m151      \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.457    \u001b[0m | \u001b[0m0.4283   \u001b[0m |\n",
      "| \u001b[0m152      \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.51     \u001b[0m | \u001b[0m0.4109   \u001b[0m |\n",
      "| \u001b[0m153      \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.324    \u001b[0m | \u001b[0m0.3627   \u001b[0m |\n",
      "| \u001b[0m154      \u001b[0m | \u001b[0m-0.8898  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.155    \u001b[0m | \u001b[0m0.419    \u001b[0m |\n",
      "| \u001b[0m155      \u001b[0m | \u001b[0m-0.8898  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.242    \u001b[0m | \u001b[0m0.4196   \u001b[0m |\n",
      "| \u001b[0m156      \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.673    \u001b[0m | \u001b[0m0.3644   \u001b[0m |\n",
      "| \u001b[0m157      \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.272    \u001b[0m | \u001b[0m0.4288   \u001b[0m |\n",
      "| \u001b[0m158      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.344    \u001b[0m | \u001b[0m0.3889   \u001b[0m |\n",
      "| \u001b[0m159      \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.102    \u001b[0m | \u001b[0m0.4094   \u001b[0m |\n",
      "| \u001b[95m160      \u001b[0m | \u001b[95m-0.8848  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.1      \u001b[0m | \u001b[95m0.3899   \u001b[0m |\n",
      "| \u001b[0m161      \u001b[0m | \u001b[0m-0.893   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.599    \u001b[0m | \u001b[0m0.3936   \u001b[0m |\n",
      "| \u001b[0m162      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.355    \u001b[0m | \u001b[0m0.4005   \u001b[0m |\n",
      "| \u001b[0m163      \u001b[0m | \u001b[0m-0.8888  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.089    \u001b[0m | \u001b[0m0.3954   \u001b[0m |\n",
      "| \u001b[0m164      \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.394    \u001b[0m | \u001b[0m0.4293   \u001b[0m |\n",
      "| \u001b[0m165      \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.232    \u001b[0m | \u001b[0m0.3748   \u001b[0m |\n",
      "| \u001b[0m166      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.646    \u001b[0m | \u001b[0m0.4221   \u001b[0m |\n",
      "| \u001b[0m167      \u001b[0m | \u001b[0m-0.8905  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.22     \u001b[0m | \u001b[0m0.3464   \u001b[0m |\n",
      "| \u001b[0m168      \u001b[0m | \u001b[0m-0.8895  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.272    \u001b[0m | \u001b[0m0.3552   \u001b[0m |\n",
      "| \u001b[0m169      \u001b[0m | \u001b[0m-0.8898  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.332    \u001b[0m | \u001b[0m0.4193   \u001b[0m |\n",
      "| \u001b[0m170      \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.505    \u001b[0m | \u001b[0m0.3617   \u001b[0m |\n",
      "| \u001b[0m171      \u001b[0m | \u001b[0m-0.8917  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.293    \u001b[0m | \u001b[0m0.3434   \u001b[0m |\n",
      "| \u001b[0m172      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.482    \u001b[0m | \u001b[0m0.3874   \u001b[0m |\n",
      "| \u001b[0m173      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.188    \u001b[0m | \u001b[0m0.3948   \u001b[0m |\n",
      "| \u001b[0m174      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.574    \u001b[0m | \u001b[0m0.3971   \u001b[0m |\n",
      "| \u001b[0m175      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.624    \u001b[0m | \u001b[0m0.3973   \u001b[0m |\n",
      "| \u001b[0m176      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.14     \u001b[0m | \u001b[0m0.3442   \u001b[0m |\n",
      "| \u001b[0m177      \u001b[0m | \u001b[0m-0.8925  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.309    \u001b[0m | \u001b[0m0.4352   \u001b[0m |\n",
      "| \u001b[0m178      \u001b[0m | \u001b[0m-0.8893  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.667    \u001b[0m | \u001b[0m0.4144   \u001b[0m |\n",
      "| \u001b[0m179      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.463    \u001b[0m | \u001b[0m0.4046   \u001b[0m |\n",
      "| \u001b[0m180      \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.091    \u001b[0m | \u001b[0m0.373    \u001b[0m |\n",
      "| \u001b[0m181      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.522    \u001b[0m | \u001b[0m0.3846   \u001b[0m |\n",
      "| \u001b[0m182      \u001b[0m | \u001b[0m-0.8961  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.166    \u001b[0m | \u001b[0m0.3388   \u001b[0m |\n",
      "| \u001b[0m183      \u001b[0m | \u001b[0m-0.8925  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.276    \u001b[0m | \u001b[0m0.4361   \u001b[0m |\n",
      "| \u001b[0m184      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.287    \u001b[0m | \u001b[0m0.3901   \u001b[0m |\n",
      "| \u001b[0m185      \u001b[0m | \u001b[0m-0.8896  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.362    \u001b[0m | \u001b[0m0.3502   \u001b[0m |\n",
      "| \u001b[0m186      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.386    \u001b[0m | \u001b[0m0.4051   \u001b[0m |\n",
      "| \u001b[0m187      \u001b[0m | \u001b[0m-0.8932  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.162    \u001b[0m | \u001b[0m0.34     \u001b[0m |\n",
      "| \u001b[0m188      \u001b[0m | \u001b[0m-0.8918  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.57     \u001b[0m | \u001b[0m0.339    \u001b[0m |\n",
      "| \u001b[0m189      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.496    \u001b[0m | \u001b[0m0.3826   \u001b[0m |\n",
      "| \u001b[0m190      \u001b[0m | \u001b[0m-0.8901  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.47     \u001b[0m | \u001b[0m0.3382   \u001b[0m |\n",
      "| \u001b[0m191      \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.599    \u001b[0m | \u001b[0m0.4207   \u001b[0m |\n",
      "| \u001b[0m192      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.488    \u001b[0m | \u001b[0m0.3956   \u001b[0m |\n",
      "| \u001b[0m193      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.42     \u001b[0m | \u001b[0m0.4049   \u001b[0m |\n",
      "| \u001b[0m194      \u001b[0m | \u001b[0m-0.8869  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.597    \u001b[0m | \u001b[0m0.3572   \u001b[0m |\n",
      "| \u001b[0m195      \u001b[0m | \u001b[0m-0.891   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.257    \u001b[0m | \u001b[0m0.4151   \u001b[0m |\n",
      "| \u001b[0m196      \u001b[0m | \u001b[0m-0.89    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.568    \u001b[0m | \u001b[0m0.3731   \u001b[0m |\n",
      "| \u001b[0m197      \u001b[0m | \u001b[0m-0.8884  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.544    \u001b[0m | \u001b[0m0.3686   \u001b[0m |\n",
      "| \u001b[0m198      \u001b[0m | \u001b[0m-0.8869  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.53     \u001b[0m | \u001b[0m0.3598   \u001b[0m |\n",
      "| \u001b[0m199      \u001b[0m | \u001b[0m-0.887   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.203    \u001b[0m | \u001b[0m0.352    \u001b[0m |\n",
      "| \u001b[0m200      \u001b[0m | \u001b[0m-0.8915  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m0.3488   \u001b[0m |\n",
      "| \u001b[0m201      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.165    \u001b[0m | \u001b[0m0.3885   \u001b[0m |\n",
      "| \u001b[0m202      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.164    \u001b[0m | \u001b[0m0.3881   \u001b[0m |\n",
      "| \u001b[0m203      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.125    \u001b[0m | \u001b[0m0.3874   \u001b[0m |\n",
      "| \u001b[0m204      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.336    \u001b[0m | \u001b[0m0.4057   \u001b[0m |\n",
      "| \u001b[0m205      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.164    \u001b[0m | \u001b[0m0.3897   \u001b[0m |\n",
      "| \u001b[0m206      \u001b[0m | \u001b[0m-0.8885  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.241    \u001b[0m | \u001b[0m0.4127   \u001b[0m |\n",
      "| \u001b[0m207      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.164    \u001b[0m | \u001b[0m0.3889   \u001b[0m |\n",
      "| \u001b[0m208      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.119    \u001b[0m | \u001b[0m0.3892   \u001b[0m |\n",
      "| \u001b[0m209      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.165    \u001b[0m | \u001b[0m0.3902   \u001b[0m |\n",
      "| \u001b[0m210      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.127    \u001b[0m | \u001b[0m0.3874   \u001b[0m |\n",
      "| \u001b[0m211      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.127    \u001b[0m | \u001b[0m0.3883   \u001b[0m |\n",
      "| \u001b[0m212      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.099    \u001b[0m | \u001b[0m0.3892   \u001b[0m |\n",
      "| \u001b[0m213      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.126    \u001b[0m | \u001b[0m0.3856   \u001b[0m |\n",
      "| \u001b[0m214      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.118    \u001b[0m | \u001b[0m0.3905   \u001b[0m |\n",
      "| \u001b[0m215      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m0.3883   \u001b[0m |\n",
      "| \u001b[0m216      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.101    \u001b[0m | \u001b[0m0.3897   \u001b[0m |\n",
      "| \u001b[0m217      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.117    \u001b[0m | \u001b[0m0.3895   \u001b[0m |\n",
      "| \u001b[0m218      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.164    \u001b[0m | \u001b[0m0.3863   \u001b[0m |\n",
      "| \u001b[0m219      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.162    \u001b[0m | \u001b[0m0.3873   \u001b[0m |\n",
      "| \u001b[0m220      \u001b[0m | \u001b[0m-0.8887  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.338    \u001b[0m | \u001b[0m0.4044   \u001b[0m |\n",
      "| \u001b[0m221      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.166    \u001b[0m | \u001b[0m0.3871   \u001b[0m |\n",
      "| \u001b[0m222      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.163    \u001b[0m | \u001b[0m0.3909   \u001b[0m |\n",
      "| \u001b[0m223      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.162    \u001b[0m | \u001b[0m0.3852   \u001b[0m |\n",
      "| \u001b[0m224      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.126    \u001b[0m | \u001b[0m0.3891   \u001b[0m |\n",
      "| \u001b[0m225      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.128    \u001b[0m | \u001b[0m0.3864   \u001b[0m |\n",
      "| \u001b[0m226      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.129    \u001b[0m | \u001b[0m0.3847   \u001b[0m |\n",
      "| \u001b[0m227      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.162    \u001b[0m | \u001b[0m0.3887   \u001b[0m |\n",
      "| \u001b[0m228      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.166    \u001b[0m | \u001b[0m0.3855   \u001b[0m |\n",
      "| \u001b[0m229      \u001b[0m | \u001b[0m-0.8888  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.117    \u001b[0m | \u001b[0m0.3911   \u001b[0m |\n",
      "| \u001b[0m230      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.163    \u001b[0m | \u001b[0m0.387    \u001b[0m |\n",
      "| \u001b[0m231      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.12     \u001b[0m | \u001b[0m0.3895   \u001b[0m |\n",
      "| \u001b[0m232      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.122    \u001b[0m | \u001b[0m0.3906   \u001b[0m |\n",
      "| \u001b[0m233      \u001b[0m | \u001b[0m-0.8888  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.12     \u001b[0m | \u001b[0m0.3912   \u001b[0m |\n",
      "| \u001b[0m234      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.124    \u001b[0m | \u001b[0m0.3891   \u001b[0m |\n",
      "| \u001b[0m235      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.122    \u001b[0m | \u001b[0m0.3882   \u001b[0m |\n",
      "| \u001b[0m236      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.123    \u001b[0m | \u001b[0m0.3906   \u001b[0m |\n",
      "| \u001b[0m237      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.161    \u001b[0m | \u001b[0m0.3886   \u001b[0m |\n",
      "| \u001b[0m238      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.116    \u001b[0m | \u001b[0m0.388    \u001b[0m |\n",
      "| \u001b[0m239      \u001b[0m | \u001b[0m-0.8888  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.126    \u001b[0m | \u001b[0m0.3915   \u001b[0m |\n",
      "| \u001b[0m240      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.122    \u001b[0m | \u001b[0m0.3864   \u001b[0m |\n",
      "| \u001b[0m241      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.124    \u001b[0m | \u001b[0m0.3855   \u001b[0m |\n",
      "| \u001b[0m242      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.159    \u001b[0m | \u001b[0m0.3883   \u001b[0m |\n",
      "| \u001b[0m243      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.121    \u001b[0m | \u001b[0m0.3875   \u001b[0m |\n",
      "| \u001b[0m244      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.123    \u001b[0m | \u001b[0m0.3873   \u001b[0m |\n",
      "| \u001b[0m245      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.121    \u001b[0m | \u001b[0m0.3851   \u001b[0m |\n",
      "| \u001b[0m246      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.119    \u001b[0m | \u001b[0m0.3862   \u001b[0m |\n",
      "| \u001b[0m247      \u001b[0m | \u001b[0m-0.8901  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.116    \u001b[0m | \u001b[0m0.3855   \u001b[0m |\n",
      "| \u001b[0m248      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.16     \u001b[0m | \u001b[0m0.3873   \u001b[0m |\n",
      "| \u001b[0m249      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.158    \u001b[0m | \u001b[0m0.3868   \u001b[0m |\n",
      "| \u001b[0m250      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.12     \u001b[0m | \u001b[0m0.3836   \u001b[0m |\n",
      "| \u001b[0m251      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.125    \u001b[0m | \u001b[0m0.3841   \u001b[0m |\n",
      "| \u001b[0m252      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.156    \u001b[0m | \u001b[0m0.3889   \u001b[0m |\n",
      "| \u001b[0m253      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.156    \u001b[0m | \u001b[0m0.3907   \u001b[0m |\n",
      "| \u001b[0m254      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.156    \u001b[0m | \u001b[0m0.3863   \u001b[0m |\n",
      "| \u001b[0m255      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.157    \u001b[0m | \u001b[0m0.388    \u001b[0m |\n",
      "| \u001b[0m256      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.157    \u001b[0m | \u001b[0m0.3844   \u001b[0m |\n",
      "| \u001b[0m257      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.154    \u001b[0m | \u001b[0m0.3878   \u001b[0m |\n",
      "| \u001b[0m258      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.153    \u001b[0m | \u001b[0m0.3893   \u001b[0m |\n",
      "| \u001b[0m259      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.152    \u001b[0m | \u001b[0m0.3884   \u001b[0m |\n",
      "| \u001b[0m260      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.155    \u001b[0m | \u001b[0m0.3872   \u001b[0m |\n",
      "| \u001b[0m261      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.152    \u001b[0m | \u001b[0m0.3864   \u001b[0m |\n",
      "| \u001b[0m262      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.153    \u001b[0m | \u001b[0m0.3851   \u001b[0m |\n",
      "| \u001b[0m263      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.149    \u001b[0m | \u001b[0m0.3878   \u001b[0m |\n",
      "| \u001b[0m264      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.149    \u001b[0m | \u001b[0m0.3857   \u001b[0m |\n",
      "| \u001b[0m265      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.15     \u001b[0m | \u001b[0m0.3846   \u001b[0m |\n",
      "| \u001b[0m266      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.147    \u001b[0m | \u001b[0m0.3886   \u001b[0m |\n",
      "| \u001b[0m267      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.145    \u001b[0m | \u001b[0m0.39     \u001b[0m |\n",
      "| \u001b[0m268      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.146    \u001b[0m | \u001b[0m0.3867   \u001b[0m |\n",
      "| \u001b[0m269      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.147    \u001b[0m | \u001b[0m0.3863   \u001b[0m |\n",
      "| \u001b[0m270      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.145    \u001b[0m | \u001b[0m0.3844   \u001b[0m |\n",
      "| \u001b[0m271      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.144    \u001b[0m | \u001b[0m0.3875   \u001b[0m |\n",
      "| \u001b[0m272      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.143    \u001b[0m | \u001b[0m0.3887   \u001b[0m |\n",
      "| \u001b[0m273      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.148    \u001b[0m | \u001b[0m0.3908   \u001b[0m |\n",
      "| \u001b[0m274      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.151    \u001b[0m | \u001b[0m0.3866   \u001b[0m |\n",
      "| \u001b[0m275      \u001b[0m | \u001b[0m-0.8888  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.143    \u001b[0m | \u001b[0m0.3916   \u001b[0m |\n",
      "| \u001b[0m276      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.099    \u001b[0m | \u001b[0m0.387    \u001b[0m |\n",
      "| \u001b[0m277      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.144    \u001b[0m | \u001b[0m0.389    \u001b[0m |\n",
      "| \u001b[0m278      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.096    \u001b[0m | \u001b[0m0.3889   \u001b[0m |\n",
      "| \u001b[0m279      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.096    \u001b[0m | \u001b[0m0.3872   \u001b[0m |\n",
      "| \u001b[0m280      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.093    \u001b[0m | \u001b[0m0.3873   \u001b[0m |\n",
      "| \u001b[0m281      \u001b[0m | \u001b[0m-0.8894  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.096    \u001b[0m | \u001b[0m0.3846   \u001b[0m |\n",
      "| \u001b[95m282      \u001b[0m | \u001b[95m-0.8848  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.094    \u001b[0m | \u001b[95m0.3898   \u001b[0m |\n",
      "| \u001b[0m283      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.091    \u001b[0m | \u001b[0m0.3893   \u001b[0m |\n",
      "| \u001b[0m284      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.09     \u001b[0m | \u001b[0m0.3873   \u001b[0m |\n",
      "| \u001b[0m285      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.142    \u001b[0m | \u001b[0m0.3865   \u001b[0m |\n",
      "| \u001b[0m286      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.14     \u001b[0m | \u001b[0m0.3881   \u001b[0m |\n",
      "| \u001b[0m287      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.088    \u001b[0m | \u001b[0m0.3883   \u001b[0m |\n",
      "| \u001b[0m288      \u001b[0m | \u001b[0m-0.8888  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.095    \u001b[0m | \u001b[0m0.3921   \u001b[0m |\n",
      "| \u001b[95m289      \u001b[0m | \u001b[95m-0.8848  \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m1.089    \u001b[0m | \u001b[95m0.3901   \u001b[0m |\n",
      "| \u001b[0m290      \u001b[0m | \u001b[0m-0.8888  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.087    \u001b[0m | \u001b[0m0.3914   \u001b[0m |\n",
      "| \u001b[0m291      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.14     \u001b[0m | \u001b[0m0.3866   \u001b[0m |\n",
      "| \u001b[0m292      \u001b[0m | \u001b[0m-0.8901  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.09     \u001b[0m | \u001b[0m0.3851   \u001b[0m |\n",
      "| \u001b[0m293      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.101    \u001b[0m | \u001b[0m0.3857   \u001b[0m |\n",
      "| \u001b[0m294      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.103    \u001b[0m | \u001b[0m0.3873   \u001b[0m |\n",
      "| \u001b[0m295      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.106    \u001b[0m | \u001b[0m0.3868   \u001b[0m |\n",
      "| \u001b[0m296      \u001b[0m | \u001b[0m-0.8901  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.104    \u001b[0m | \u001b[0m0.3853   \u001b[0m |\n",
      "| \u001b[0m297      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.106    \u001b[0m | \u001b[0m0.3896   \u001b[0m |\n",
      "| \u001b[0m298      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.105    \u001b[0m | \u001b[0m0.3887   \u001b[0m |\n",
      "| \u001b[0m299      \u001b[0m | \u001b[0m-0.8848  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.107    \u001b[0m | \u001b[0m0.3879   \u001b[0m |\n",
      "| \u001b[0m300      \u001b[0m | \u001b[0m-0.8888  \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.103    \u001b[0m | \u001b[0m0.3912   \u001b[0m |\n",
      "=============================================================\n",
      "Best parameters for Cluster 6: {'depth': 2.0, 'l2_leaf_reg': 1.089134331947135, 'learning_rate': 0.3901115268825481}\n",
      "Best RMSE for Cluster 6: 0.884815269154883\n",
      "Best Parameters for each cluster: {6: {'depth': 2.0, 'l2_leaf_reg': 1.089134331947135, 'learning_rate': 0.3901115268825481}}\n",
      "Best RMSEs for each cluster: {6: 0.884815269154883}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 初始化存储最佳参数和RMSE的字典\n",
    "# best_params = {}\n",
    "best_rmse = {}\n",
    "\n",
    "# 定义CatBoost模型的目标函数\n",
    "def catboost_eval(depth, learning_rate, l2_leaf_reg):\n",
    "    params = {\n",
    "        'iterations': 1000,\n",
    "        'depth': int(depth),\n",
    "        'learning_rate': learning_rate,\n",
    "        'l2_leaf_reg': l2_leaf_reg,\n",
    "        'loss_function': 'RMSE',\n",
    "        'verbose': False\n",
    "    }\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=20)\n",
    "    # model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    return -rmse\n",
    "\n",
    "# 进行Bayesian优化\n",
    "for cluster in [6]:\n",
    "    train_cluster_data = train_df[train_df['Cluster'] == cluster]\n",
    "    X_train = train_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y_train = train_cluster_data['stars']\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "    X_test, y_test = prepare_test_data(test_df, cluster)\n",
    "\n",
    "    pbounds = {\n",
    "        'depth': (int(best_params[cluster]['depth']), int(best_params[cluster]['depth'])),\n",
    "        'learning_rate': (best_params[cluster]['learning_rate'] - 0.05, best_params[cluster]['learning_rate'] + 0.05),\n",
    "        'l2_leaf_reg': (best_params[cluster]['l2_leaf_reg'] - 0.1, best_params[cluster]['l2_leaf_reg'] + 0.5)\n",
    "    }\n",
    "\n",
    "    optimizer = BayesianOptimization(f=catboost_eval, pbounds=pbounds, random_state=1)\n",
    "    optimizer.maximize(init_points=200, n_iter=100)  # 初始点和迭代次数\n",
    "\n",
    "    # 保存最佳参数和RMSE\n",
    "    best_params[cluster] = optimizer.max['params']\n",
    "    best_rmse[cluster] = -optimizer.max['target']\n",
    "\n",
    "    print(f\"Best parameters for Cluster {cluster}: {best_params[cluster]}\")\n",
    "    print(f\"Best RMSE for Cluster {cluster}: {best_rmse[cluster]}\")\n",
    "\n",
    "# 输出所有最佳参数和RMSE\n",
    "print(\"Best Parameters for each cluster:\", best_params)\n",
    "print(\"Best RMSEs for each cluster:\", best_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95215d0-c1ca-476a-93bd-0431e0f3de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Parameters for each cluster: {6: {'depth': 2.0, 'l2_leaf_reg': 1.1835517768726047, 'learning_rate': 0.38770112704134657}}\n",
    "Best RMSEs for each cluster: {6: 0.8837446917922023}\n",
    "\n",
    "Best Parameters for each cluster: {6: {'depth': 2.61655602741076, 'l2_leaf_reg': 0.7257814607240285, 'learning_rate': 0.4030828148420926}}\n",
    "Best RMSEs for each cluster: {6: 0.8842334031650307}\n",
    "\n",
    "Best Parameters for each cluster: {6: {'depth': 2.950053661171063, 'l2_leaf_reg': 0.6486081840841198, 'learning_rate': 0.39867067648355686}}\n",
    "Best RMSEs for each cluster: {6: 0.8865506932349891}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ac0c2bf-257a-4573-a637-3d7098ecc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {6: {'depth': 2.950053661171063, 'l2_leaf_reg': 0.6486081840841198, 'learning_rate': 0.39867067648355686}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224904ed-ede7-4801-ad1b-94f1e3079bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67064b42-0cbf-421f-90d9-bae6e7ff5977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f8477a-9c85-4df0-bff7-abb5207556de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18a160-eb90-40f5-9841-60c02bbf7608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ff997-92c5-40b0-b25a-3a6f274b6eba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Best Parameters for each cluster: {5: {'depth': 2.993493090480159, 'l2_leaf_reg': 1.9453159754453004, 'learning_rate': 0.736287494768294}, \n",
    "#                                    7: {'depth': 6.87137925586567, 'l2_leaf_reg': 18.323103915785264, 'learning_rate': 0.8392475333120256}, \n",
    "#                                    8: {'depth': 2.208545783377387, 'l2_leaf_reg': 8.456919746460654, 'learning_rate': 0.2832516216429279}}\n",
    "# Best RMSEs for each cluster: {5: 1.0010820144199166, 7: 1.015653168191138, 8: 1.000305549514303}\n",
    "\n",
    "# Best Parameters for each cluster: {***5: {'depth': 2.536426180826484, 'l2_leaf_reg': 2.1469803776077248, 'learning_rate': 0.7397939925293111}, \n",
    "#                                    7: {'depth': 6.716705166497869, 'l2_leaf_reg': 17.60463486698329, 'learning_rate': 0.7809900704215599}, \n",
    "#                                    ***8: {'depth': 2.2848383925693954, 'l2_leaf_reg': 7.64236558394111, 'learning_rate': 0.3545012597743415}}\n",
    "# Best RMSEs for each cluster: {5: 1.0009132591349195, 7: 1.0188319686406953, 8: 0.9991016563528642}\n",
    "\n",
    "# Best Parameters for each cluster: {5: {'depth': 2.260149256878929, 'l2_leaf_reg': 1.771921285491023, 'learning_rate': 0.7469798363027962}, \n",
    "#                                    ***7: {'depth': 6.336524926677278, 'l2_leaf_reg': 17.81766138426488, 'learning_rate': 0.8294239282966256},\n",
    "#                                    8: {'depth': 3.3769352821951455, 'l2_leaf_reg': 7.652216726613778, 'learning_rate': 0.26090859187150245}}\n",
    "# Best RMSEs for each cluster: {5: 1.009668889015085, 7: 1.016489858960287, 8: 1.0000324480217584}\n",
    "\n",
    "\n",
    "# {5: 1.0165864148856156, 7: 1.018870661936267, 8: 1.0012668953921562}\n",
    "# {5: {'depth': 3.8631427835104324, 'l2_leaf_reg': 1.080469117124645, 'learning_rate': 0.8920618912033068}, \n",
    "#  7: {'depth': 6.459387391131091, 'l2_leaf_reg': 17.52155119655796, 'learning_rate': 0.7785244285710464}, \n",
    "#  8: {'depth': 3.219613498858582, 'l2_leaf_reg': 6.9542411087094465, 'learning_rate': 0.39832986606754484}}\n",
    "\n",
    "\n",
    "# Best parameters for Cluster 8: {'depth': 3.1197656703616117, 'l2_leaf_reg': 8.096715894710567, 'learning_rate': 0.2589612531162498}\n",
    "# Best RMSE for Cluster 8: 1.0001124660202096\n",
    "\n",
    "# Best parameters for Cluster 7: {'depth': 6.579716021009375, 'l2_leaf_reg': 7.396807489755532, 'learning_rate': 0.28058104702652625}\n",
    "# Best RMSE for Cluster 7: 1.0270522194225222\n",
    "\n",
    "# Best parameters for Cluster 5: {'depth': 3.503385081458421, 'l2_leaf_reg': 2.404965197063553, 'learning_rate': 0.20647001835054793}\n",
    "# Best RMSE for Cluster 5: 1.0216433481698786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9def989a-1a24-47cc-84e2-612735493093",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0846155607336996\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import VotingRegressor\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# estimators = [\n",
    "#     ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "#     ('lr', LinearRegression()),\n",
    "#     ('dt', DecisionTreeRegressor())\n",
    "# ]\n",
    "\n",
    "# voting = VotingRegressor(estimators=estimators)\n",
    "# voting.fit(X_train, y_train)\n",
    "# predictions = voting.predict(X_val)\n",
    "# rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# poly = PolynomialFeatures(degree=2)\n",
    "# X_train_poly = poly.fit_transform(X_train)\n",
    "# X_val_poly = poly.transform(X_val)\n",
    "\n",
    "# model.fit(X_train_poly, y_train)\n",
    "# predictions = model.predict(X_val_poly)\n",
    "# rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "# print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28176545-e610-4713-ad1a-e9cd2aecefc2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for Cluster 7\n",
      "|   iter    |  target   |   depth   | l2_lea... | learni... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-1.078   \u001b[0m | \u001b[0m6.247    \u001b[0m | \u001b[0m14.51    \u001b[0m | \u001b[0m0.1843   \u001b[0m | \u001b[0m638.8    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-1.037   \u001b[0m | \u001b[95m4.936    \u001b[0m | \u001b[95m6.56     \u001b[0m | \u001b[95m0.01923  \u001b[0m | \u001b[95m879.6    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-1.039   \u001b[0m | \u001b[0m7.607    \u001b[0m | \u001b[0m12.08    \u001b[0m | \u001b[0m0.01004  \u001b[0m | \u001b[0m972.9    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-1.038   \u001b[0m | \u001b[0m8.995    \u001b[0m | \u001b[0m7.123    \u001b[0m | \u001b[0m0.04955  \u001b[0m | \u001b[0m265.1    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-1.05    \u001b[0m | \u001b[0m5.825    \u001b[0m | \u001b[0m10.25    \u001b[0m | \u001b[0m0.1108   \u001b[0m | \u001b[0m362.1    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-1.054   \u001b[0m | \u001b[0m7.671    \u001b[0m | \u001b[0m6.395    \u001b[0m | \u001b[0m0.07658  \u001b[0m | \u001b[0m429.7    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-1.042   \u001b[0m | \u001b[0m6.736    \u001b[0m | \u001b[0m12.85    \u001b[0m | \u001b[0m0.05392  \u001b[0m | \u001b[0m562.8    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-1.061   \u001b[0m | \u001b[0m7.554    \u001b[0m | \u001b[0m5.465    \u001b[0m | \u001b[0m0.1538   \u001b[0m | \u001b[0m253.5    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-1.08    \u001b[0m | \u001b[0m4.39     \u001b[0m | \u001b[0m14.49    \u001b[0m | \u001b[0m0.2416   \u001b[0m | \u001b[0m827.6    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-1.073   \u001b[0m | \u001b[0m5.828    \u001b[0m | \u001b[0m5.977    \u001b[0m | \u001b[0m0.1726   \u001b[0m | \u001b[0m496.1    \u001b[0m |\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m-1.036   \u001b[0m | \u001b[95m4.732    \u001b[0m | \u001b[95m9.952    \u001b[0m | \u001b[95m0.01343  \u001b[0m | \u001b[95m918.4    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-1.048   \u001b[0m | \u001b[0m5.553    \u001b[0m | \u001b[0m11.63    \u001b[0m | \u001b[0m0.08137  \u001b[0m | \u001b[0m568.1    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-1.125   \u001b[0m | \u001b[0m7.28     \u001b[0m | \u001b[0m6.849    \u001b[0m | \u001b[0m0.2425   \u001b[0m | \u001b[0m797.6    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-1.099   \u001b[0m | \u001b[0m9.637    \u001b[0m | \u001b[0m13.95    \u001b[0m | \u001b[0m0.1515   \u001b[0m | \u001b[0m929.7    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-1.038   \u001b[0m | \u001b[0m4.531    \u001b[0m | \u001b[0m6.96     \u001b[0m | \u001b[0m0.01608  \u001b[0m | \u001b[0m392.8    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-1.087   \u001b[0m | \u001b[0m4.454    \u001b[0m | \u001b[0m8.878    \u001b[0m | \u001b[0m0.2019   \u001b[0m | \u001b[0m911.6    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-1.04    \u001b[0m | \u001b[0m4.502    \u001b[0m | \u001b[0m9.023    \u001b[0m | \u001b[0m0.03175  \u001b[0m | \u001b[0m920.9    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-1.084   \u001b[0m | \u001b[0m4.324    \u001b[0m | \u001b[0m12.36    \u001b[0m | \u001b[0m0.1747   \u001b[0m | \u001b[0m880.0    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-1.114   \u001b[0m | \u001b[0m7.418    \u001b[0m | \u001b[0m5.013    \u001b[0m | \u001b[0m0.1597   \u001b[0m | \u001b[0m877.5    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-1.041   \u001b[0m | \u001b[0m4.9      \u001b[0m | \u001b[0m10.14    \u001b[0m | \u001b[0m0.02791  \u001b[0m | \u001b[0m920.0    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-1.039   \u001b[0m | \u001b[0m5.38     \u001b[0m | \u001b[0m6.623    \u001b[0m | \u001b[0m0.02455  \u001b[0m | \u001b[0m881.9    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-1.078   \u001b[0m | \u001b[0m6.978    \u001b[0m | \u001b[0m7.246    \u001b[0m | \u001b[0m0.1181   \u001b[0m | \u001b[0m919.1    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-1.049   \u001b[0m | \u001b[0m4.625    \u001b[0m | \u001b[0m9.193    \u001b[0m | \u001b[0m0.1086   \u001b[0m | \u001b[0m394.2    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-1.06    \u001b[0m | \u001b[0m4.972    \u001b[0m | \u001b[0m13.9     \u001b[0m | \u001b[0m0.1692   \u001b[0m | \u001b[0m565.3    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-1.038   \u001b[0m | \u001b[0m6.418    \u001b[0m | \u001b[0m8.178    \u001b[0m | \u001b[0m0.03307  \u001b[0m | \u001b[0m391.1    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-1.051   \u001b[0m | \u001b[0m8.794    \u001b[0m | \u001b[0m6.155    \u001b[0m | \u001b[0m0.06958  \u001b[0m | \u001b[0m392.6    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-1.047   \u001b[0m | \u001b[0m4.385    \u001b[0m | \u001b[0m5.099    \u001b[0m | \u001b[0m0.1012   \u001b[0m | \u001b[0m390.7    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-1.058   \u001b[0m | \u001b[0m4.627    \u001b[0m | \u001b[0m13.06    \u001b[0m | \u001b[0m0.1284   \u001b[0m | \u001b[0m917.5    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-1.067   \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m9.228    \u001b[0m | \u001b[0m0.25     \u001b[0m | \u001b[0m389.8    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-1.057   \u001b[0m | \u001b[0m6.439    \u001b[0m | \u001b[0m6.642    \u001b[0m | \u001b[0m0.1602   \u001b[0m | \u001b[0m267.2    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-1.049   \u001b[0m | \u001b[0m7.971    \u001b[0m | \u001b[0m10.28    \u001b[0m | \u001b[0m0.005    \u001b[0m | \u001b[0m564.5    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-1.07    \u001b[0m | \u001b[0m9.121    \u001b[0m | \u001b[0m5.8      \u001b[0m | \u001b[0m0.178    \u001b[0m | \u001b[0m262.3    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-1.083   \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m9.259    \u001b[0m | \u001b[0m0.005    \u001b[0m | \u001b[0m266.5    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-1.038   \u001b[0m | \u001b[0m6.9      \u001b[0m | \u001b[0m8.372    \u001b[0m | \u001b[0m0.04129  \u001b[0m | \u001b[0m393.7    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-1.049   \u001b[0m | \u001b[0m8.619    \u001b[0m | \u001b[0m10.34    \u001b[0m | \u001b[0m0.0852   \u001b[0m | \u001b[0m391.9    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-1.039   \u001b[0m | \u001b[0m5.403    \u001b[0m | \u001b[0m5.646    \u001b[0m | \u001b[0m0.0133   \u001b[0m | \u001b[0m395.4    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-1.115   \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.25     \u001b[0m | \u001b[0m881.0    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-1.046   \u001b[0m | \u001b[0m5.453    \u001b[0m | \u001b[0m7.578    \u001b[0m | \u001b[0m0.1161   \u001b[0m | \u001b[0m394.9    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-1.042   \u001b[0m | \u001b[0m6.294    \u001b[0m | \u001b[0m7.08     \u001b[0m | \u001b[0m0.04928  \u001b[0m | \u001b[0m392.6    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-1.075   \u001b[0m | \u001b[0m6.232    \u001b[0m | \u001b[0m7.142    \u001b[0m | \u001b[0m0.1051   \u001b[0m | \u001b[0m879.9    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-1.096   \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m10.9     \u001b[0m | \u001b[0m0.25     \u001b[0m | \u001b[0m919.0    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-1.045   \u001b[0m | \u001b[0m4.955    \u001b[0m | \u001b[0m10.4     \u001b[0m | \u001b[0m0.08222  \u001b[0m | \u001b[0m649.6    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-1.064   \u001b[0m | \u001b[0m4.558    \u001b[0m | \u001b[0m12.51    \u001b[0m | \u001b[0m0.1658   \u001b[0m | \u001b[0m859.8    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-1.053   \u001b[0m | \u001b[0m8.298    \u001b[0m | \u001b[0m5.525    \u001b[0m | \u001b[0m0.1212   \u001b[0m | \u001b[0m258.2    \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-1.039   \u001b[0m | \u001b[0m9.012    \u001b[0m | \u001b[0m7.07     \u001b[0m | \u001b[0m0.0446   \u001b[0m | \u001b[0m264.8    \u001b[0m |\n",
      "=========================================================================\n",
      "Best parameters for Cluster 7: {'depth': 4.7322294090686725, 'l2_leaf_reg': 9.951769101112703, 'learning_rate': 0.013425187673228506, 'n_estimators': 918.3883618709039}\n",
      "Best RMSE for Cluster 7: 1.0364747689027016\n",
      "Optimizing for Cluster 6\n",
      "|   iter    |  target   |   depth   | l2_lea... | learni... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-0.9297  \u001b[0m | \u001b[0m6.247    \u001b[0m | \u001b[0m14.51    \u001b[0m | \u001b[0m0.1843   \u001b[0m | \u001b[0m638.8    \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 遍历指定的Clusters\n",
    "for cluster in [7, 6, 8, 1, 5]:\n",
    "    print(f\"Optimizing for Cluster {cluster}\")\n",
    "    # 准备数据\n",
    "    train_cluster_data = train_df[train_df['Cluster'] == cluster]\n",
    "    X_train = train_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y_train = train_cluster_data['stars']\n",
    "    \n",
    "    test_cluster_data = test_df[test_df['Cluster'] == cluster]\n",
    "    X_test = test_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y_test = test_cluster_data['stars']\n",
    "    \n",
    "    # 定义目标函数\n",
    "    def cb_cv(depth, learning_rate, n_estimators, l2_leaf_reg):\n",
    "        depth = int(depth)\n",
    "        n_estimators = int(n_estimators)\n",
    "        estimator = CatBoostRegressor(\n",
    "            depth=depth,\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "            l2_leaf_reg=l2_leaf_reg,\n",
    "            random_seed=42,\n",
    "            verbose=False\n",
    "        )\n",
    "        estimator.fit(X_train, y_train)\n",
    "        preds = estimator.predict(X_test)\n",
    "        return -np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "    # 设置参数搜索空间\n",
    "    pbounds = {\n",
    "        'depth': (4, 10),\n",
    "        'learning_rate': (0.005, 0.25),\n",
    "        'n_estimators': (100, 1000),\n",
    "        'l2_leaf_reg': (5, 15)\n",
    "    }\n",
    "\n",
    "    # pbounds = {\n",
    "    #     'depth': (int(best_params[cluster]['depth']) - 1, int(best_params[cluster]['depth']) + 1),\n",
    "    #     'learning_rate': (max(0.01, best_params[cluster]['learning_rate'] - 0.005), best_params[cluster]['learning_rate'] + 0.005),\n",
    "    #     'n_estimators': (max(100, int(best_params[cluster]['n_estimators']) - 50), int(best_params[cluster]['n_estimators']) + 50),\n",
    "    #     'l2_leaf_reg': (max(1, best_params[cluster]['l2_leaf_reg'] - 1), best_params[cluster]['l2_leaf_reg'] + 1)\n",
    "    # }\n",
    "\n",
    "\n",
    "    # 使用贝叶斯优化\n",
    "    optimizer = BayesianOptimization(f=cb_cv, pbounds=pbounds, random_state=42, verbose=2)\n",
    "    optimizer.maximize(init_points=15, n_iter=30)  # 增加初始化点和迭代次数\n",
    "\n",
    "    # 保存最佳参数和对应的RMSE\n",
    "    best_params[cluster] = optimizer.max['params']\n",
    "    best_rmses[cluster] = -optimizer.max['target']\n",
    "\n",
    "    print(f\"Best parameters for Cluster {cluster}: {best_params[cluster]}\")\n",
    "    print(f\"Best RMSE for Cluster {cluster}: {best_rmses[cluster]}\")\n",
    "\n",
    "# 输出所有最佳参数和RMSE\n",
    "print(\"Best Parameters for each cluster:\", best_params)\n",
    "print(\"Best RMSEs for each cluster:\", best_rmses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f9ac1-52db-40a3-bfb3-77068a624cec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "RMSE Scores by Cluster: 1: 0.9486380392367105, 5: 1.0693467025903196, 6: 0.9071186256407098, 7: 1.042741917361027, 8: 1.039941487282683}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd90e5-5886-44de-9865-137ab91f875a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Best Parameters for each cluster: {7: {'depth': 5.233959253839706, 'l2_leaf_reg': 5.531793633070324, 'learning_rate': 0.022523592873744964, 'n_estimators': 895.3299321377824}, \n",
    "                                   6: {'depth': 8.56956279182458, 'l2_leaf_reg': 7.727827495157177, 'learning_rate': 0.018229238234732596, 'n_estimators': 462.46324152466224}, \n",
    "                                   8: {'depth': 5.994933768167258, 'l2_leaf_reg': 5.186746727672216, 'learning_rate': 0.02510956175893532, 'n_estimators': 362.65732003713}, \n",
    "                                   1: {'depth': 6.031006169303008, 'l2_leaf_reg': 9.729298920378694, 'learning_rate': 0.012723862553242364, 'n_estimators': 162.51483915965784}, \n",
    "                                   5: {'depth': 6.031006169303008, 'l2_leaf_reg': 9.729298920378694, 'learning_rate': 0.012723862553242364, 'n_estimators': 162.51483915965784}}\n",
    "Best RMSEs for each cluster: {7: 1.0374946293262677, 6: 0.8875830102874258, 8: 1.01610383204095, 1: 0.9179302653164916, 5: 1.049184245822053}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2dd4f3-6514-4da7-8f70-694dfaddfac3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### WORST: 8 re-model\n",
    "\n",
    "> Best parameters for Cluster 8: {'depth': 6.352673798460998, 'l2_leaf_reg': 7.564480551391564, 'learning_rate': 0.1775612544990892, 'n_estimators': 638.3900345249591}\n",
    "Best RMSE for Cluster 8: 0.3849426727018452\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2513ba50-73b0-4b2a-8145-5252676b3878",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   depth   | l2_lea... | learni... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-1.08    \u001b[0m | \u001b[0m9.371    \u001b[0m | \u001b[0m9.803    \u001b[0m | \u001b[0m0.2652   \u001b[0m | \u001b[0m779.6    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-1.076   \u001b[0m | \u001b[95m7.404    \u001b[0m | \u001b[95m6.624    \u001b[0m | \u001b[95m0.1776   \u001b[0m | \u001b[95m859.9    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-1.06    \u001b[0m | \u001b[95m11.41    \u001b[0m | \u001b[95m8.832    \u001b[0m | \u001b[95m0.1727   \u001b[0m | \u001b[95m891.0    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-1.071   \u001b[0m | \u001b[0m13.49    \u001b[0m | \u001b[0m6.849    \u001b[0m | \u001b[0m0.1936   \u001b[0m | \u001b[0m655.0    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-1.066   \u001b[0m | \u001b[0m8.738    \u001b[0m | \u001b[0m8.099    \u001b[0m | \u001b[0m0.2262   \u001b[0m | \u001b[0m687.4    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-1.069   \u001b[0m | \u001b[0m12.36    \u001b[0m | \u001b[0m8.929    \u001b[0m | \u001b[0m0.209    \u001b[0m | \u001b[0m890.4    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-1.063   \u001b[0m | \u001b[0m10.64    \u001b[0m | \u001b[0m9.268    \u001b[0m | \u001b[0m0.2448   \u001b[0m | \u001b[0m891.0    \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m-1.055   \u001b[0m | \u001b[95m11.07    \u001b[0m | \u001b[95m8.206    \u001b[0m | \u001b[95m0.17     \u001b[0m | \u001b[95m891.6    \u001b[0m |\n",
      "| \u001b[95m9        \u001b[0m | \u001b[95m-1.051   \u001b[0m | \u001b[95m10.44    \u001b[0m | \u001b[95m7.285    \u001b[0m | \u001b[95m0.19     \u001b[0m | \u001b[95m890.9    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-1.083   \u001b[0m | \u001b[0m11.13    \u001b[0m | \u001b[0m6.36     \u001b[0m | \u001b[0m0.2904   \u001b[0m | \u001b[0m892.1    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-1.059   \u001b[0m | \u001b[0m10.64    \u001b[0m | \u001b[0m7.172    \u001b[0m | \u001b[0m0.2105   \u001b[0m | \u001b[0m890.3    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-1.056   \u001b[0m | \u001b[0m10.03    \u001b[0m | \u001b[0m7.994    \u001b[0m | \u001b[0m0.17     \u001b[0m | \u001b[0m891.0    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-1.089   \u001b[0m | \u001b[0m8.873    \u001b[0m | \u001b[0m7.369    \u001b[0m | \u001b[0m0.2185   \u001b[0m | \u001b[0m891.0    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-1.078   \u001b[0m | \u001b[0m11.06    \u001b[0m | \u001b[0m8.582    \u001b[0m | \u001b[0m0.2582   \u001b[0m | \u001b[0m889.9    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-1.057   \u001b[0m | \u001b[0m11.21    \u001b[0m | \u001b[0m7.059    \u001b[0m | \u001b[0m0.2608   \u001b[0m | \u001b[0m891.0    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-1.066   \u001b[0m | \u001b[0m10.56    \u001b[0m | \u001b[0m7.82     \u001b[0m | \u001b[0m0.1842   \u001b[0m | \u001b[0m891.2    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-1.053   \u001b[0m | \u001b[0m7.856    \u001b[0m | \u001b[0m9.88     \u001b[0m | \u001b[0m0.1719   \u001b[0m | \u001b[0m620.8    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-1.073   \u001b[0m | \u001b[0m10.04    \u001b[0m | \u001b[0m6.352    \u001b[0m | \u001b[0m0.1767   \u001b[0m | \u001b[0m851.1    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-1.069   \u001b[0m | \u001b[0m11.52    \u001b[0m | \u001b[0m8.367    \u001b[0m | \u001b[0m0.2161   \u001b[0m | \u001b[0m891.8    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-1.078   \u001b[0m | \u001b[0m9.281    \u001b[0m | \u001b[0m7.147    \u001b[0m | \u001b[0m0.26     \u001b[0m | \u001b[0m800.2    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-1.055   \u001b[0m | \u001b[0m14.88    \u001b[0m | \u001b[0m8.42     \u001b[0m | \u001b[0m0.2871   \u001b[0m | \u001b[0m827.1    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-1.062   \u001b[0m | \u001b[0m12.43    \u001b[0m | \u001b[0m8.99     \u001b[0m | \u001b[0m0.1756   \u001b[0m | \u001b[0m720.8    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-1.072   \u001b[0m | \u001b[0m13.61    \u001b[0m | \u001b[0m8.872    \u001b[0m | \u001b[0m0.2084   \u001b[0m | \u001b[0m762.2    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-1.069   \u001b[0m | \u001b[0m10.1     \u001b[0m | \u001b[0m6.85     \u001b[0m | \u001b[0m0.2671   \u001b[0m | \u001b[0m890.4    \u001b[0m |\n",
      "| \u001b[95m25       \u001b[0m | \u001b[95m-1.051   \u001b[0m | \u001b[95m11.41    \u001b[0m | \u001b[95m8.3      \u001b[0m | \u001b[95m0.1722   \u001b[0m | \u001b[95m891.1    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-1.061   \u001b[0m | \u001b[0m10.41    \u001b[0m | \u001b[0m7.497    \u001b[0m | \u001b[0m0.2806   \u001b[0m | \u001b[0m890.6    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-1.105   \u001b[0m | \u001b[0m6.526    \u001b[0m | \u001b[0m6.515    \u001b[0m | \u001b[0m0.2416   \u001b[0m | \u001b[0m860.9    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-1.068   \u001b[0m | \u001b[0m14.53    \u001b[0m | \u001b[0m8.415    \u001b[0m | \u001b[0m0.1919   \u001b[0m | \u001b[0m732.1    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-1.089   \u001b[0m | \u001b[0m7.339    \u001b[0m | \u001b[0m9.768    \u001b[0m | \u001b[0m0.2396   \u001b[0m | \u001b[0m785.2    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-1.121   \u001b[0m | \u001b[0m6.553    \u001b[0m | \u001b[0m8.064    \u001b[0m | \u001b[0m0.2255   \u001b[0m | \u001b[0m885.9    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-1.075   \u001b[0m | \u001b[0m9.912    \u001b[0m | \u001b[0m6.877    \u001b[0m | \u001b[0m0.2209   \u001b[0m | \u001b[0m890.4    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-1.061   \u001b[0m | \u001b[0m7.784    \u001b[0m | \u001b[0m9.131    \u001b[0m | \u001b[0m0.1879   \u001b[0m | \u001b[0m621.5    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-1.075   \u001b[0m | \u001b[0m8.322    \u001b[0m | \u001b[0m9.861    \u001b[0m | \u001b[0m0.2089   \u001b[0m | \u001b[0m620.0    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-1.076   \u001b[0m | \u001b[0m12.45    \u001b[0m | \u001b[0m6.21     \u001b[0m | \u001b[0m0.2317   \u001b[0m | \u001b[0m652.7    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-1.064   \u001b[0m | \u001b[0m6.953    \u001b[0m | \u001b[0m9.671    \u001b[0m | \u001b[0m0.25     \u001b[0m | \u001b[0m620.5    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-1.08    \u001b[0m | \u001b[0m13.54    \u001b[0m | \u001b[0m7.176    \u001b[0m | \u001b[0m0.2851   \u001b[0m | \u001b[0m807.1    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-1.054   \u001b[0m | \u001b[0m13.46    \u001b[0m | \u001b[0m6.449    \u001b[0m | \u001b[0m0.1973   \u001b[0m | \u001b[0m857.3    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-1.077   \u001b[0m | \u001b[0m11.4     \u001b[0m | \u001b[0m6.695    \u001b[0m | \u001b[0m0.2446   \u001b[0m | \u001b[0m835.5    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-1.07    \u001b[0m | \u001b[0m13.18    \u001b[0m | \u001b[0m6.031    \u001b[0m | \u001b[0m0.1788   \u001b[0m | \u001b[0m870.0    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-1.061   \u001b[0m | \u001b[0m13.68    \u001b[0m | \u001b[0m6.4      \u001b[0m | \u001b[0m0.1944   \u001b[0m | \u001b[0m858.0    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-1.084   \u001b[0m | \u001b[0m11.56    \u001b[0m | \u001b[0m9.092    \u001b[0m | \u001b[0m0.2812   \u001b[0m | \u001b[0m730.8    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-1.08    \u001b[0m | \u001b[0m14.43    \u001b[0m | \u001b[0m6.54     \u001b[0m | \u001b[0m0.2737   \u001b[0m | \u001b[0m857.2    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-1.06    \u001b[0m | \u001b[0m12.92    \u001b[0m | \u001b[0m7.114    \u001b[0m | \u001b[0m0.194    \u001b[0m | \u001b[0m857.5    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-1.072   \u001b[0m | \u001b[0m11.77    \u001b[0m | \u001b[0m7.822    \u001b[0m | \u001b[0m0.2696   \u001b[0m | \u001b[0m843.2    \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-1.071   \u001b[0m | \u001b[0m8.018    \u001b[0m | \u001b[0m9.229    \u001b[0m | \u001b[0m0.2128   \u001b[0m | \u001b[0m664.2    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-1.068   \u001b[0m | \u001b[0m7.045    \u001b[0m | \u001b[0m9.489    \u001b[0m | \u001b[0m0.1902   \u001b[0m | \u001b[0m629.5    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-1.058   \u001b[0m | \u001b[0m12.61    \u001b[0m | \u001b[0m6.041    \u001b[0m | \u001b[0m0.2582   \u001b[0m | \u001b[0m857.8    \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-1.065   \u001b[0m | \u001b[0m12.39    \u001b[0m | \u001b[0m6.266    \u001b[0m | \u001b[0m0.2236   \u001b[0m | \u001b[0m856.9    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-1.066   \u001b[0m | \u001b[0m12.36    \u001b[0m | \u001b[0m6.423    \u001b[0m | \u001b[0m0.1867   \u001b[0m | \u001b[0m676.4    \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-1.099   \u001b[0m | \u001b[0m7.384    \u001b[0m | \u001b[0m9.95     \u001b[0m | \u001b[0m0.2703   \u001b[0m | \u001b[0m621.5    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-1.065   \u001b[0m | \u001b[0m9.513    \u001b[0m | \u001b[0m9.375    \u001b[0m | \u001b[0m0.2627   \u001b[0m | \u001b[0m720.7    \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-1.067   \u001b[0m | \u001b[0m11.85    \u001b[0m | \u001b[0m9.168    \u001b[0m | \u001b[0m0.254    \u001b[0m | \u001b[0m876.0    \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-1.07    \u001b[0m | \u001b[0m11.86    \u001b[0m | \u001b[0m7.587    \u001b[0m | \u001b[0m0.2935   \u001b[0m | \u001b[0m891.0    \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-1.082   \u001b[0m | \u001b[0m8.921    \u001b[0m | \u001b[0m7.432    \u001b[0m | \u001b[0m0.2823   \u001b[0m | \u001b[0m703.6    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-1.072   \u001b[0m | \u001b[0m8.274    \u001b[0m | \u001b[0m8.381    \u001b[0m | \u001b[0m0.2862   \u001b[0m | \u001b[0m715.8    \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m-1.081   \u001b[0m | \u001b[0m10.05    \u001b[0m | \u001b[0m8.32     \u001b[0m | \u001b[0m0.2391   \u001b[0m | \u001b[0m820.6    \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m-1.085   \u001b[0m | \u001b[0m7.743    \u001b[0m | \u001b[0m9.344    \u001b[0m | \u001b[0m0.2306   \u001b[0m | \u001b[0m620.9    \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m-1.071   \u001b[0m | \u001b[0m9.465    \u001b[0m | \u001b[0m7.22     \u001b[0m | \u001b[0m0.2444   \u001b[0m | \u001b[0m662.3    \u001b[0m |\n",
      "| \u001b[95m59       \u001b[0m | \u001b[95m-1.047   \u001b[0m | \u001b[95m10.58    \u001b[0m | \u001b[95m6.856    \u001b[0m | \u001b[95m0.1811   \u001b[0m | \u001b[95m891.0    \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-1.068   \u001b[0m | \u001b[0m11.09    \u001b[0m | \u001b[0m7.481    \u001b[0m | \u001b[0m0.289    \u001b[0m | \u001b[0m890.8    \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-1.075   \u001b[0m | \u001b[0m7.265    \u001b[0m | \u001b[0m6.269    \u001b[0m | \u001b[0m0.1857   \u001b[0m | \u001b[0m824.3    \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-1.07    \u001b[0m | \u001b[0m14.75    \u001b[0m | \u001b[0m6.922    \u001b[0m | \u001b[0m0.1849   \u001b[0m | \u001b[0m729.1    \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-1.064   \u001b[0m | \u001b[0m13.39    \u001b[0m | \u001b[0m9.263    \u001b[0m | \u001b[0m0.2798   \u001b[0m | \u001b[0m888.9    \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-1.071   \u001b[0m | \u001b[0m11.52    \u001b[0m | \u001b[0m8.287    \u001b[0m | \u001b[0m0.22     \u001b[0m | \u001b[0m705.6    \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-1.073   \u001b[0m | \u001b[0m13.81    \u001b[0m | \u001b[0m9.727    \u001b[0m | \u001b[0m0.2424   \u001b[0m | \u001b[0m764.5    \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-1.074   \u001b[0m | \u001b[0m10.74    \u001b[0m | \u001b[0m7.236    \u001b[0m | \u001b[0m0.2505   \u001b[0m | \u001b[0m891.1    \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-1.074   \u001b[0m | \u001b[0m14.96    \u001b[0m | \u001b[0m6.59     \u001b[0m | \u001b[0m0.2283   \u001b[0m | \u001b[0m638.5    \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-1.063   \u001b[0m | \u001b[0m12.94    \u001b[0m | \u001b[0m6.863    \u001b[0m | \u001b[0m0.2621   \u001b[0m | \u001b[0m601.4    \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m-1.083   \u001b[0m | \u001b[0m9.877    \u001b[0m | \u001b[0m9.068    \u001b[0m | \u001b[0m0.2823   \u001b[0m | \u001b[0m696.6    \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-1.068   \u001b[0m | \u001b[0m10.18    \u001b[0m | \u001b[0m7.082    \u001b[0m | \u001b[0m0.2466   \u001b[0m | \u001b[0m890.7    \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-1.083   \u001b[0m | \u001b[0m7.664    \u001b[0m | \u001b[0m7.713    \u001b[0m | \u001b[0m0.2898   \u001b[0m | \u001b[0m713.2    \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m-1.076   \u001b[0m | \u001b[0m9.137    \u001b[0m | \u001b[0m6.284    \u001b[0m | \u001b[0m0.2974   \u001b[0m | \u001b[0m768.6    \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-1.06    \u001b[0m | \u001b[0m8.336    \u001b[0m | \u001b[0m9.183    \u001b[0m | \u001b[0m0.2233   \u001b[0m | \u001b[0m614.9    \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-1.08    \u001b[0m | \u001b[0m13.65    \u001b[0m | \u001b[0m6.199    \u001b[0m | \u001b[0m0.2601   \u001b[0m | \u001b[0m857.4    \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m-1.083   \u001b[0m | \u001b[0m14.24    \u001b[0m | \u001b[0m7.009    \u001b[0m | \u001b[0m0.2501   \u001b[0m | \u001b[0m656.5    \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-1.098   \u001b[0m | \u001b[0m7.341    \u001b[0m | \u001b[0m7.296    \u001b[0m | \u001b[0m0.2494   \u001b[0m | \u001b[0m782.8    \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-1.052   \u001b[0m | \u001b[0m10.54    \u001b[0m | \u001b[0m9.183    \u001b[0m | \u001b[0m0.2496   \u001b[0m | \u001b[0m768.1    \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-1.074   \u001b[0m | \u001b[0m10.87    \u001b[0m | \u001b[0m8.206    \u001b[0m | \u001b[0m0.2771   \u001b[0m | \u001b[0m891.5    \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m-1.07    \u001b[0m | \u001b[0m12.2     \u001b[0m | \u001b[0m8.414    \u001b[0m | \u001b[0m0.2568   \u001b[0m | \u001b[0m774.7    \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m-1.064   \u001b[0m | \u001b[0m14.07    \u001b[0m | \u001b[0m7.206    \u001b[0m | \u001b[0m0.1914   \u001b[0m | \u001b[0m730.4    \u001b[0m |\n",
      "| \u001b[0m81       \u001b[0m | \u001b[0m-1.088   \u001b[0m | \u001b[0m10.88    \u001b[0m | \u001b[0m7.838    \u001b[0m | \u001b[0m0.2677   \u001b[0m | \u001b[0m658.6    \u001b[0m |\n",
      "| \u001b[0m82       \u001b[0m | \u001b[0m-1.065   \u001b[0m | \u001b[0m13.18    \u001b[0m | \u001b[0m9.949    \u001b[0m | \u001b[0m0.2495   \u001b[0m | \u001b[0m745.5    \u001b[0m |\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m-1.072   \u001b[0m | \u001b[0m6.498    \u001b[0m | \u001b[0m8.138    \u001b[0m | \u001b[0m0.2148   \u001b[0m | \u001b[0m679.7    \u001b[0m |\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m-1.066   \u001b[0m | \u001b[0m13.39    \u001b[0m | \u001b[0m7.877    \u001b[0m | \u001b[0m0.295    \u001b[0m | \u001b[0m747.9    \u001b[0m |\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m-1.057   \u001b[0m | \u001b[0m11.69    \u001b[0m | \u001b[0m6.221    \u001b[0m | \u001b[0m0.1779   \u001b[0m | \u001b[0m689.1    \u001b[0m |\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m-1.063   \u001b[0m | \u001b[0m13.56    \u001b[0m | \u001b[0m8.56     \u001b[0m | \u001b[0m0.2205   \u001b[0m | \u001b[0m691.2    \u001b[0m |\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m-1.072   \u001b[0m | \u001b[0m11.84    \u001b[0m | \u001b[0m9.691    \u001b[0m | \u001b[0m0.2243   \u001b[0m | \u001b[0m631.6    \u001b[0m |\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m-1.061   \u001b[0m | \u001b[0m10.18    \u001b[0m | \u001b[0m8.726    \u001b[0m | \u001b[0m0.1762   \u001b[0m | \u001b[0m638.9    \u001b[0m |\n",
      "| \u001b[0m89       \u001b[0m | \u001b[0m-1.074   \u001b[0m | \u001b[0m7.879    \u001b[0m | \u001b[0m6.884    \u001b[0m | \u001b[0m0.1723   \u001b[0m | \u001b[0m784.0    \u001b[0m |\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m-1.061   \u001b[0m | \u001b[0m9.136    \u001b[0m | \u001b[0m7.106    \u001b[0m | \u001b[0m0.1777   \u001b[0m | \u001b[0m863.9    \u001b[0m |\n",
      "| \u001b[0m91       \u001b[0m | \u001b[0m-1.102   \u001b[0m | \u001b[0m8.557    \u001b[0m | \u001b[0m6.196    \u001b[0m | \u001b[0m0.2929   \u001b[0m | \u001b[0m716.8    \u001b[0m |\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m-1.071   \u001b[0m | \u001b[0m9.836    \u001b[0m | \u001b[0m8.528    \u001b[0m | \u001b[0m0.2945   \u001b[0m | \u001b[0m623.9    \u001b[0m |\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m-1.08    \u001b[0m | \u001b[0m8.267    \u001b[0m | \u001b[0m9.91     \u001b[0m | \u001b[0m0.2392   \u001b[0m | \u001b[0m796.6    \u001b[0m |\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m-1.065   \u001b[0m | \u001b[0m13.34    \u001b[0m | \u001b[0m7.748    \u001b[0m | \u001b[0m0.2721   \u001b[0m | \u001b[0m807.7    \u001b[0m |\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m-1.072   \u001b[0m | \u001b[0m13.73    \u001b[0m | \u001b[0m6.314    \u001b[0m | \u001b[0m0.2422   \u001b[0m | \u001b[0m717.9    \u001b[0m |\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m-1.081   \u001b[0m | \u001b[0m11.2     \u001b[0m | \u001b[0m8.929    \u001b[0m | \u001b[0m0.2812   \u001b[0m | \u001b[0m607.9    \u001b[0m |\n",
      "| \u001b[0m97       \u001b[0m | \u001b[0m-1.078   \u001b[0m | \u001b[0m9.542    \u001b[0m | \u001b[0m9.411    \u001b[0m | \u001b[0m0.2055   \u001b[0m | \u001b[0m866.4    \u001b[0m |\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m-1.076   \u001b[0m | \u001b[0m8.344    \u001b[0m | \u001b[0m6.666    \u001b[0m | \u001b[0m0.2593   \u001b[0m | \u001b[0m638.9    \u001b[0m |\n",
      "| \u001b[0m99       \u001b[0m | \u001b[0m-1.089   \u001b[0m | \u001b[0m9.448    \u001b[0m | \u001b[0m9.833    \u001b[0m | \u001b[0m0.2949   \u001b[0m | \u001b[0m759.1    \u001b[0m |\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m-1.082   \u001b[0m | \u001b[0m6.66     \u001b[0m | \u001b[0m9.901    \u001b[0m | \u001b[0m0.2584   \u001b[0m | \u001b[0m780.5    \u001b[0m |\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m-1.089   \u001b[0m | \u001b[0m6.476    \u001b[0m | \u001b[0m8.781    \u001b[0m | \u001b[0m0.2586   \u001b[0m | \u001b[0m897.8    \u001b[0m |\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m-1.076   \u001b[0m | \u001b[0m8.589    \u001b[0m | \u001b[0m8.135    \u001b[0m | \u001b[0m0.2716   \u001b[0m | \u001b[0m684.7    \u001b[0m |\n",
      "| \u001b[0m103      \u001b[0m | \u001b[0m-1.075   \u001b[0m | \u001b[0m12.7     \u001b[0m | \u001b[0m8.086    \u001b[0m | \u001b[0m0.2976   \u001b[0m | \u001b[0m717.3    \u001b[0m |\n",
      "| \u001b[95m104      \u001b[0m | \u001b[95m-1.046   \u001b[0m | \u001b[95m14.9     \u001b[0m | \u001b[95m9.591    \u001b[0m | \u001b[95m0.2479   \u001b[0m | \u001b[95m839.5    \u001b[0m |\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m-1.065   \u001b[0m | \u001b[0m14.54    \u001b[0m | \u001b[0m8.818    \u001b[0m | \u001b[0m0.174    \u001b[0m | \u001b[0m852.9    \u001b[0m |\n",
      "=========================================================================\n",
      "Best parameters: {'depth': 14.900008149596621, 'l2_leaf_reg': 9.590776599097083, 'learning_rate': 0.24794356444236376, 'n_estimators': 839.5132250773224}\n",
      "Final RMSE for Cluster 8: 1.0458446050536865\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 准备Cluster 8的数据\n",
    "data_cluster8 = final_df[final_df['Cluster'] == 8]\n",
    "X = data_cluster8.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "y = data_cluster8['stars']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 目标函数定义\n",
    "def cb_cv(n_estimators, depth, learning_rate, l2_leaf_reg):\n",
    "    depth = int(depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    model = CatBoostRegressor(n_estimators=n_estimators, depth=depth,\n",
    "                              learning_rate=learning_rate, l2_leaf_reg=l2_leaf_reg,\n",
    "                              random_seed=42, verbose=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    return -rmse\n",
    "\n",
    "# 参数搜索空间设置\n",
    "params = {\n",
    "    'n_estimators': (600, 900),\n",
    "    'depth': (6, 15),\n",
    "    'learning_rate': (0.17, 0.30),\n",
    "    'l2_leaf_reg': (6,10)\n",
    "}\n",
    "\n",
    "# 进行Bayesian优化\n",
    "optimizer = BayesianOptimization(f=cb_cv, pbounds=params, random_state=42)\n",
    "optimizer.maximize(init_points=5, n_iter=100)\n",
    "\n",
    "# 输出最优参数\n",
    "print(\"Best parameters:\", optimizer.max['params'])\n",
    "best_params = optimizer.max['params']\n",
    "best_model = CatBoostRegressor(n_estimators=int(best_params['n_estimators']),\n",
    "                               depth=int(best_params['depth']),\n",
    "                               learning_rate=best_params['learning_rate'],\n",
    "                               l2_leaf_reg=best_params['l2_leaf_reg'],\n",
    "                               random_seed=42, verbose=False)\n",
    "best_model.fit(X_train, y_train)\n",
    "best_preds = best_model.predict(X_val)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_val, best_preds))\n",
    "print(\"Final RMSE for Cluster 8:\", final_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd550d6-1267-4065-8112-68234df85db6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ff77b9d-2d60-4285-9047-3942951398c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# best_param_set = best_params[1]\n",
    "# best_param_set['n_estimators'] = round(best_param_set['n_estimators'])\n",
    "# best_param_set['depth'] = round(best_param_set['depth'])\n",
    "\n",
    "# model = CatBoostRegressor(**best_param_set)\n",
    "\n",
    "# # 使用交叉验证来评估模型\n",
    "# scores = cross_val_score(model, X_train, y_train, scoring='neg_root_mean_squared_error', cv=5)\n",
    "# print(\"Cross-validated RMSE scores for Cluster 1:\", -scores)\n",
    "# print(\"Average RMSE:\", -scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acca5bb2-7582-4701-bf79-8230b97f3a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4cc494d3-c97e-4d3e-b892-9940bb07f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 对预测结果进行可视化\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(y_val, y_pred, alpha=0.3)\n",
    "# plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'k--', lw=4)\n",
    "# plt.xlabel('Measured')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.title('Validation Data Predicted vs Actual Values')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b008fe4-e603-48f1-a1a5-bd306349a774",
   "metadata": {},
   "source": [
    "### Small Sample Cluster (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c5202614-9010-49c4-b053-1beb61b12635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 RMSE: 1.3309021302671094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "def prepare_data(df, cluster, drop_columns):\n",
    "    if cluster == -1:\n",
    "        cluster_data = df\n",
    "    else:\n",
    "        cluster_data = df[df['Cluster'] == cluster]\n",
    "\n",
    "    # 确保尝试删除的列存在于DataFrame中，否则忽略\n",
    "    drop_columns = [col for col in drop_columns if col in cluster_data.columns]\n",
    "    X = cluster_data.drop(columns=drop_columns, errors='ignore')\n",
    "    y = cluster_data['stars']\n",
    "    return X, y\n",
    "\n",
    "def train_simple_model(cluster, train_df, test_df):\n",
    "    drop_columns = ['stars', 'user_id', 'business_id']\n",
    "    # 如果score列有NaN值，添加到删除列表\n",
    "    if pd.isnull(train_df['score']).any() or pd.isnull(test_df['score']).any():\n",
    "        drop_columns.append('score')\n",
    "        \n",
    "    X_train, y_train = prepare_data(train_df, cluster, drop_columns)\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.50, random_state=42)\n",
    "    X_test, y_test = prepare_data(test_df, cluster, drop_columns)\n",
    "    \n",
    "    # 使用岭回归并通过交叉验证选择最佳正则化系数\n",
    "    model = RidgeCV(alphas=np.logspace(-6, 6, 13), cv=KFold(5))\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# 计算Cluster 1和6的RMSE\n",
    "rmse_1 = train_simple_model(1, train_df, val_df)\n",
    "print(f\"Cluster 1 RMSE: {rmse_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1cc787ca-c0bc-4ee6-95e3-a288269b29ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.0035938136638046293\n",
      "Best l1_ratio: 0.1\n",
      "Cluster 1 RMSE: 1.3274108290306523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def prepare_data(df, cluster, drop_columns):\n",
    "    if cluster == -1:\n",
    "        cluster_data = df\n",
    "    else:\n",
    "        cluster_data = df[df['Cluster'] == cluster]\n",
    "\n",
    "    # 确保尝试删除的列存在于DataFrame中，否则忽略\n",
    "    drop_columns = [col for col in drop_columns if col in cluster_data.columns]\n",
    "    X = cluster_data.drop(columns=drop_columns, errors='ignore')\n",
    "    y = cluster_data['stars']\n",
    "    return X, y\n",
    "\n",
    "def train_elastic_net(cluster, train_df, test_df):\n",
    "    drop_columns = ['stars', 'user_id', 'business_id']\n",
    "    # 如果score列有NaN值，添加到删除列表\n",
    "    if pd.isnull(train_df['score']).any() or pd.isnull(test_df['score']).any():\n",
    "        drop_columns.append('score')\n",
    "\n",
    "    X_train, y_train = prepare_data(train_df, cluster, drop_columns)\n",
    "    X_test, y_test = prepare_data(test_df, cluster, drop_columns)\n",
    "        \n",
    "    # 使用ElasticNetCV自动调整参数\n",
    "    model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], alphas=np.logspace(-6, 2, 100), cv=5, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best alpha:\", model.alpha_)\n",
    "    print(\"Best l1_ratio:\", model.l1_ratio_)\n",
    "    \n",
    "    # 训练最终模型\n",
    "    model = ElasticNet(alpha=model.alpha_, l1_ratio=model.l1_ratio_)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 预测测试集\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "cluster = 1  # 示例使用Cluster 1\n",
    "rmse = train_elastic_net(cluster, train_df, val_df)\n",
    "print(f\"Cluster {cluster} RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bd434-2db9-4c38-adff-d140db5c35af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1b6105d7-e4fd-489f-9ef4-0b5a4936e0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.005179474679231208\n",
      "Best l1_ratio: 0.01\n",
      "Cluster 1 RMSE: 0.9858956922327305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "def prepare_data(df, cluster, drop_columns):\n",
    "    if cluster == -1:\n",
    "        cluster_data = df\n",
    "    else:\n",
    "        cluster_data = df[df['Cluster'] == cluster]\n",
    "\n",
    "    drop_columns = [col for col in drop_columns if col in cluster_data.columns]\n",
    "    X = cluster_data.drop(columns=drop_columns, errors='ignore')\n",
    "    y = cluster_data['stars']\n",
    "    return X, y\n",
    "\n",
    "def train_elastic_net(cluster, train_df, test_df):\n",
    "    drop_columns = ['stars', 'user_id', 'business_id']\n",
    "    if train_df['score'].isnull().any() or test_df['score'].isnull().any():\n",
    "        drop_columns.append('score')\n",
    "\n",
    "    X_train, y_train = prepare_data(train_df, cluster, drop_columns)\n",
    "    X_test, y_test = prepare_data(test_df, cluster, drop_columns)\n",
    "        \n",
    "    # 使用ElasticNetCV进行更细粒度的参数搜索\n",
    "    model_cv = ElasticNetCV(l1_ratio=np.linspace(0.01, 0, 1), alphas=np.logspace(-6, 1, 50), cv=5, random_state=42)\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best alpha:\", model_cv.alpha_)\n",
    "    print(\"Best l1_ratio:\", model_cv.l1_ratio_)\n",
    "    \n",
    "    # 使用选择的最佳参数训练ElasticNet模型\n",
    "    model = ElasticNet(alpha=model_cv.alpha_, l1_ratio=model_cv.l1_ratio_, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 特征选择\n",
    "    selector = SelectFromModel(estimator=model, threshold='mean', prefit=True)\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    # 重新训练模型使用被选择的特征\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 预测并计算RMSE\n",
    "    preds = model.predict(X_test_selected)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# 示例代码执行\n",
    "cluster = 1  # 使用Cluster 1\n",
    "rmse = train_elastic_net(cluster, train_df, test_df)\n",
    "print(f\"Cluster {cluster} RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037316d-9f46-48e2-a821-88c7a28a276e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390f3d1-e36b-4ae4-83aa-2663dce9e16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a4d94-a810-47c2-9e33-191325cd5e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b9b4edfd-3f23-4d18-be84-999b16dfab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下列包含NaN值：\n",
      "score\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_nan_columns(df):\n",
    "    nan_columns = df.columns[df.isna().any()].tolist()\n",
    "    if nan_columns:\n",
    "        print(\"以下列包含NaN值：\")\n",
    "        for column in nan_columns:\n",
    "            print(column)\n",
    "    else:\n",
    "        print(\"DataFrame中没有包含NaN值的列。\")\n",
    "\n",
    "# 检查val_df中的NaN列\n",
    "check_nan_columns(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e6b99-73ef-4356-bb43-6dd7d3c93c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94a8b4-042a-4eb4-a98c-1138472be961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad957284-5d1e-42d6-89a5-762c034da079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b9420805-f8f0-4066-9ce6-26c62bdd5ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.0035938136638046293\n",
      "Best l1_ratio: 0.1\n",
      "Cluster 1 RMSE: 0.9591603171535215\n"
     ]
    }
   ],
   "source": [
    "def train_elastic_net(cluster, train_df, test_df):\n",
    "    # 准备数据\n",
    "    X_train, y_train = prepare_data(train_df, cluster)\n",
    "    X_test, y_test = prepare_data(test_df, cluster)\n",
    "    \n",
    "    # 使用ElasticNetCV自动调整参数\n",
    "    model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], alphas=np.logspace(-6, 2, 100), cv=5, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best alpha:\", model.alpha_)\n",
    "    print(\"Best l1_ratio:\", model.l1_ratio_)\n",
    "    \n",
    "    # 训练最终模型\n",
    "    final_model = ElasticNet(alpha=model.alpha_, l1_ratio=model.l1_ratio_)\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 预测测试集\n",
    "    test_preds = final_model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "    \n",
    "    return test_rmse\n",
    "\n",
    "cluster = 1  # 示例使用Cluster 1\n",
    "rmse = train_elastic_net(cluster, train_df, test_df)\n",
    "print(f\"Cluster {cluster} RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c8b6e0-7f47-4d85-b43b-478ffb67c2a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SPECIFIC FEATURES AND CLUSTER ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b56f5-d10f-4af7-8ffa-1015663a6384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd99c3-2289-4726-9421-5ec5a518b285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead5d1e-8898-47e6-92fa-000bf5e690f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026921b0-4994-4212-99b1-f6fa0c6e705d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e149ad-b875-4309-a77a-913475601bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9640ee0f-7c92-4ba9-96ad-79d6f36e89fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68e45a-a2a1-45c7-9fd8-d74c7e2cdf93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f723a1b-bae8-4c43-ad29-8a06ca54b15d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RANK METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b760f7e1-aa91-4db7-9e21-a0e167a5eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个Cluster中有多少条记录\n",
    "group_data = final_df.groupby('Cluster').size().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfc17c57-21e3-4565-8b1c-2e1648706d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备XGBoost的数据，假设label是目标变量\n",
    "X = final_df.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "\n",
    "y = final_df['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "219e4b18-3ad6-4418-acbb-477b656230fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6bf987d-0ed2-44bb-bd80-c04ceefa5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建DMatrix\n",
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "dtrain.set_group(group_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eta': 0.1,\n",
    "    'gamma': 0.1,\n",
    "    'min_child_weight': 0.1,\n",
    "    'max_depth': 3\n",
    "}\n",
    "\n",
    "# 训练模型\n",
    "bst = xgb.train(params, dtrain, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e28e78-d34f-401a-a4aa-208fb0851859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d7b3b06-a188-459f-96c0-79726e61e93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Prepare Test data \n",
    "test_data_file = '../yelp_true.csv'\n",
    "test_df = pd.read_csv(test_data_file)\n",
    "\n",
    "data_folder_path = '../data/'\n",
    "test_res_rdd = feature_processor.process_all_features(sc, test_df, data_folder_path, test_data_file)\n",
    "\n",
    "val_df = rdd_to_pandas(test_res_rdd)\n",
    "val_df = val_df.merge(user_clusters, on='user_id', how='left')\n",
    "\n",
    "val_group_data = val_df.groupby('Cluster').size().to_list()\n",
    "\n",
    "X_val = val_df.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "\n",
    "y_val = val_df['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "042c332d-2715-4e8d-85fa-78b458de902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac83a922-684b-4c23-89b4-67b8a4243cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [-0.5655462  -0.39554703 -0.379111   ... -0.28824937 -0.37578714\n",
      " -0.63751644]\n"
     ]
    }
   ],
   "source": [
    "predictions = bst.predict(dtest)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2925b9a7-29f8-4e76-824f-6ff76f8c569b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "060ad3f9-a5e3-48dd-b69b-fdbecfd34639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = merged_final_df.drop(['user_id', 'business_id', 'stars'], axis=1)\n",
    "y = merged_final_df['stars']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cac54391-9ea6-478d-8ed3-bbf8328af0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../yelp_true.csv的RMSE: 0.9819683713608058\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'colsample_bytree': 0.6000253271077364,\n",
    "    'gamma': 0.3476073435753331,\n",
    "    'learning_rate': 0.03186356519406673,\n",
    "    'max_depth': 8,\n",
    "    'n_estimators': 480,\n",
    "    'subsample': 0.8831766281686719\n",
    "}\n",
    "\n",
    "best_model = XGBRegressor(**params)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 使用独立的测试集进行最终评估\n",
    "y_pred = best_model.predict(X_test)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"{test_data_file}的RMSE:\", final_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
