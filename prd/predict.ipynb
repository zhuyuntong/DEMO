{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a291572-0723-47cb-bb63-c6027a057a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/04 01:04:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import json\n",
    "from operator import add\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from node2vec import Node2Vec as n2v\n",
    "import networkx as nx\n",
    "from hashlib import md5\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "\n",
    "from utils import create_category_md5_mapping, integrate_mapping_user_bus_cat_data, dataframe_to_rdd_dict, analyze_top_business_categories, analyze_top_categories\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "def initialize_spark_context(APP_NAME=\"Train: XGBModel\"):\n",
    "    # Spark配置项列表\n",
    "    SPARK_CONF = [\n",
    "        (\"spark.dynamicAllocation.enabled\", \"true\"),  # 启用动态资源分配\n",
    "        (\"spark.dynamicAllocation.maxExecutors\", \"10\"),  # 最大执行器数量\n",
    "        (\"spark.executor.memory\", \"3g\"),  # 每个执行器的内存\n",
    "        (\"spark.executor.cores\", \"2\"),  # 每个执行器的CPU核心数\n",
    "        (\"spark.executor.memoryOverhead\", \"3000\"),  # 执行器内存开销\n",
    "        (\"spark.driver.memory\", \"4g\"),  # 驱动程序的内存\n",
    "        (\"spark.driver.maxResultSize\", \"2g\"),  # 驱动程序的最大结果大小\n",
    "        (\"spark.python.worker.memory\", \"2g\"),  # Python工作进程的内存\n",
    "        (\"spark.sql.shuffle.partitions\", \"20\"),  # Shuffle操作的分区数\n",
    "        (\"spark.sql.sources.partitionOverWriteMode\", \"dynamic\"),  # 分区覆写模式\n",
    "        (\"spark.network.timeout\", \"600s\"),  # 网络超时设置\n",
    "        (\"spark.executor.heartbeatInterval\", \"120s\"),  # 执行器心跳间隔\n",
    "    ]\n",
    "\n",
    "    # 创建Spark配置\n",
    "    spark_conf = pyspark.SparkConf()\n",
    "    spark_conf.setAppName(APP_NAME)\n",
    "    spark_conf.setAll(SPARK_CONF)\n",
    "\n",
    "    # 创建SparkContext\n",
    "    sc = pyspark.SparkContext(conf=spark_conf)\n",
    "    sc.setLogLevel(\"ERROR\")  # 设置日志级别\n",
    "\n",
    "    return sc\n",
    "\n",
    "sc = initialize_spark_context()\n",
    "\n",
    "import better_features\n",
    "from better_features import FeatureProcessor, read_json_data, transform_user_data, transform_business_data, extract_review_data\n",
    "from datetime import datetime #add\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def rdd_to_pandas(rdd):\n",
    "    return pd.DataFrame(rdd.collect(), columns=rdd.first().keys())\n",
    "\n",
    "def prepare_test_data(test_df, cluster):\n",
    "    if cluster == -1:\n",
    "        test_cluster_data = test_df\n",
    "    else:\n",
    "        test_cluster_data = test_df[test_df['Cluster'] == cluster]\n",
    "        \n",
    "    X_test = test_cluster_data.drop(columns=['stars', 'user_id', 'business_id'])\n",
    "    y_test = test_cluster_data['stars']\n",
    "    return X_test, y_test\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "user_parsed_df = pd.read_csv('cache/user_df.csv') # parsed from users.json\n",
    "business_parsed_df = pd.read_csv('cache/business_df.csv') # parsed from business.json\n",
    "review_parsed_df = pd.read_csv('cache/review_df.csv') # parsed from business.json\n",
    "\n",
    "train_df = pd.read_csv('cache/train_df.csv', index_col=None)\n",
    "test_df = pd.read_csv('cache/test_df.csv', index_col=None)\n",
    "val_df = pd.read_csv('cache/val_df.csv', index_col=None)\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdd757-52aa-48f7-a647-aa123664747c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "277f6f88-62f4-4705-aa2b-ff9643516bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_xgb_params = {\n",
    "    0: {'learning_rate': 0.04246778091879101, 'max_depth': 6, 'n_estimators': 491, 'subsample': 0.8689},\n",
    "    2: {'learning_rate': 0.12350751460907078, 'max_depth': 3, 'n_estimators': 288, 'subsample': 0.8880},\n",
    "    3: {'learning_rate': 0.08288064461501718, 'max_depth': 5, 'n_estimators': 305, 'subsample': 0.6839},\n",
    "    4: {'learning_rate': 0.18299396047960448, 'max_depth': 4, 'n_estimators': 250, 'subsample': 0.9081}\n",
    "}\n",
    "\n",
    "large_catboost_params = {\n",
    "    0: {'depth': 12, 'l2_leaf_reg': 18.15, 'learning_rate': 0.06229, 'n_estimators': 1486},\n",
    "    2: {'depth': 6, 'l2_leaf_reg': 28.02, 'learning_rate': 0.1090, 'n_estimators': 176},\n",
    "    3: {'depth': 5, 'l2_leaf_reg': 0.2358, 'learning_rate': 0.1968, 'n_estimators': 62},\n",
    "    4: {'depth': 4, 'l2_leaf_reg': 0.3376, 'learning_rate': 0.1914, 'n_estimators': 46}\n",
    "}\n",
    "\n",
    "# 5, 6, 7, 8\n",
    "# test_size = 0.1\n",
    "medium_catboost_params = {\n",
    "    5: {'depth': 3, 'l2_leaf_reg': 0.415375550656062, 'learning_rate': 0.9017553809036529}, \n",
    "    7: {'depth': 6, 'l2_leaf_reg': 18.3792029910461, 'learning_rate': 0.9372003134293689}, \n",
    "    8: {'depth': 1, 'l2_leaf_reg': 7.440376345058953, 'learning_rate': 0.4049807340854126},\n",
    "    6: {'depth': 2, 'l2_leaf_reg': 1.1835517768726047, 'learning_rate': 0.38770112704134657}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bdefd5-b3f6-415a-a9b3-b45ae5d0ef1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06839fdb-b8fa-4a85-b248-847fdfe3902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE: 0.982394945341761\n",
      "CB RMSE: 0.9872458065362693\n",
      "Final RMSE: 0.9820347044803716\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# 初始化和训练模型，返回预测结果和RMSE\n",
    "def train_and_predict(X_train, y_train, X_test, y_test, model_params, model_type='xgb'):\n",
    "    if model_type == 'xgb':\n",
    "        model = XGBRegressor(**model_params, objective='reg:squarederror', verbosity=0)\n",
    "    elif model_type == 'cb':\n",
    "        model = CatBoostRegressor(**model_params, verbose=False)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type: \" + model_type)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test).clip(1, 5)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    return preds, rmse\n",
    "\n",
    "# 处理数据\n",
    "def prepare_data(df, drop_cols):\n",
    "    df = df.drop(columns=drop_cols, errors='ignore')\n",
    "    X = df.drop(columns=['stars'])\n",
    "    y = df['stars']\n",
    "    return X, y\n",
    "\n",
    "# 配置和数据准备\n",
    "drop_cols = ['user_id', 'business_id']  # 默认去除的列\n",
    "\n",
    "# 为cluster 0准备数据\n",
    "X_train, y_train = prepare_data(train_df[train_df['Cluster'] == 0], drop_cols)\n",
    "X_test, y_test = prepare_data(test_df[test_df['Cluster'] == 0], drop_cols)\n",
    "\n",
    "# 训练模型和预测\n",
    "xgb_params = large_xgb_params[0]\n",
    "cb_params = large_catboost_params[0]\n",
    "\n",
    "xgb_preds, xgb_rmse = train_and_predict(X_train, y_train, X_test, y_test, xgb_params, model_type='xgb')\n",
    "cb_preds, cb_rmse = train_and_predict(X_train, y_train, X_test, y_test, cb_params, model_type='cb')\n",
    "\n",
    "# 组合预测结果和计算最终RMSE\n",
    "best_ratio = 0.5  # 假设已经通过某种方式得到最佳权重比例\n",
    "final_preds = best_ratio * cb_preds + (1 - best_ratio) * xgb_preds\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, final_preds))\n",
    "\n",
    "# 输出结果\n",
    "print(\"XGB RMSE:\", xgb_rmse)\n",
    "print(\"CB RMSE:\", cb_rmse)\n",
    "print(\"Final RMSE:\", final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c3fff-d77f-48e8-8a33-ce0be5eafedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6a5c7-0b4b-469a-818e-b67eba21abc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa21759-13d5-4c15-960c-b2a7a6fb3782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466507a-103e-41af-9d28-4dbfac590700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
